{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "## Agent Supervisor\n",
    "\n",
    "The [previous example](multi-agent-collaboration.ipynb) routed messages automatically based on the output of the initial researcher agent.\n",
    "\n",
    "We can also choose to use an LLM to orchestrate the different agents.\n",
    "\n",
    "Below, we will create an agent group, with an agent supervisor to help delegate tasks.\n",
    "\n",
    "![diagram](./img/supervisor-diagram.png)\n",
    "\n",
    "To simplify the code in each agent node, we will use the AgentExecutor class from LangChain. This and other \"advanced agent\" notebooks are designed to show how you can implement certain design patterns in LangGraph. If the pattern suits your needs, we recommend combining it with some of the other fundamental patterns described elsewhere in the docs for best performance.\n",
    "\n",
    "Before we build, let's configure our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"OPENAI_API_KEY\", \"sk_...\");\n",
    "// Deno.env.set(\"TAVILY_API_KEY\", \"sk_...\");\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"sk_...\");\n",
    "Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_PROJECT\", \"Multi-agent Collaboration: LangGraphJS\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac25624-4d83-45a4-b9ef-a10589aacfb7",
   "metadata": {},
   "source": [
    "## Create tools\n",
    "\n",
    "For this example, you will make an agent to do web research with a search engine, and one agent to create plots. Define the tools they'll use below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04c6778-403b-4b49-9b93-678e910d5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import {TavilySearchResults} from \"npm:@langchain/community/tools/tavily_search\"\n",
    "import { DynamicStructuredTool } from \"npm:@langchain/core/tools\";\n",
    "import * as d3 from \"https://cdn.skypack.dev/d3@7\";\n",
    "import { createCanvas } from \"https://deno.land/x/skia_canvas/mod.ts\";\n",
    "import { z } from \"npm:zod\";\n",
    "\n",
    "const chartTool = new DynamicStructuredTool({\n",
    "  name: \"generate_bar_chart\",\n",
    "  description:\n",
    "    \"Generates a bar chart from an array of data points using D3.js and displays it for the user.\",\n",
    "  schema: z.object({\n",
    "    data: z\n",
    "      .object({\n",
    "        label: z.string(),\n",
    "        value: z.number(),\n",
    "      })\n",
    "      .array(),\n",
    "  }),\n",
    "  func: async ({data}) => {\n",
    "    // const data = input.data;\n",
    "    const width = 500;\n",
    "    const height = 500;\n",
    "    const margin = { top: 20, right: 30, bottom: 30, left: 40 };\n",
    "\n",
    "    const canvas = createCanvas(width, height);\n",
    "    const ctx = canvas.getContext(\"2d\");\n",
    "\n",
    "    const x = d3\n",
    "      .scaleBand()\n",
    "      .domain(data.map((d) => d.label))\n",
    "      .range([margin.left, width - margin.right])\n",
    "      .padding(0.1);\n",
    "\n",
    "    const y = d3\n",
    "      .scaleLinear()\n",
    "      .domain([0, d3.max(data, (d) => d.value)])\n",
    "      .nice()\n",
    "      .range([height - margin.bottom, margin.top]);\n",
    "\n",
    "    const colorPalette = [\n",
    "      \"#e6194B\",\n",
    "      \"#3cb44b\",\n",
    "      \"#ffe119\",\n",
    "      \"#4363d8\",\n",
    "      \"#f58231\",\n",
    "      \"#911eb4\",\n",
    "      \"#42d4f4\",\n",
    "      \"#f032e6\",\n",
    "      \"#bfef45\",\n",
    "      \"#fabebe\",\n",
    "    ];\n",
    "\n",
    "    data.forEach((d, idx) => {\n",
    "      ctx.fillStyle = colorPalette[idx % colorPalette.length];\n",
    "      ctx.fillRect(\n",
    "        x(d.label),\n",
    "         y(d.value),\n",
    "        x.bandwidth(),\n",
    "        height - margin.bottom - y(d.value),\n",
    "      );\n",
    "    });\n",
    "\n",
    "    ctx.beginPath();\n",
    "    ctx.strokeStyle = \"black\";\n",
    "    ctx.moveTo(margin.left, height - margin.bottom);\n",
    "    ctx.lineTo(width - margin.right, height - margin.bottom);\n",
    "    ctx.stroke();\n",
    "\n",
    "    ctx.textAlign = \"center\";\n",
    "    ctx.textBaseline = \"top\";\n",
    "    x.domain().forEach((d) => {\n",
    "      const xCoord = x(d) + x.bandwidth() / 2;\n",
    "      ctx.fillText(d, xCoord, height - margin.bottom + 6);\n",
    "    });\n",
    "\n",
    "    ctx.beginPath();\n",
    "    ctx.moveTo(margin.left, height - margin.top);\n",
    "    ctx.lineTo(margin.left, height - margin.bottom);\n",
    "    ctx.stroke();\n",
    "\n",
    "    ctx.textAlign = \"right\";\n",
    "    ctx.textBaseline = \"middle\";\n",
    "    const ticks = y.ticks();\n",
    "    ticks.forEach((d) => {\n",
    "      const yCoord = y(d); // height - margin.bottom - y(d);\n",
    "      ctx.moveTo(margin.left, yCoord);\n",
    "      ctx.lineTo(margin.left - 6, yCoord);\n",
    "      ctx.stroke();\n",
    "      ctx.fillText(d, margin.left - 8, yCoord);\n",
    "    });\n",
    "\n",
    "    await Deno.jupyter.display(canvas);\n",
    "    return \"Chart generated\";\n",
    "  },\n",
    "});\n",
    "\n",
    "const tavilyTool = new TavilySearchResults();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d1e85-22d4-4c22-9062-72a346a0d709",
   "metadata": {},
   "source": [
    "## Helper Utilites\n",
    "\n",
    "Define a helper function below, which make it easier to add new agent worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4823dd9-26bd-4e1a-8117-b97b2860211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { AgentExecutor, createOpenAIToolsAgent } from \"npm:langchain/agents\";\n",
    "import { BaseMessage, HumanMessage } from \"npm:@langchain/core/messages\";\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"npm:@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"npm:@langchain/openai\";\n",
    "import { END, StateGraph } from \"npm:@langchain/langgraph\";\n",
    "import { Runnable } from \"npm:@langchain/core/runnables\";\n",
    "\n",
    "\n",
    "async function createAgent(\n",
    "  llm: ChatOpenAI, \n",
    "  tools: any[], \n",
    "  systemPrompt: string\n",
    "): Runnable {\n",
    "  // Each worker node will be given a name and some tools.\n",
    "  const prompt = await ChatPromptTemplate.fromMessages([\n",
    "   [\"system\", systemPrompt],\n",
    "    new MessagesPlaceholder(\"messages\"),\n",
    "    new MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "  ]);\n",
    "  const agent = await createOpenAIToolsAgent({llm, tools, prompt});\n",
    "  return new AgentExecutor({agent, tools});\n",
    "}\n",
    "\n",
    "\n",
    "async function agentNode({state, agent, name}){\n",
    "    const result = await agent.invoke(state)\n",
    "    return {messages: [new HumanMessage({ content: result.output, name })]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b883c63-460d-45b0-82a3-61257db20af0",
   "metadata": {},
   "source": [
    "## Create Agent Supervisor\n",
    "\n",
    "The supervisor routes the work between our worker agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c108a0-6dc3-46fd-a5e6-a1fcfad5458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"npm:@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"npm:@langchain/openai\";\n",
    "import { JsonOutputToolsParser } from \"npm:langchain/output_parsers\";\n",
    "\n",
    "const members = [\"Researcher\", \"ChartGenerator\"];\n",
    "\n",
    "const systemPrompt = (\n",
    "  \"You are a supervisor tasked with managing a conversation between the\" +\n",
    "  \" following workers: {members}. Given the following user request,\" +\n",
    "  \" respond with the worker to act next. Each worker will perform a\" +\n",
    "  \" task and respond with their results and status. When finished,\" +\n",
    "  \" respond with FINISH.\"\n",
    ");\n",
    "const options = [\"FINISH\", ...members];\n",
    "\n",
    "// Define the routing function\n",
    "const functionDef = {\n",
    "  name: \"route\",\n",
    "  description: \"Select the next role.\",\n",
    "  parameters: {\n",
    "    title: \"routeSchema\",\n",
    "    type: \"object\",\n",
    "    properties: {\n",
    "      next: {\n",
    "        title: \"Next\",\n",
    "        anyOf: [\n",
    "          { enum: options },\n",
    "        ],\n",
    "      },\n",
    "    },\n",
    "    required: [\"next\"],\n",
    "  },\n",
    "};\n",
    "const toolDef = {\n",
    "    type: \"function\",\n",
    "    function: functionDef,\n",
    "}\n",
    "\n",
    "const prompt = await ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", systemPrompt],\n",
    "  new MessagesPlaceholder(\"messages\"),\n",
    "  [\n",
    "    \"system\",\n",
    "    \"Given the conversation above, who should act next?\"\n",
    "      +\" Or should we FINISH? Select one of: {options}\",\n",
    "  ],\n",
    "]).partial({ options: options.join(\", \"), members: members.join(\", \") });\n",
    "\n",
    "const llm = new ChatOpenAI(\"gpt-4-1106-preview\");\n",
    "\n",
    "const supervisorChain = prompt\n",
    "  .pipe(llm.bind({tools: [toolDef], tool_choice: {\"type\": \"function\", \"function\": {\"name\": \"route\"}}}))\n",
    "  .pipe(new JsonOutputToolsParser())\n",
    "   // select the first one\n",
    "  .pipe((x ) => (x[0].args));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204c8c8c-dd24-454a-8eba-8600886eafb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ next: \u001b[32m\"Researcher\"\u001b[39m }"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await supervisorChain.invoke({messages: [new HumanMessage({content:\"write a report on birds.\"})]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d507f-34d1-4f1b-8dde-5e58d17b2166",
   "metadata": {},
   "source": [
    "## Construct Graph\n",
    "\n",
    "We're ready to start building the graph. First, we'll define the state the graph will track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb72f53-e88c-4643-bfbb-b1b75bf1857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"npm:@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"npm:@langchain/openai\";\n",
    "import { END, StateGraph } from \"npm:@langchain/langgraph\";\n",
    "import { BaseMessage } from \"npm:@langchain/core/messages\";\n",
    "\n",
    "interface AgentStateChannels {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => BaseMessage[];\n",
    "    default: () => BaseMessage[];\n",
    "  };\n",
    "  next: string;\n",
    "}\n",
    "\n",
    "// This defines the agent state\n",
    "const agentStateChannels: AgentStateChannels = {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),\n",
    "    default: () => [],\n",
    "  },\n",
    "  next: 'initialValueForNext', // Replace 'initialValueForNext' with your initial value if needed\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1593d5-39f7-4819-96d2-4ad7d7991d72",
   "metadata": {},
   "source": [
    "Next, create the agents to add to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14778e86-077b-4e6a-893c-400e59b0cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, StateGraph } from \"npm:@langchain/langgraph\";\n",
    "\n",
    "const llm = new ChatOpenAI({modelName: \"gpt-4-1106-preview\"});\n",
    "\n",
    "const researcherAgent = await createAgent(\n",
    "  llm, \n",
    "  [tavilyTool], \n",
    "  \"You are a web researcher. You may use the Tavily search engine to search the web for\"\n",
    "    +\" important information, so the Chart Generator in your team can make useful plots.\"\n",
    ");\n",
    "const researcherNode = async (state) => await agentNode({\n",
    "     state, \n",
    "     agent: researcherAgent, \n",
    "     name: \"Researcher\",\n",
    " });\n",
    "const chartGenAgent = await createAgent(\n",
    "  llm, \n",
    "  [chartTool], \n",
    "  \"You excel at generating bar charts. Use the researcher's information to generate the charts.\"\n",
    ");\n",
    "const chartGenNode = async (state) => await agentNode({\n",
    "    state, agent: chartGenAgent, \n",
    "    name: \"ChartGenerator\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac913ae-0dfc-44bf-a26c-8f23f7e3e4a2",
   "metadata": {},
   "source": [
    "Now we can create the graph itself! Add the nodes, and add edges to define how how work will be performed in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f874f7-dac1-4b81-9ddc-a161f9b5bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 1. Create the graph\n",
    "const workflow = new StateGraph({\n",
    "  channels: agentStateChannels,\n",
    "});\n",
    "\n",
    "// 2. Add the nodes; these will do the work\n",
    "workflow.addNode(\"Researcher\", researcherNode);\n",
    "workflow.addNode(\"ChartGenerator\", chartGenNode);\n",
    "workflow.addNode(\"supervisor\", supervisorChain);\n",
    "// 3. Define the edges. We will define both regular and conditional ones\n",
    "// After a worker completes, report to supervisor\n",
    "members.forEach(member => {\n",
    "    workflow.addEdge(member, \"supervisor\");\n",
    "});\n",
    "\n",
    "// When the supervisor returns, route to the agent identified in the supervisor's output\n",
    "const conditionalMap: { [key: string]: string } = members.reduce((acc, member) => {\n",
    "    acc[member] = member;\n",
    "    return acc;\n",
    "}, {});\n",
    "// Or end work if done\n",
    "conditionalMap[\"FINISH\"] = END;\n",
    "\n",
    "workflow.addConditionalEdges(\n",
    "    \"supervisor\", \n",
    "    (x: AgentStateChannels) => x.next,\n",
    "    conditionalMap,\n",
    ");\n",
    "\n",
    "workflow.setEntryPoint(\"supervisor\");\n",
    "\n",
    "const graph = workflow.compile();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36496de-7121-4c49-8cb6-58c943c66628",
   "metadata": {},
   "source": [
    "## Invoke the team\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ba78e9-d9c1-457c-a073-d606d5d3e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "const streamResults = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            new HumanMessage({content:\"What were the 3 most popular tv shows in 2023?\"})\n",
    "        ]\n",
    "    },\n",
    "    {recursionLimit: 100},\n",
    ")\n",
    "for await (const output of await streamResults) {\n",
    "    if (!output?.__end__){\n",
    "        console.log(output);\n",
    "        console.log('----');\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a92dfd-0e11-47f5-aad4-b68d24990e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ supervisor: { next: \u001b[32m\"Researcher\"\u001b[39m } }\n",
      "----\n",
      "{\n",
      "  Researcher: {\n",
      "    messages: [\n",
      "      HumanMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[32m\"I found the US GDP data for the years 2021, 2022, and 2023 from the search results.\\n\"\u001b[39m +\n",
      "            \u001b[32m\"\\n\"\u001b[39m +\n",
      "            \u001b[32m\"The GDP values \"\u001b[39m... 833 more characters,\n",
      "          name: \u001b[32m\"Researcher\"\u001b[39m,\n",
      "          additional_kwargs: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m\"I found the US GDP data for the years 2021, 2022, and 2023 from the search results.\\n\"\u001b[39m +\n",
      "          \u001b[32m\"\\n\"\u001b[39m +\n",
      "          \u001b[32m\"The GDP values \"\u001b[39m... 833 more characters,\n",
      "        name: \u001b[32m\"Researcher\"\u001b[39m,\n",
      "        additional_kwargs: {}\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "----\n",
      "{ supervisor: { next: \u001b[32m\"ChartGenerator\"\u001b[39m } }\n",
      "----\n",
      "{\n",
      "  ChartGenerator: {\n",
      "    messages: [\n",
      "      HumanMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[32m\"Here is the bar chart showing the US GDP for the years 2021 and 2022:\\n\"\u001b[39m +\n",
      "            \u001b[32m\"\\n\"\u001b[39m +\n",
      "            \u001b[32m\"![US GDP Bar Chart](sandbox:/\"\u001b[39m... 337 more characters,\n",
      "          name: \u001b[32m\"ChartGenerator\"\u001b[39m,\n",
      "          additional_kwargs: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m\"Here is the bar chart showing the US GDP for the years 2021 and 2022:\\n\"\u001b[39m +\n",
      "          \u001b[32m\"\\n\"\u001b[39m +\n",
      "          \u001b[32m\"![US GDP Bar Chart](sandbox:/\"\u001b[39m... 337 more characters,\n",
      "        name: \u001b[32m\"ChartGenerator\"\u001b[39m,\n",
      "        additional_kwargs: {}\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "----\n",
      "{ supervisor: { next: \u001b[32m\"FINISH\"\u001b[39m } }\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "const streamResults = await graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            new HumanMessage({content:\"Generate a bar chart of the US gdp over the past 3 years.\"})\n",
    "        ]\n",
    "    },\n",
    "    {recursionLimit: 150},\n",
    ")\n",
    "for await (const output of await streamResults) {\n",
    "    if (!output?.__end__){\n",
    "        console.log(output);\n",
    "        console.log('----');\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d363d2c-e0da-4cce-ba47-ad2aa9df0fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
