{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {},
   "source": [
    "# Basic Multi-agent Collaboration\n",
    "\n",
    "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like `gpt-4`, it can be less effective at using many tools. \n",
    "\n",
    "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create an specialized agent for each task or domain and route tasks to the correct \"expert\".\n",
    "\n",
    "This notebook (inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al.) shows one way to do this using LangGraph.\n",
    "\n",
    "The resulting graph will look something like the following diagram:\n",
    "\n",
    "![multi_agent diagram](./img/simple_multi_agent_diagram.png)\n",
    "\n",
    "Before we get started, a quick note: this and other multi-agent notebooks are designed to show _how_ you can implement certain design patterns in LangGraph. If the pattern suits your needs, we recommend combining it with some of the other fundamental patterns described elsewhere in the docs for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"OPENAI_API_KEY\", \"sk_...\");\n",
    "// Deno.env.set(\"TAVILY_API_KEY\", \"sk_...\");\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"sk_...\");\n",
    "Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_PROJECT\", \"Multi-agent Collaboration: LangGraphJS\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4344a7-21df-4d54-90d2-9d19b3416ffb",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "The following helper functions will help create agents. These agents will then be nodes in the graph. \n",
    "\n",
    "You can skip ahead if you just want to see what the graph looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4325a10e-38dc-4a98-9004-e1525eaba377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder,\n",
    "} from \"npm:@langchain/core/prompts\";\n",
    "import { BaseTool } from \"npm:@langchain/core/tools\";\n",
    "import { convertToOpenAITool } from \"npm:@langchain/core/utils/function_calling\";\n",
    "import type { BaseLanguageModelInterface } from \"npm:@langchain/core/language_models/base\";\n",
    "import { Runnable } from \"npm:@langchain/core/runnables\";\n",
    "\n",
    "/**\n",
    " * Create an agent that can run a set of tools.\n",
    " */\n",
    "async function createAgent({\n",
    "  llm,\n",
    "  tools,\n",
    "  systemMessage,\n",
    "}: {\n",
    "  llm: BaseLanguageModel;\n",
    "  tools: BaseTool[];\n",
    "  systemMessage: string;\n",
    "}): Promise<Runnable> {\n",
    "  const toolNames = tools.map((tool) => tool.name).join(\", \");\n",
    "  const formattedTools = tools.map((t) => convertToOpenAITool(t));\n",
    "\n",
    "  let prompt = await ChatPromptTemplate.fromMessages([\n",
    "    [\n",
    "      \"system\",\n",
    "      \"You are a helpful AI assistant, collaborating with other assistants.\" +\n",
    "        \" Use the provided tools to progress towards answering the question.\" +\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \" +\n",
    "        \" will help where you left off. Execute what you can to make progress.\" +\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\" +\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\" +\n",
    "        \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "    ],\n",
    "    new MessagesPlaceholder(\"messages\"),\n",
    "  ]);\n",
    "  prompt = await prompt.partial({\n",
    "    system_message: systemMessage,\n",
    "    tool_names: toolNames,\n",
    "  })\n",
    "\n",
    "  return prompt.pipe(llm.bind({ tools: formattedTools }));\n",
    "}\n",
    "\n",
    "const isToolMessage = (message) => !!message?.additional_kwargs?.tool_calls;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b40de2-5dd4-4d5b-882e-577210723ff4",
   "metadata": {},
   "source": [
    "## Define tools\n",
    "\n",
    "These tools will be used by our worker agents to answer our questions.\n",
    "\n",
    "We will create a chart tool (using d3.js), and the LangChain TavilySearchResults tool for web search functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca076f3b-a729-4ca9-8f91-05c2ba58d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TavilySearchResults } from \"npm:@langchain/community/tools/tavily_search\";\n",
    "import { DynamicStructuredTool } from \"npm:@langchain/core/tools\";\n",
    "import * as d3 from \"https://cdn.skypack.dev/d3@7\";\n",
    "import { createCanvas } from \"https://deno.land/x/skia_canvas/mod.ts\";\n",
    "import { z } from \"npm:zod\";\n",
    "\n",
    "const chartTool = new DynamicStructuredTool({\n",
    "  name: \"generate_bar_chart\",\n",
    "  description:\n",
    "    \"Generates a bar chart from an array of data points using D3.js and displays it for the user.\",\n",
    "  schema: z.object({\n",
    "    data: z\n",
    "      .object({\n",
    "        label: z.string(),\n",
    "        value: z.number(),\n",
    "      })\n",
    "      .array(),\n",
    "  }),\n",
    "  func: async ({data}) => {\n",
    "    // const data = input.data;\n",
    "    const width = 500;\n",
    "    const height = 500;\n",
    "    const margin = { top: 20, right: 30, bottom: 30, left: 40 };\n",
    "\n",
    "    const canvas = createCanvas(width, height);\n",
    "    const ctx = canvas.getContext(\"2d\");\n",
    "\n",
    "    const x = d3\n",
    "      .scaleBand()\n",
    "      .domain(data.map((d) => d.label))\n",
    "      .range([margin.left, width - margin.right])\n",
    "      .padding(0.1);\n",
    "\n",
    "    const y = d3\n",
    "      .scaleLinear()\n",
    "      .domain([0, d3.max(data, (d) => d.value)])\n",
    "      .nice()\n",
    "      .range([height - margin.bottom, margin.top]);\n",
    "\n",
    "    const colorPalette = [\n",
    "      \"#e6194B\",\n",
    "      \"#3cb44b\",\n",
    "      \"#ffe119\",\n",
    "      \"#4363d8\",\n",
    "      \"#f58231\",\n",
    "      \"#911eb4\",\n",
    "      \"#42d4f4\",\n",
    "      \"#f032e6\",\n",
    "      \"#bfef45\",\n",
    "      \"#fabebe\",\n",
    "    ];\n",
    "\n",
    "    data.forEach((d, idx) => {\n",
    "      ctx.fillStyle = colorPalette[idx % colorPalette.length];\n",
    "      ctx.fillRect(\n",
    "        x(d.label),\n",
    "         y(d.value),\n",
    "        x.bandwidth(),\n",
    "        height - margin.bottom - y(d.value),\n",
    "      );\n",
    "    });\n",
    "\n",
    "    ctx.beginPath();\n",
    "    ctx.strokeStyle = \"black\";\n",
    "    ctx.moveTo(margin.left, height - margin.bottom);\n",
    "    ctx.lineTo(width - margin.right, height - margin.bottom);\n",
    "    ctx.stroke();\n",
    "\n",
    "    ctx.textAlign = \"center\";\n",
    "    ctx.textBaseline = \"top\";\n",
    "    x.domain().forEach((d) => {\n",
    "      const xCoord = x(d) + x.bandwidth() / 2;\n",
    "      ctx.fillText(d, xCoord, height - margin.bottom + 6);\n",
    "    });\n",
    "\n",
    "    ctx.beginPath();\n",
    "    ctx.moveTo(margin.left, height - margin.top);\n",
    "    ctx.lineTo(margin.left, height - margin.bottom);\n",
    "    ctx.stroke();\n",
    "\n",
    "    ctx.textAlign = \"right\";\n",
    "    ctx.textBaseline = \"middle\";\n",
    "    const ticks = y.ticks();\n",
    "    ticks.forEach((d) => {\n",
    "      const yCoord = y(d); // height - margin.bottom - y(d);\n",
    "      ctx.moveTo(margin.left, yCoord);\n",
    "      ctx.lineTo(margin.left - 6, yCoord);\n",
    "      ctx.stroke();\n",
    "      ctx.fillText(d, margin.left - 8, yCoord);\n",
    "    });\n",
    "\n",
    "    await Deno.jupyter.display(canvas);\n",
    "    return \"Chart generated\";\n",
    "  },\n",
    "});\n",
    "\n",
    "const tavilyTool = new TavilySearchResults();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b54c0c-0b09-408b-abc5-86308929afb6",
   "metadata": {},
   "source": [
    "## Create graph\n",
    "\n",
    "Now that we've defined our tools and made some helper functions, will create the individual agents below and tell them how to talk to each other using LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a283e-ea04-40c1-b792-f9e5f7d81203",
   "metadata": {},
   "source": [
    "### Define Agent Nodes\n",
    "\n",
    "In LangGraph, nodes represent functions that perform the work. In our example, we will have \"agent\" nodes and a \"callTool\" node.\n",
    "\n",
    "The input for every node is the graph's state. In our case, the state will have a list of messages as input, as well as the name of the previous node.\n",
    "\n",
    "First, let's define the nodes for the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"npm:@langchain/openai\";\n",
    "import {\n",
    "  AIMessage,\n",
    "  BaseMessage,\n",
    "  ToolMessage,\n",
    "  HumanMessage,\n",
    "} from \"npm:@langchain/core/messages\";\n",
    "\n",
    "// Helper function to create a node for a given agent\n",
    "async function agentNode({ state, agent, name }) {\n",
    "  let result = await agent.invoke(state);\n",
    "  // We convert the agent output into a format that is suitable\n",
    "  // to append to the global state\n",
    "  if (!isToolMessage(result)) {\n",
    "    // If the agent is NOT calling a tool, we want it to\n",
    "    // look like a human message.\n",
    "    result = new HumanMessage({ ...result, name: name });\n",
    "  }\n",
    "  return {\n",
    "    messages: [result],\n",
    "    // Since we have a strict workflow, we can\n",
    "    // track the sender so we know who to pass to next.\n",
    "    sender: name,\n",
    "  };\n",
    "}\n",
    "\n",
    "const llm = new ChatOpenAI({ modelName: \"gpt-4-1106-preview\" });\n",
    "\n",
    "// Research agent and node\n",
    "const researchAgent = await createAgent({\n",
    "  llm,\n",
    "  tools: [tavilyTool],\n",
    "  systemMessage:\n",
    "    \"You should provide accurate data for the chart generator to use.\",\n",
    "});\n",
    "\n",
    "async function researchNode(state) {\n",
    "  return await agentNode({\n",
    "    state: state,\n",
    "    agent: researchAgent,\n",
    "    name: \"Researcher\",\n",
    "  });\n",
    "}\n",
    "// Chart Generator\n",
    "const chartAgent = await createAgent({\n",
    "  llm,\n",
    "  tools: [chartTool],\n",
    "  systemMessage: \"Any charts you display will be visible by the user.\",\n",
    "});\n",
    "async function chartNode(state) {\n",
    "  return await agentNode({\n",
    "    state: state,\n",
    "    agent: chartAgent,\n",
    "    name: \"ChartGenerator\",\n",
    "  });\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd9f7d1-a839-4f28-8ef3-3cf665c6016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Example invocation\n",
    "const researchResults = await researchNode(\n",
    "   {\n",
    "        messages: [\n",
    "            new HumanMessage(\n",
    "                \"Research the US primaries in 2024\")\n",
    "        ]\n",
    "    }\n",
    "    \n",
    ")\n",
    "researchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7f1b2-24a3-4340-bcb2-feb22e344fb6",
   "metadata": {},
   "source": [
    "### Define Tool Node\n",
    "\n",
    "We now define a node to run the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a79c76-5c7c-42f6-91cf-635bc8305804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ToolExecutor } from \"npm:@langchain/langgraph/prebuilt\";\n",
    "const tools = [tavilyTool, chartTool];\n",
    "const toolExecutor = new ToolExecutor({ tools });\n",
    "\n",
    "// This runs tools in the graph\n",
    "async function toolNode(state) {\n",
    "  // It takes in an agent action and calls that tool and returns the result.\n",
    "  const messages = state.messages;\n",
    "  // Based on the continue condition\n",
    "  // we know the last message involves a function call\n",
    "  const lastMessage = messages[messages.length - 1];\n",
    "  const toolCalls = lastMessage.additional_kwargs.tool_calls;\n",
    "  const toolInputs = toolCalls.map((toolArgs) => {\n",
    "    let args = JSON.parse(toolArgs.function.arguments);\n",
    "    // We can pass single-arg inputs by value\n",
    "    if (\"__arg1\" in args && args.length === 1) {\n",
    "      args = args[\"__arg1\"];\n",
    "    }\n",
    "    return {\n",
    "      tool: toolArgs.function.name,\n",
    "      toolInput: args,\n",
    "    };\n",
    "  });\n",
    "  const toolResponses = await toolExecutor.batch(toolInputs);\n",
    "  const toolMessages = toolResponses.map((response, idx) => {\n",
    "    const action = toolInputs[idx];\n",
    "    const toolName = action.tool;\n",
    "    return new ToolMessage({\n",
    "      content: `${toolName} response: ${response}`,\n",
    "      name: action.tool,\n",
    "      tool_call_id: toolCalls[idx].id,\n",
    "    });\n",
    "  });\n",
    "  // We return an object, because this will get\n",
    "  // added to the existing list\n",
    "  return { messages: toolMessages };\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38a474-2354-4bbf-b35a-b4b0e8135f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Example invocation\n",
    "await toolNode(researchResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb30498-dbc4-4b20-980f-da08ebc9da56",
   "metadata": {},
   "source": [
    "### Define Edge Logic\n",
    "\n",
    "We can define some of the edge logic that is needed to decide what to do based on results of the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f4b4d37-e8a3-4abb-8d42-eaea26016f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Either agent can decide to end\n",
    "function router(state) {\n",
    "    const messages = state.messages;\n",
    "    const lastMessage = messages[messages.length - 1];\n",
    "    if (isToolMessage(lastMessage)) {\n",
    "        // The previous agent is invoking a tool\n",
    "        return \"call_tool\";\n",
    "    }\n",
    "    if (typeof lastMessage.content === 'string' && lastMessage.content.includes(\"FINAL ANSWER\")) {\n",
    "        // Any agent decided the work is done\n",
    "        return \"end\";\n",
    "    }\n",
    "    return \"continue\";\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a8c3c-86a0-46aa-b970-ab070fb787d9",
   "metadata": {},
   "source": [
    "### Define State\n",
    "\n",
    "We first define the state of the graph. This will just a list of messages, along with a key to track the most recent sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290c91d4-f6f4-443c-8181-233d39102974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StateGraph, END } from \"npm:@langchain/langgraph\";\n",
    "\n",
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder,\n",
    "} from \"npm:@langchain/core/prompts\";\n",
    "\n",
    "interface AgentStateChannels {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => BaseMessage[];\n",
    "    default: () => BaseMessage[];\n",
    "  };\n",
    "  // The agent node that last performed work\n",
    "  sender: string;\n",
    "}\n",
    "\n",
    "// This defines the object that is passed between each node\n",
    "// in the graph. We will create different nodes for each agent and tool\n",
    "const agentStateChannels: AgentStateChannels = {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),\n",
    "    default: () => [],\n",
    "  },\n",
    "  sender: \"user\",\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9359c34-e191-43a2-a3d4-f2dea636dfd2",
   "metadata": {},
   "source": [
    "### Define the Graph\n",
    "\n",
    "We can now put it all together and define the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01c59d31-e753-472e-ae7b-94ab068ff0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 1. Create the graph\n",
    "const workflow = new StateGraph({\n",
    "  channels: agentStateChannels,\n",
    "});\n",
    "\n",
    "// 2. Add the nodes; these will do the work\n",
    "workflow.addNode(\"Researcher\", researchNode);\n",
    "workflow.addNode(\"ChartGenerator\", chartNode);\n",
    "workflow.addNode(\"call_tool\", toolNode)\n",
    "\n",
    "// 3. Define the edges. We will define both regular and conditional ones\n",
    "// After a worker completes, report to supervisor\n",
    "workflow.addConditionalEdges(\n",
    "    \"Researcher\",\n",
    "    router,\n",
    "    {\n",
    "        // We will transition to the other agent\n",
    "        continue: \"ChartGenerator\", \n",
    "        call_tool: \"call_tool\", \n",
    "        end: END,\n",
    "    },\n",
    ")\n",
    "workflow.addConditionalEdges(\n",
    "    \"ChartGenerator\",\n",
    "    router,\n",
    "    {\n",
    "        // We will transition to the other agent\n",
    "        continue: \"Researcher\",\n",
    "        call_tool: \"call_tool\",\n",
    "        end: END,\n",
    "    },\n",
    ")\n",
    "workflow.addConditionalEdges(\n",
    "    \"call_tool\",\n",
    "    // Each agent node updates the 'sender' field\n",
    "    // the tool calling node does not, meaning\n",
    "    // this edge will route back to the original agent\n",
    "    // who invoked the tool\n",
    "    (x) => x.sender,\n",
    "    {\n",
    "        Researcher: \"Researcher\",\n",
    "        ChartGenerator: \"ChartGenerator\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.setEntryPoint(\"Researcher\");\n",
    "const graph = workflow.compile();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9447e7-9ab6-43eb-8ae6-9b52f8ba8425",
   "metadata": {},
   "source": [
    "## Invoke\n",
    "\n",
    "With the graph created, you can invoke it! Let's have it chart some stats for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3264bf5-19d9-4f36-af7c-e189d0d9e82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  Researcher: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: { content: \u001b[32m\"\"\u001b[39m, additional_kwargs: \u001b[36m[Object]\u001b[39m },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m\"\"\u001b[39m,\n",
      "        name: \u001b[90mundefined\u001b[39m,\n",
      "        additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[36m[Array]\u001b[39m }\n",
      "      }\n",
      "    ],\n",
      "    sender: \u001b[32m\"Researcher\"\u001b[39m\n",
      "  }\n",
      "}\n",
      "----\n",
      "{\n",
      "  call_tool: {\n",
      "    messages: [\n",
      "      ToolMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[32m'tavily_search_results_json response: [{\"title\":\"Gross Domestic Product | U.S. Bureau of Economic Ana'\u001b[39m... 2219 more characters,\n",
      "          name: \u001b[32m\"tavily_search_results_json\"\u001b[39m,\n",
      "          tool_call_id: \u001b[32m\"call_GcK7p2SrVatmACES3oq4D8SO\"\u001b[39m,\n",
      "          additional_kwargs: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m'tavily_search_results_json response: [{\"title\":\"Gross Domestic Product | U.S. Bureau of Economic Ana'\u001b[39m... 2219 more characters,\n",
      "        name: \u001b[32m\"tavily_search_results_json\"\u001b[39m,\n",
      "        additional_kwargs: {},\n",
      "        tool_call_id: \u001b[32m\"call_GcK7p2SrVatmACES3oq4D8SO\"\u001b[39m\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "----\n",
      "{\n",
      "  Researcher: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[32m\"The results from the search provide some general information on the United States GDP growth rates a\"\u001b[39m... 639 more characters,\n",
      "          additional_kwargs: \u001b[36m[Object]\u001b[39m\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m\"The results from the search provide some general information on the United States GDP growth rates a\"\u001b[39m... 639 more characters,\n",
      "        name: \u001b[90mundefined\u001b[39m,\n",
      "        additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[36m[Array]\u001b[39m }\n",
      "      }\n",
      "    ],\n",
      "    sender: \u001b[32m\"Researcher\"\u001b[39m\n",
      "  }\n",
      "}\n",
      "----\n",
      "{\n",
      "  call_tool: {\n",
      "    messages: [\n",
      "      ToolMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[32m'tavily_search_results_json response: [{\"title\":\"Gross Domestic Product | U.S. Bureau of Economic Ana'\u001b[39m... 2371 more characters,\n",
      "          name: \u001b[32m\"tavily_search_results_json\"\u001b[39m,\n",
      "          tool_call_id: \u001b[32m\"call_nUfFEk4TdfuJQJMInIAX2E1k\"\u001b[39m,\n",
      "          additional_kwargs: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m'tavily_search_results_json response: [{\"title\":\"Gross Domestic Product | U.S. Bureau of Economic Ana'\u001b[39m... 2371 more characters,\n",
      "        name: \u001b[32m\"tavily_search_results_json\"\u001b[39m,\n",
      "        additional_kwargs: {},\n",
      "        tool_call_id: \u001b[32m\"call_nUfFEk4TdfuJQJMInIAX2E1k\"\u001b[39m\n",
      "      },\n",
      "      ToolMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[32m'tavily_search_results_json response: [{\"title\":\"The 2023 U.S. economy, in charts - CNBC\",\"url\":\"http'\u001b[39m... 3050 more characters,\n",
      "          name: \u001b[32m\"tavily_search_results_json\"\u001b[39m,\n",
      "          tool_call_id: \u001b[32m\"call_lYRZyLulTbfFQA7MmbEDsZjb\"\u001b[39m,\n",
      "          additional_kwargs: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m'tavily_search_results_json response: [{\"title\":\"The 2023 U.S. economy, in charts - CNBC\",\"url\":\"http'\u001b[39m... 3050 more characters,\n",
      "        name: \u001b[32m\"tavily_search_results_json\"\u001b[39m,\n",
      "        additional_kwargs: {},\n",
      "        tool_call_id: \u001b[32m\"call_lYRZyLulTbfFQA7MmbEDsZjb\"\u001b[39m\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "----\n",
      "{\n",
      "  Researcher: {\n",
      "    messages: [\n",
      "      HumanMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"From the search results, we can gather the following data about the US GDP over the past 3 years:\\n\"\u001b[39m +\n",
      "            \u001b[32m\"\\n\"\u001b[39m +\n",
      "            \u001b[32m\"-\"\u001b[39m... 1347 more characters,\n",
      "          name: \u001b[32m\"Researcher\"\u001b[39m,\n",
      "          additional_kwargs: \u001b[36m[Object]\u001b[39m\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m\"From the search results, we can gather the following data about the US GDP over the past 3 years:\\n\"\u001b[39m +\n",
      "          \u001b[32m\"\\n\"\u001b[39m +\n",
      "          \u001b[32m\"-\"\u001b[39m... 1347 more characters,\n",
      "        name: \u001b[32m\"Researcher\"\u001b[39m,\n",
      "        additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m }\n",
      "      }\n",
      "    ],\n",
      "    sender: \u001b[32m\"Researcher\"\u001b[39m\n",
      "  }\n",
      "}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "const streamResults = await graph.stream(\n",
    "  {\n",
    "    messages: [\n",
    "      new HumanMessage({\n",
    "        content:\n",
    "          \"Generate a bar chart of the US gdp over the past 3 years.\",\n",
    "      }),\n",
    "    ],\n",
    "  },\n",
    "  { recursionLimit: 150 }\n",
    ");\n",
    "for await (const output of await streamResults) {\n",
    "  if (!output?.__end__) {\n",
    "    console.log(output);\n",
    "    console.log(\"----\");\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de22e4f-54b0-45ca-bcf8-1f3409e4d9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
