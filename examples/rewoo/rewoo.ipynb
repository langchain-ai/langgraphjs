{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1523e3ff",
   "metadata": {},
   "source": [
    "# Reasoning without Observation\n",
    "\n",
    "In [ReWOO](https://arxiv.org/abs/2305.18323), Xu, et. al, propose an agent that\n",
    "combines a multi-step planner and variable substitution for effective tool use.\n",
    "It was designed to improve on the ReACT-style agent architecture in the\n",
    "following ways:\n",
    "\n",
    "1. Reduce token consumption and execution time by generating the full chain of\n",
    "   tools used in a single pass. (_ReACT-style agent architecture requires many\n",
    "   LLM calls with redundant prefixes (since the system prompt and previous steps\n",
    "   are provided to the LLM for each reasoning step_)\n",
    "2. Simplify the fine-tuning process. Since the planning data doesn't depend on\n",
    "   the outputs of the tool, models can be fine-tuned without actually invoking\n",
    "   the tools (in theory).\n",
    "\n",
    "The following diagram outlines ReWOO's overall computation graph:\n",
    "\n",
    "![ReWoo Diagram](./img/rewoo.png)\n",
    "\n",
    "ReWOO is made of 3 modules:\n",
    "\n",
    "1. ðŸ§ **Planner**: Generate the plan in the following format:\n",
    "\n",
    "```text\n",
    "Plan: <reasoning>\n",
    "#E1 = Tool[argument for tool]\n",
    "Plan: <reasoning>\n",
    "#E2 = Tool[argument for tool with #E1 variable substitution]\n",
    "...\n",
    "```\n",
    "\n",
    "3. **Worker**: executes the tool with the provided arguments.\n",
    "4. ðŸ§ **Solver**: generates the answer for the initial task based on the tool\n",
    "   observations.\n",
    "\n",
    "The modules with a ðŸ§  emoji depend on an LLM call. Notice that we avoid\n",
    "redundant calls to the planner LLM by using variable substitution.\n",
    "\n",
    "In this example, each module is represented by a LangGraph node. The end result\n",
    "will leave a trace that looks\n",
    "[like this one](https://smith.langchain.com/public/39dbdcf8-fbcc-4479-8e28-15377ca5e653/r).\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017dc2f7",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "\n",
    "For this example, we will provide the agent with a Tavily search engine tool.\n",
    "You can get an API key [here](https://app.tavily.com/sign-in) or replace with a\n",
    "free tool option (e.g.,\n",
    "[duck duck go search](https://python.langchain.com/docs/integrations/tools/ddg)).\n",
    "\n",
    "For this notebook, you should add a `.env` file at the root of the repo with\n",
    "`TAVILY_API_KEY`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4184f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import \"dotenv/config\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73082b",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "```bash\n",
    "npm install langchain @langchain/community @langchain/openai @langchain/core\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e1e4a",
   "metadata": {},
   "source": [
    "**Graph State**: In LangGraph, every node updates a shared graph state. The\n",
    "state is the input to any node whenever it is invoked.\n",
    "\n",
    "Below, we will define a state object to contain the task, plan, steps, and other\n",
    "variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ff6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { Annotation } from \"@langchain/langgraph\";\n",
    "\n",
    "const GraphState = Annotation.Root({\n",
    "  task: Annotation<string>({\n",
    "    reducer: (x, y) => (y ?? x),\n",
    "    default: () => \"\",\n",
    "  }),\n",
    "  planString: Annotation<string>({\n",
    "    reducer: (x, y) => (y ?? x),\n",
    "    default: () => \"\",\n",
    "  }),\n",
    "  steps: Annotation<string[][]>({\n",
    "    reducer: (x, y) => x.concat(y),\n",
    "    default: () => [],\n",
    "  }),\n",
    "  results: Annotation<Record<string, any>>({\n",
    "    reducer: (x, y) => ({ ...x, ...y }),\n",
    "    default: () => ({}),\n",
    "  }),\n",
    "  result: Annotation<string>({\n",
    "    reducer: (x, y) => (y ?? x),\n",
    "    default: () => \"\",\n",
    "  }),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546316c",
   "metadata": {},
   "source": [
    "## 1. Planner\n",
    "\n",
    "The planner prompts an LLM to generate a plan in the form of a task list. The\n",
    "arguments to each task are strings that may contain special variables\n",
    "(`#E{{0-9}}+`) that are used for variable substitution from other task results.\n",
    "\n",
    "![ReWOO workflow](./img/rewoo-paper-workflow.png)\n",
    "\n",
    "Our example agent will have two tools:\n",
    "\n",
    "1. Google - a search engine (in this case Tavily)\n",
    "2. LLM - an LLM call to reason about previous outputs.\n",
    "\n",
    "The LLM tool receives less of the prompt context and so can be more\n",
    "token-efficient than the ReACT paradigm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9cc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "  model: \"gpt-4o\",\n",
    "  temperature: 0,\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7bd03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-9z88bDgCFkpWbYitlBSkuEaUU0YA2\",\n",
      "  \"content\": \"Plan: Identify the winner of the 2023 Australian Open.\\n#E1 = Google[\\\"winner of the 2023 Australian Open\\\"]\\n\\nPlan: Find the hometown of the winner identified in #E1.\\n#E2 = Google[\\\"hometown of #E1\\\"]\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 55,\n",
      "      \"promptTokens\": 438,\n",
      "      \"totalTokens\": 493\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"system_fingerprint\": \"fp_3aa7262c27\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 438,\n",
      "    \"output_tokens\": 55,\n",
      "    \"total_tokens\": 493\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const template =\n",
    "  `For the following task, make plans that can solve the problem step by step. For each plan, indicate\n",
    "which external tool together with tool input to retrieve evidence. You can store the evidence into a \n",
    "variable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\n",
    "\n",
    "Tools can be one of the following:\n",
    "(1) Google[input]: Worker that searches results from Google. Useful when you need to find short\n",
    "and succinct answers about a specific topic. The input should be a search query.\n",
    "(2) LLM[input]: A pre-trained LLM like yourself. Useful when you need to act with general \n",
    "world knowledge and common sense. Prioritize it when you are confident in solving the problem\n",
    "yourself. Input can be any instruction.\n",
    "\n",
    "For example,\n",
    "Task: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x \n",
    "hours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours \n",
    "less than Toby. How many hours did Rebecca work? \n",
    "Plan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve with Wolfram Alpha.\n",
    "#E1 = WolframAlpha[Solve x + (2x - 10) + ((2x - 10) - 8) = 157]\n",
    "Plan: Find out the number of hours Thomas worked.\n",
    "#E2 = LLM[What is x, given #E1]\n",
    "Plan: Calculate the number of hours Rebecca worked.\n",
    "#E3 = Calculator[(2 * #E2 - 10) - 8]\n",
    "\n",
    "Important!\n",
    "Variables/results MUST be referenced using the # symbol!\n",
    "The plan will be executed as a program, so no coreference resolution apart from naive variable replacement is allowed.\n",
    "The ONLY way for steps to share context is by including #E<step> within the arguments of the tool.\n",
    "\n",
    "Begin! \n",
    "Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
    "\n",
    "Task: {task}`;\n",
    "\n",
    "const promptTemplate = ChatPromptTemplate.fromMessages([[\"human\", template]]);\n",
    "\n",
    "const planner = promptTemplate.pipe(model);\n",
    "\n",
    "const task = \"what is the hometown of the winner of the 2023 australian open?\";\n",
    "await planner.invoke({ task });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4700cc",
   "metadata": {},
   "source": [
    "#### Planner Node\n",
    "\n",
    "To connect the planner to our graph, we will create a `getPlan` node that\n",
    "accepts the `ReWOO` state and returns with a state update for the `steps` and\n",
    "`planString` fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a058cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableConfig } from \"@langchain/core/runnables\";\n",
    "\n",
    "const regexPattern = new RegExp(\n",
    "  \"Plan\\\\s*\\\\d*:\\\\s*([^#]+)\\\\s*(#E\\\\d+)\\\\s*=\\\\s*(\\\\w+)\\\\s*\\\\[([^\\\\]]+)\\\\]\",\n",
    "  \"g\",\n",
    ");\n",
    "\n",
    "async function getPlan(state: typeof GraphState.State, config?: RunnableConfig) {\n",
    "  console.log(\"---GET PLAN---\");\n",
    "  const task = state.task;\n",
    "  const result = await planner.invoke({ task }, config);\n",
    "  // Find all matches in the sample text.\n",
    "  const matches = result.content.toString().matchAll(regexPattern);\n",
    "  let steps: string[][] = [];\n",
    "  for (const match of matches) {\n",
    "    const item = [match[1], match[2], match[3], match[4], match[0]];\n",
    "    if (item.some((i) => i === undefined)) {\n",
    "      throw new Error(\"Invalid match\");\n",
    "    }\n",
    "    steps.push(item as string[]);\n",
    "  }\n",
    "  return {\n",
    "    steps,\n",
    "    planString: result.content.toString(),\n",
    "  };\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b18588",
   "metadata": {},
   "source": [
    "## 2. Executor\n",
    "\n",
    "The executor receives the plan and executes the tools in sequence.\n",
    "\n",
    "Below, instantiate the search engine and define the tools execution node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a33c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n",
    "\n",
    "const search = new TavilySearchResults();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d49a2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "const _getCurrentTask = (state: typeof GraphState.State) => {\n",
    "  console.log(\"_getCurrentTask\", state);\n",
    "  if (!state.results) {\n",
    "    return 1;\n",
    "  }\n",
    "  if (Object.entries(state.results).length === state.steps.length) {\n",
    "    return null;\n",
    "  }\n",
    "  return Object.entries(state.results).length + 1;\n",
    "};\n",
    "\n",
    "const _parseResult = (input: unknown) => {\n",
    "  if (typeof input === \"string\") {\n",
    "    const parsedInput = JSON.parse(input);\n",
    "    if (Array.isArray(parsedInput) && \"content\" in parsedInput[0]) {\n",
    "      // This means it is a tool result.\n",
    "      return parsedInput.map(({ content }) => content).join(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  if (input && typeof input === \"object\" && \"content\" in input) {\n",
    "    // If it's not a tool, we know it's an LLM result.\n",
    "    const { content } = input;\n",
    "    return content;\n",
    "  }\n",
    "  throw new Error(\"Invalid input received\");\n",
    "};\n",
    "\n",
    "async function toolExecution(state: typeof GraphState.State, config?: RunnableConfig) {\n",
    "  console.log(\"---EXECUTE TOOL---\");\n",
    "  const _step = _getCurrentTask(state);\n",
    "  if (_step === null) {\n",
    "    throw new Error(\"No current task found\");\n",
    "  }\n",
    "  const [_, stepName, tool, toolInputTemplate] = state.steps[_step - 1];\n",
    "  let toolInput = toolInputTemplate;\n",
    "  const _results = state.results || {};\n",
    "  for (const [k, v] of Object.entries(_results)) {\n",
    "    toolInput = toolInput.replace(k, v);\n",
    "  }\n",
    "  let result;\n",
    "  if (tool === \"Google\") {\n",
    "    result = await search.invoke(toolInput, config);\n",
    "  } else if (tool === \"LLM\") {\n",
    "    result = await model.invoke(toolInput, config);\n",
    "  } else {\n",
    "    throw new Error(\"Invalid tool specified\");\n",
    "  }\n",
    "  _results[stepName] = JSON.stringify(_parseResult(result), null, 2);\n",
    "  return { results: _results };\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995406a",
   "metadata": {},
   "source": [
    "## 3. Solver\n",
    "\n",
    "The solver receives the full plan and generates the final response based on the\n",
    "responses of the tool calls from the worker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea68d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "const solvePrompt = ChatPromptTemplate.fromTemplate(\n",
    "  `Solve the following task or problem. To solve the problem, we have made step-by-step Plan and\n",
    "retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might\n",
    "contain irrelevant information.\n",
    "\n",
    "{plan}\n",
    "\n",
    "Now solve the question or task according to provided Evidence above. Respond with the answer\n",
    "directly with no extra words.\n",
    "\n",
    "Task: {task}\n",
    "Response:`,\n",
    ");\n",
    "\n",
    "async function solve(state: typeof GraphState.State, config?: RunnableConfig) {\n",
    "  console.log(\"---SOLVE---\");\n",
    "  let plan = \"\";\n",
    "  const _results = state.results || {};\n",
    "  for (let [_plan, stepName, tool, toolInput] of state.steps) {\n",
    "    for (const [k, v] of Object.entries(_results)) {\n",
    "      toolInput = toolInput.replace(k, v);\n",
    "    }\n",
    "    plan += `Plan: ${_plan}\\n${stepName} = ${tool}[${toolInput}]\\n`;\n",
    "  }\n",
    "  const model = new ChatOpenAI({\n",
    "    temperature: 0,\n",
    "    model: \"gpt-4o\",\n",
    "  });\n",
    "  const result = await solvePrompt\n",
    "    .pipe(model)\n",
    "    .invoke({ plan, task: state.task }, config);\n",
    "  return {\n",
    "    result: result.content.toString(),\n",
    "  };\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba164af7",
   "metadata": {},
   "source": [
    "## 4. Define Graph\n",
    "\n",
    "Our graph defines the workflow. Each of the planner, tool executor, and solver\n",
    "modules are added as nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f69da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, START, StateGraph } from \"@langchain/langgraph\";\n",
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "\n",
    "const _route = (state: typeof GraphState.State) => {\n",
    "  console.log(\"---ROUTE TASK---\");\n",
    "  const _step = _getCurrentTask(state);\n",
    "  if (_step === null) {\n",
    "    // We have executed all tasks\n",
    "    return \"solve\";\n",
    "  }\n",
    "  // We are still executing tasks, loop back to the \"tool\" node\n",
    "  return \"tool\";\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph(GraphState)\n",
    "  .addNode(\"plan\", getPlan)\n",
    "  .addNode(\"tool\", toolExecution)\n",
    "  .addNode(\"solve\", solve)\n",
    "  .addEdge(\"plan\", \"tool\")\n",
    "  .addEdge(\"solve\", END)\n",
    "  .addConditionalEdges(\"tool\", _route)\n",
    "  .addEdge(START, \"plan\");\n",
    "\n",
    "// Compile\n",
    "const app = workflow.compile({ checkpointer: new MemorySaver() });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea7a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GET PLAN---\n",
      "{\n",
      "  plan: {\n",
      "    planString: 'Plan: Identify the winner of the 2023 Australian Open.\\n' +\n",
      "      '#E1 = Google[\"winner of the 2023 Australian Open\"]\\n' +\n",
      "      '\\n' +\n",
      "      'Plan: Find the hometown of the winner identified in #E1.\\n' +\n",
      "      '#E2 = Google[\"hometown of #E1\"]',\n",
      "    steps: [ [Array] ]\n",
      "  }\n",
      "}\n",
      "-----\n",
      "---EXECUTE TOOL---\n",
      "_getCurrentTask {\n",
      "  task: 'what is the hometown of the winner of the 2023 australian open?',\n",
      "  planString: 'Plan: Identify the winner of the 2023 Australian Open.\\n' +\n",
      "    '#E1 = Google[\"winner of the 2023 Australian Open\"]\\n' +\n",
      "    '\\n' +\n",
      "    'Plan: Find the hometown of the winner identified in #E1.\\n' +\n",
      "    '#E2 = Google[\"hometown of #E1\"]',\n",
      "  steps: [\n",
      "    [\n",
      "      'Identify the winner of the 2023 Australian Open.\\n',\n",
      "      '#E1',\n",
      "      'Google',\n",
      "      '\"winner of the 2023 Australian Open\"',\n",
      "      'Plan: Identify the winner of the 2023 Australian Open.\\n' +\n",
      "        '#E1 = Google[\"winner of the 2023 Australian Open\"]'\n",
      "    ]\n",
      "  ],\n",
      "  results: {},\n",
      "  result: ''\n",
      "}\n",
      "---ROUTE TASK---\n",
      "_getCurrentTask {\n",
      "  task: 'what is the hometown of the winner of the 2023 australian open?',\n",
      "  planString: 'Plan: Identify the winner of the 2023 Australian Open.\\n' +\n",
      "    '#E1 = Google[\"winner of the 2023 Australian Open\"]\\n' +\n",
      "    '\\n' +\n",
      "    'Plan: Find the hometown of the winner identified in #E1.\\n' +\n",
      "    '#E2 = Google[\"hometown of #E1\"]',\n",
      "  steps: [\n",
      "    [\n",
      "      'Identify the winner of the 2023 Australian Open.\\n',\n",
      "      '#E1',\n",
      "      'Google',\n",
      "      '\"winner of the 2023 Australian Open\"',\n",
      "      'Plan: Identify the winner of the 2023 Australian Open.\\n' +\n",
      "        '#E1 = Google[\"winner of the 2023 Australian Open\"]'\n",
      "    ]\n",
      "  ],\n",
      "  results: {\n",
      "    '#E1': `\"A one-set shoot-off to decide the winner of the 2023 Australian Open. There could not have been a better script. SECOND SET (* denotes server) Sabalenka* 6-3 Rybakina - Wide second serve into the deuce court from Sabalenka and forehand return from Rybakina is long. Deep backhand crosscourt return from Rybakina draws a shot ball from Sabalenka ...\\\\nThe Crossword Solver found 30 answers to \\\\\"Tennis player Sabalenka, winner of the 2023 Australian Open\\\\\", 5 letters crossword clue. The Crossword Solver finds answers to classic crosswords and cryptic crossword puzzles. Enter the length or pattern for better results. Click the answer to find similar crossword clues .\\\\nAccording to bet365, Djokovic has even odds of winning the title at Melbourne Park -- meaning that the 35-year-old has a 50% chance of being the winner of the 2023 Australian Open men's singles ...\\\\nWe found 40 solutions for Tennis player Sabalenka, winner of the 2023 Australian Open. The top solutions are determined by popularity, ratings and frequency of searches. The most likely answer for the clue is ARYNA. How many solutions does Tennis player Sabalenka, winner of the 2023 Australian Open have?\"`\n",
      "  },\n",
      "  result: ''\n",
      "}\n",
      "{\n",
      "  tool: {\n",
      "    results: {\n",
      "      '#E1': `\"A one-set shoot-off to decide the winner of the 2023 Australian Open. There could not have been a better script. SECOND SET (* denotes server) Sabalenka* 6-3 Rybakina - Wide second serve into the deuce court from Sabalenka and forehand return from Rybakina is long. Deep backhand crosscourt return from Rybakina draws a shot ball from Sabalenka ...\\\\nThe Crossword Solver found 30 answers to \\\\\"Tennis player Sabalenka, winner of the 2023 Australian Open\\\\\", 5 letters crossword clue. The Crossword Solver finds answers to classic crosswords and cryptic crossword puzzles. Enter the length or pattern for better results. Click the answer to find similar crossword clues .\\\\nAccording to bet365, Djokovic has even odds of winning the title at Melbourne Park -- meaning that the 35-year-old has a 50% chance of being the winner of the 2023 Australian Open men's singles ...\\\\nWe found 40 solutions for Tennis player Sabalenka, winner of the 2023 Australian Open. The top solutions are determined by popularity, ratings and frequency of searches. The most likely answer for the clue is ARYNA. How many solutions does Tennis player Sabalenka, winner of the 2023 Australian Open have?\"`\n",
      "    }\n",
      "  }\n",
      "}\n",
      "-----\n",
      "---SOLVE---\n",
      "{ solve: { result: 'Belgrade, Serbia' } }\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "const threadConfig = { configurable: { thread_id: \"123\" } };\n",
    "let finalResult;\n",
    "const stream = await app.stream(\n",
    "  {\n",
    "    task: \"what is the hometown of the winner of the 2023 australian open?\",\n",
    "  },\n",
    "  threadConfig,\n",
    ");\n",
    "for await (const item of stream) {\n",
    "  console.log(item);\n",
    "  console.log(\"-----\");\n",
    "  finalResult = item;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef614005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgrade, Serbia\n"
     ]
    }
   ],
   "source": [
    "const snapshot = await app.getState(threadConfig);\n",
    "console.log(snapshot.values.result);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6291f",
   "metadata": {},
   "source": [
    "> #### See the LangSmith trace [here](https://smith.langchain.com/public/730ea730-d896-450e-ac85-3c7e228c79f4/r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0b424",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations on implementing ReWOO! Before you leave, I'll leave you with a\n",
    "couple limitations of the current implementation from the paper:\n",
    "\n",
    "1. If little context of the environment is available, the planner will be\n",
    "   ineffective in its tool use. This can typically be ameliorated through\n",
    "   few-shot prompting and/or fine-tuning.\n",
    "2. The tasks are still executed in sequence, meaning the total execution time is\n",
    "   impacted by _every_ tool call, not just the longest-running in a given step.\n",
    "\n",
    "```\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.16.1"
   }
  },
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
