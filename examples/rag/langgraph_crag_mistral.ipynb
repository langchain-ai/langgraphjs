{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrective RAG\n",
    "\n",
    "Self-reflection can enhance RAG, enabling correction of poor quality retrieval or generations.\n",
    "\n",
    "Several recent papers focus on this theme, but implementing the ideas can be tricky.\n",
    "\n",
    "Here we show how to implement self-reflective RAG using `Mistral` and `LangGraph`.\n",
    "\n",
    "We'll focus on ideas from one paper, `Corrective RAG (CRAG)` [here](https://arxiv.org/pdf/2401.15884.pdf).\n",
    "\n",
    "![Screenshot 2024-02-07 at 1.21.51 PM.png](attachment:a65940f9-5c51-4d7c-9ca1-ae576e4bb51a.png)\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Using APIs \n",
    "\n",
    "* Set `MISTRAL_API_KEY` and set up Subscription to activate it.\n",
    "* Set `TAVILY_API_KEY` to enable web search [here](https://app.tavily.com/sign-in).\n",
    "\n",
    "### Using CoLab \n",
    "\n",
    "* [Here](https://colab.research.google.com/drive/1U5OcwWjoXZSud30q4XOk1UlIJNjaD3kX?usp=sharing) is a link to a CoLab for this notebook. \n",
    "\n",
    "### Running Locally \n",
    "\n",
    "If you want to run this locally (e.g., on your laptop), use [Ollama](https://ollama.ai/library/mistral/tags):\n",
    "\n",
    "* Download [Ollama app](https://ollama.ai/).\n",
    "* Download a `Mistral` model e.g., `ollama pull mistral:7b-instruct`, from various Mistral versions [here](https://ollama.ai/library/mistral) and Mixtral versions [here](https://ollama.ai/library/mixtral) available.\n",
    "* Download LLaMA2 `ollama pull llama2:latest` to use Ollama embeddings.\n",
    "* Set flags indicating we will run locally and the Mistral model downloaded:\n",
    "  \n",
    "```\n",
    "run_local = \"Yes\"\n",
    "local_llm = \"mistral:7b-instruct\"\n",
    "```\n",
    "\n",
    "### Tracing \n",
    "\n",
    "* Optionally, use [LangSmith](https://docs.smith.langchain.com/) for tracing (shown at bottom) by setting: \n",
    "\n",
    "```\n",
    "export LANGCHAIN_TRACING_V2=true\n",
    "export LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "export LANGCHAIN_API_KEY=<your-api-key>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "First, let's index a popular blog post on agents using [Mistral embeddings](https://js.langchain.com/docs/integrations/text_embedding/mistralai).\n",
    "\n",
    "We'll use a local vectorstore, [Chroma](https://js.langchain.com/docs/integrations/vectorstores/chroma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "name": "typescript"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
