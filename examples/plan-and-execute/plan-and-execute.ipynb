{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan-and-Execute\n",
    "\n",
    "This notebook shows how to create a \"plan-and-execute\" style agent. This is heavily inspired by the [Plan-and-Solve](https://arxiv.org/abs/2305.04091) paper as well as the [Baby-AGI](https://github.com/yoheinakajima/babyagi) project.\n",
    "\n",
    "The core idea is to first come up with a multi-step plan, and then go through that plan one item at a time.\n",
    "After accomplishing a particular task, you can then revisit the plan and modify as appropriate.\n",
    "\n",
    "This compares to a typical [ReAct](https://arxiv.org/abs/2210.03629) style agent where you think one step at a time.\n",
    "The advantages of this \"plan-and-execute\" style agent are:\n",
    "\n",
    "1. Explicit long term planning (which even really strong LLMs can struggle with)\n",
    "2. Ability to use smaller/weaker models for the execution step, only using larger/better models for the planning step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to install the packages required.\n",
    "\n",
    "```bash\n",
    "npm install @langchain/langgraph @langchain/openai langchain\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set API keys for OpenAI (the LLM we will use) and Tavily (the search tool we will use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"OPENAI_API_KEY\", \"YOUR_API_KEY\")\n",
    "// Deno.env.set(\"TAVILY_API_KEY\", \"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can set API key for LangSmith tracing, which will give us best-in-class observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\")\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"YOUR_API_KEY\")\n",
    "// Deno.env.set(\"LANGCHAIN_PROJECT\", \"YOUR_PROJECT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "We will first define the tools we want to use. For this simple example, we will use a built-in search tool via Tavily. However, it is really easy to create your own tools - see documentation [here](https://js.langchain.com/docs/modules/agents/tools/dynamic) on how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n",
    "\n",
    "const tools = [new TavilySearchResults({ maxResults: 3 })];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Execution Agent\n",
    "\n",
    "Now we will create the execution agent we want to use to execute tasks. \n",
    "Note that for this example, we will be using the same execution agent for each task, but this doesn't HAVE to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING]: Importing from \"langchain/embeddings/fake\" is deprecated.\n",
      "\n",
      "Instead, please import from \"@langchain/core/utils/testing\".\n",
      "\n",
      "This will be mandatory after the next \"langchain\" minor version bump to 0.2.\n"
     ]
    }
   ],
   "source": [
    "import { pull } from \"langchain/hub\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { createOpenAIFunctionsAgent } from \"langchain/agents\";\n",
    "// Get the prompt to use - you can modify this!\n",
    "const prompt = await pull<ChatPromptTemplate>(\"hwchase17/openai-functions-agent\");\n",
    "// Choose the LLM that will drive the agent\n",
    "const llm = new ChatOpenAI({ modelName: \"gpt-4-0125-preview\" })\n",
    "// Construct the OpenAI Functions agent\n",
    "const agentRunnable = await createOpenAIFunctionsAgent({\n",
    "  llm, tools, prompt\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { createAgentExecutor } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const agentExecutor = createAgentExecutor({\n",
    "  agentRunnable,\n",
    "  tools,\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping write for channel chatHistory which has no readers\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot use 'in' operator to search for 'messageLog' in undefined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "TypeError: Cannot use 'in' operator to search for 'messageLog' in undefined",
      "    at file:///Users/bracesproul/Library/Caches/deno/npm/registry.npmjs.org/langchain/0.1.17/dist/agents/format_scratchpad/openai_functions.js:33:26",
      "    at Array.flatMap (<anonymous>)",
      "    at formatToOpenAIFunctionMessages (file:///Users/bracesproul/Library/Caches/deno/npm/registry.npmjs.org/langchain/0.1.17/dist/agents/format_scratchpad/openai_functions.js:32:18)",
      "    at RunnableLambda.agent_scratchpad [as func] (file:///Users/bracesproul/Library/Caches/deno/npm/registry.npmjs.org/langchain/0.1.17/dist/agents/openai_functions/index.js:229:42)",
      "    at RunnableLambda._invoke (file:///Users/bracesproul/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.25/dist/runnables/base.js:1074:33)",
      "    at RunnableLambda._callWithConfig (file:///Users/bracesproul/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.25/dist/runnables/base.js:183:33)",
      "    at eventLoopTick (ext:core/01_core.js:63:7)",
      "    at async file:///Users/bracesproul/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.25/dist/runnables/base.js:997:31",
      "    at async Promise.all (index 0)",
      "    at async RunnableMap.invoke (file:///Users/bracesproul/Library/Caches/deno/npm/registry.npmjs.org/@langchain/core/0.1.25/dist/runnables/base.js:996:13)"
     ]
    }
   ],
   "source": [
    "await agentExecutor.invoke({ input: \"who is the winnner of the us open\" });"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
