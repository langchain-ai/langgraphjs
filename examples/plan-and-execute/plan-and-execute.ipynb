{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f5011ae",
   "metadata": {},
   "source": [
    "# Plan-and-Execute\n",
    "\n",
    "This notebook shows how to create a \"plan-and-execute\" style agent. This is\n",
    "heavily inspired by the [Plan-and-Solve](https://arxiv.org/abs/2305.04091) paper\n",
    "as well as the [Baby-AGI](https://github.com/yoheinakajima/babyagi) project.\n",
    "\n",
    "The core idea is to first come up with a multi-step plan, and then go through\n",
    "that plan one item at a time. After accomplishing a particular task, you can\n",
    "then revisit the plan and modify as appropriate.\n",
    "\n",
    "This compares to a typical [ReAct](https://arxiv.org/abs/2210.03629) style agent\n",
    "where you think one step at a time. The advantages of this \"plan-and-execute\"\n",
    "style agent are:\n",
    "\n",
    "1. Explicit long term planning (which even really strong LLMs can struggle with)\n",
    "2. Ability to use smaller/weaker models for the execution step, only using\n",
    "   larger/better models for the planning step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d34776",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to install the packages required.\n",
    "\n",
    "```bash\n",
    "npm install @langchain/langgraph @langchain/openai langchain @langchain/core\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c72ec",
   "metadata": {},
   "source": [
    "Next, we need to set API keys for OpenAI (the LLM we will use) and Tavily (the\n",
    "search tool we will use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54485855",
   "metadata": {},
   "outputs": [],
   "source": [
    "// process.env.OPENAI_API_KEY = \"YOUR_API_KEY\"\n",
    "// process.env.TAVILY_API_KEY = \"YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c681775",
   "metadata": {},
   "source": [
    "Optionally, we can set API key for LangSmith tracing, which will give us\n",
    "best-in-class observability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57574807",
   "metadata": {},
   "outputs": [],
   "source": [
    "// process.env.LANGCHAIN_TRACING_V2 = \"true\"\n",
    "// process.env.LANGCHAIN_API_KEY = \"YOUR_API_KEY\"\n",
    "// process.env.LANGCHAIN_PROJECT = \"YOUR_PROJECT_NAME\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5c3b9",
   "metadata": {},
   "source": [
    "## Define the State\n",
    "\n",
    "Let's start by defining the state to track for this agent.\n",
    "\n",
    "First, we will need to track the current plan. Let's represent that as a list of\n",
    "strings.\n",
    "\n",
    "Next, we should track previously executed steps. Let's represent that as a list\n",
    "of tuples (these tuples will contain the step and then the result)\n",
    "\n",
    "Finally, we need to have some state to represent the final response as well as\n",
    "the original input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e49ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { Annotation } from \"@langchain/langgraph\";\n",
    "\n",
    "const PlanExecuteState = Annotation.Root({\n",
    "  input: Annotation<string>({\n",
    "    reducer: (x, y) => y ?? x ?? \"\",\n",
    "  }),\n",
    "  plan: Annotation<string[]>({\n",
    "    reducer: (x, y) => y ?? x ?? [],\n",
    "  }),\n",
    "  pastSteps: Annotation<[string, string][]>({\n",
    "    reducer: (x, y) => x.concat(y),\n",
    "  }),\n",
    "  response: Annotation<string>({\n",
    "    reducer: (x, y) => y ?? x,\n",
    "  }),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ee3fd",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "We will first define the tools we want to use. For this simple example, we will\n",
    "use a built-in search tool via Tavily. However, it is really easy to create your\n",
    "own tools - see documentation\n",
    "[here](https://js.langchain.com/docs/modules/agents/tools/dynamic) on how to do\n",
    "that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a13860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n",
    "\n",
    "const tools = [new TavilySearchResults({ maxResults: 3 })];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9aa1f",
   "metadata": {},
   "source": [
    "## Define our Execution Agent\n",
    "\n",
    "Now we will create the execution agent we want to use to execute tasks. Note\n",
    "that for this example, we will be using the same execution agent for each task,\n",
    "but this doesn't HAVE to be the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa0509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const agentExecutor = createReactAgent({\n",
    "  llm: new ChatOpenAI({ model: \"gpt-4o\" }),\n",
    "  tools: tools,\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d6c87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  messages: [\n",
       "    HumanMessage {\n",
       "      \"content\": \"who is the winner of the us open\",\n",
       "      \"additional_kwargs\": {},\n",
       "      \"response_metadata\": {}\n",
       "    },\n",
       "    AIMessage {\n",
       "      \"content\": \"\",\n",
       "      \"additional_kwargs\": {\n",
       "        \"tool_calls\": [\n",
       "          {\n",
       "            \"id\": \"call_c2N7Z1RX31qKJaSlpOJ0K7Wm\",\n",
       "            \"type\": \"function\",\n",
       "            \"function\": \"[Object]\"\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"response_metadata\": {\n",
       "        \"tokenUsage\": {\n",
       "          \"completionTokens\": 25,\n",
       "          \"promptTokens\": 80,\n",
       "          \"totalTokens\": 105\n",
       "        },\n",
       "        \"finish_reason\": \"tool_calls\"\n",
       "      },\n",
       "      \"tool_calls\": [\n",
       "        {\n",
       "          \"name\": \"tavily_search_results_json\",\n",
       "          \"args\": {\n",
       "            \"input\": \"winner of the US Open 2023\"\n",
       "          },\n",
       "          \"type\": \"tool_call\",\n",
       "          \"id\": \"call_c2N7Z1RX31qKJaSlpOJ0K7Wm\"\n",
       "        }\n",
       "      ],\n",
       "      \"invalid_tool_calls\": []\n",
       "    },\n",
       "    ToolMessage {\n",
       "      \"content\": \"[{\\\"title\\\":\\\"How Wyndham Clark won the 2023 U.S. Open over Rory McIlroy, Scottie ...\\\",\\\"url\\\":\\\"https://www.nytimes.com/athletic/live-blogs/us-open-leaderboard-live-scores-results-tee-times/mhPUFgLsyFfM/\\\",\\\"content\\\":\\\"Wyndham Clark is your 2023 U.S. Open champion. Wyndham Clark has won his first major championship, besting some of the best players in the world on Sunday at Los Angeles Country Club to claim the ...\\\",\\\"score\\\":0.9981324,\\\"raw_content\\\":null},{\\\"title\\\":\\\"Championship Point | Coco Gauff Wins Women's Singles Title | 2023 US Open\\\",\\\"url\\\":\\\"https://www.youtube.com/watch?v=rZ0XQWWFIAo\\\",\\\"content\\\":\\\"The moment Coco Gauff beat Aryna Sabalenka in the final of the 2023 US Open.Don't miss a moment of the US Open! Subscribe now: https://bit.ly/2Pdr81iThe 2023...\\\",\\\"score\\\":0.997459,\\\"raw_content\\\":null},{\\\"title\\\":\\\"2023 U.S. Open leaderboard: Wyndham Clark breaks through edging Rory ...\\\",\\\"url\\\":\\\"https://www.cbssports.com/golf/news/2023-u-s-open-leaderboard-wyndham-clark-breaks-through-edging-rory-mcilroy-for-first-major-championship/live/\\\",\\\"content\\\":\\\"College Pick'em\\\\nA Daily SportsLine Betting Podcast\\\\nNFL Playoff Time!\\\\n2023 U.S. Open leaderboard: Wyndham Clark breaks through edging Rory McIlroy for first major championship\\\\nClark beat one of the game's best clinching his second PGA Tour victory, both in the last six weeks\\\\nWith Rickie Fowler, Rory McIlroy and Scottie Scheffler atop the 2023 U.S. Open leaderboard, it appeared as if Los Angeles Country Club was set to crown a shining star as its national champion. After making birdie on No. 1 to momentarily pull even with the leaders, McIlroy was unable to take advantage of the short par-4 6th before leaving one on the table on the par-5 8th when his birdie putt from less than four feet failed to even touch the hole.\\\\n The shot on 14 was kind of the shot of the week for me -- to make a birdie there and grind it on the way in. The Champion Golfer of the Year now goes to defend the Claret Jug at Hoylake where he will relish the opportunity to put his creativity and imagination on display again.\\\\n Instead, the City of Angels saw a breakout performance from perhaps one of the game's rising stars as 29-year-old Wyndham Clark (-10) outlasted the veteran McIlroy (-9) to capture his first major championship and clinch his second professional victory.\\\\n\\\",\\\"score\\\":0.99586606,\\\"raw_content\\\":null}]\",\n",
       "      \"name\": \"tavily_search_results_json\",\n",
       "      \"additional_kwargs\": {},\n",
       "      \"response_metadata\": {},\n",
       "      \"tool_call_id\": \"call_c2N7Z1RX31qKJaSlpOJ0K7Wm\"\n",
       "    },\n",
       "    AIMessage {\n",
       "      \"content\": \"The winners of the 2023 US Open are:\\n\\n- **Men's Singles**: Wyndham Clark, who won his first major championship.\\n- **Women's Singles**: Coco Gauff, who defeated Aryna Sabalenka in the final.\",\n",
       "      \"additional_kwargs\": {},\n",
       "      \"response_metadata\": {\n",
       "        \"tokenUsage\": {\n",
       "          \"completionTokens\": 50,\n",
       "          \"promptTokens\": 717,\n",
       "          \"totalTokens\": 767\n",
       "        },\n",
       "        \"finish_reason\": \"stop\"\n",
       "      },\n",
       "      \"tool_calls\": [],\n",
       "      \"invalid_tool_calls\": []\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "await agentExecutor.invoke({\n",
    "  messages: [new HumanMessage(\"who is the winner of the us open\")],\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d42a9",
   "metadata": {},
   "source": [
    "## Planning Step\n",
    "\n",
    "Let's now think about creating the planning step. This will use function calling\n",
    "to create a plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b5b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "\n",
    "const plan = zodToJsonSchema(\n",
    "  z.object({\n",
    "    steps: z\n",
    "      .array(z.string())\n",
    "      .describe(\"different steps to follow, should be in sorted order\"),\n",
    "  }),\n",
    ");\n",
    "const planFunction = {\n",
    "  name: \"plan\",\n",
    "  description: \"This tool is used to plan the steps to follow\",\n",
    "  parameters: plan,\n",
    "};\n",
    "\n",
    "const planTool = {\n",
    "  type: \"function\",\n",
    "  function: planFunction,\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba67c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const plannerPrompt = ChatPromptTemplate.fromTemplate(\n",
    "  `For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "{objective}`,\n",
    ");\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "  modelName: \"gpt-4-0125-preview\",\n",
    "}).withStructuredOutput(planFunction);\n",
    "\n",
    "const planner = plannerPrompt.pipe(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53fec065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  steps: [\n",
       "    \u001b[32m\"Identify the current Australia Open winner.\"\u001b[39m,\n",
       "    \u001b[32m\"Research the hometown of the identified Australia Open winner.\"\u001b[39m,\n",
       "    \u001b[32m\"Report the hometown of the Australia Open winner.\"\u001b[39m\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await planner.invoke({\n",
    "  objective: \"what is the hometown of the current Australia open winner?\",\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a106e",
   "metadata": {},
   "source": [
    "## Re-Plan Step\n",
    "\n",
    "Now, let's create a step that re-does the plan based on the result of the\n",
    "previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb888fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { JsonOutputToolsParser } from \"@langchain/core/output_parsers/openai_tools\";\n",
    "\n",
    "const response = zodToJsonSchema(\n",
    "  z.object({\n",
    "    response: z.string().describe(\"Response to user.\"),\n",
    "  }),\n",
    ");\n",
    "\n",
    "const responseTool = {\n",
    "  type: \"function\",\n",
    "  function: {\n",
    "    name: \"response\",\n",
    "    description: \"Response to user.\",\n",
    "    parameters: response,\n",
    "  },\n",
    "};\n",
    "\n",
    "const replannerPrompt = ChatPromptTemplate.fromTemplate(\n",
    "  `For the given objective, come up with a simple step by step plan. \n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps.\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{pastSteps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that and use the 'response' function.\n",
    "Otherwise, fill out the plan.  \n",
    "Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.`,\n",
    ");\n",
    "\n",
    "const parser = new JsonOutputToolsParser();\n",
    "const replanner = replannerPrompt\n",
    "  .pipe(\n",
    "    new ChatOpenAI({ model: \"gpt-4o\" }).bindTools([\n",
    "      planTool,\n",
    "      responseTool,\n",
    "    ]),\n",
    "  )\n",
    "  .pipe(parser);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6ab14",
   "metadata": {},
   "source": [
    "## Create the Graph\n",
    "\n",
    "We can now create the graph!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef97a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, START, StateGraph } from \"@langchain/langgraph\";\n",
    "import { RunnableConfig } from \"@langchain/core/runnables\";\n",
    "\n",
    "async function executeStep(\n",
    "  state: typeof PlanExecuteState.State,\n",
    "  config?: RunnableConfig,\n",
    "): Promise<Partial<typeof PlanExecuteState.State>> {\n",
    "  const task = state.plan[0];\n",
    "  const input = {\n",
    "    messages: [new HumanMessage(task)],\n",
    "  };\n",
    "  const { messages } = await agentExecutor.invoke(input, config);\n",
    "\n",
    "  return {\n",
    "    pastSteps: [[task, messages[messages.length - 1].content.toString()]],\n",
    "    plan: state.plan.slice(1),\n",
    "  };\n",
    "}\n",
    "\n",
    "async function planStep(\n",
    "  state: typeof PlanExecuteState.State,\n",
    "): Promise<Partial<typeof PlanExecuteState.State>> {\n",
    "  const plan = await planner.invoke({ objective: state.input });\n",
    "  return { plan: plan.steps };\n",
    "}\n",
    "\n",
    "async function replanStep(\n",
    "  state: typeof PlanExecuteState.State,\n",
    "): Promise<Partial<typeof PlanExecuteState.State>> {\n",
    "  const output = await replanner.invoke({\n",
    "    input: state.input,\n",
    "    plan: state.plan.join(\"\\n\"),\n",
    "    pastSteps: state.pastSteps\n",
    "      .map(([step, result]) => `${step}: ${result}`)\n",
    "      .join(\"\\n\"),\n",
    "  });\n",
    "  const toolCall = output[0];\n",
    "\n",
    "  if (toolCall.type == \"response\") {\n",
    "    return { response: toolCall.args?.response };\n",
    "  }\n",
    "\n",
    "  return { plan: toolCall.args?.steps };\n",
    "}\n",
    "\n",
    "function shouldEnd(state: typeof PlanExecuteState.State) {\n",
    "  return state.response ? \"true\" : \"false\";\n",
    "}\n",
    "\n",
    "const workflow = new StateGraph(PlanExecuteState)\n",
    "  .addNode(\"planner\", planStep)\n",
    "  .addNode(\"agent\", executeStep)\n",
    "  .addNode(\"replan\", replanStep)\n",
    "  .addEdge(START, \"planner\")\n",
    "  .addEdge(\"planner\", \"agent\")\n",
    "  .addEdge(\"agent\", \"replan\")\n",
    "  .addConditionalEdges(\"replan\", shouldEnd, {\n",
    "    true: END,\n",
    "    false: \"agent\",\n",
    "  });\n",
    "\n",
    "// Finally, we compile it!\n",
    "// This compiles it into a LangChain Runnable,\n",
    "// meaning you can use it as you would any other runnable\n",
    "const app = workflow.compile();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4bb886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  planner: {\n",
      "    plan: [\n",
      "      \"Identify the winner of the 2024 Australian Open.\",\n",
      "      \"Research the hometown of the identified winner.\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  agent: {\n",
      "    plan: [ \"Research the hometown of the identified winner.\" ],\n",
      "    pastSteps: [\n",
      "      [\n",
      "        \"Identify the winner of the 2024 Australian Open.\",\n",
      "        \"The winner of the 2024 Australian Open men's singles title is Jannik Sinner of Italy. He achieved a \"... 175 more characters\n",
      "      ]\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{ replan: { plan: [ \"Research the hometown of Jannik Sinner.\" ] } }\n",
      "{\n",
      "  agent: {\n",
      "    plan: [],\n",
      "    pastSteps: [\n",
      "      [\n",
      "        \"Research the hometown of Jannik Sinner.\",\n",
      "        \"Jannik Sinner's hometown is Sexten (also known as Sesto) in northern Italy. Located in the Dolomites\"... 126 more characters\n",
      "      ]\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  replan: {\n",
      "    response: \"The objective has been achieved. The hometown of the 2024 Australian Open winner, Jannik Sinner, is \"... 47 more characters\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const config = { recursionLimit: 50 };\n",
    "const inputs = {\n",
    "  input: \"what is the hometown of the 2024 Australian open winner?\",\n",
    "};\n",
    "\n",
    "for await (const event of await app.stream(inputs, config)) {\n",
    "  console.log(event);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7f2be",
   "metadata": {},
   "source": [
    "> #### See the LangSmith trace [here](https://smith.langchain.com/public/5bb4f582-d111-417d-ba91-29bcced272bb/r).\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.16.1"
   }
  },
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
