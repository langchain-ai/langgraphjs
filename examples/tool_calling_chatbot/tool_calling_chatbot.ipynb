{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatCloudflareWorkersAI } from \"@langchain/cloudflare\";\n",
    "import { AIMessage, BaseMessage } from \"@langchain/core/messages\";\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { END, MessageGraph } from \"@langchain/langgraph\";\n",
    "\n",
    "const model = new ChatCloudflareWorkersAI({\n",
    "  model: \"@hf/thebloke/zephyr-7b-beta-awq\",\n",
    "  temperature: 0,\n",
    "});\n",
    "\n",
    "const graph = new MessageGraph();\n",
    "\n",
    "graph.addNode(\"initial_support_agent\", async (state: BaseMessage[]) => {\n",
    "  const SYSTEM_TEMPLATE = `You are a secretary for LangCorp, a company that sells computers.\n",
    "Be concise in your responses.\n",
    "You can help customers with basic questions, but if the customer is having a billing or technical problem,\n",
    "do not try to answer the question directly or gather information.\n",
    "Instead, immediately transfer them to the billing or technical team by asking the user to hold for a moment.`;\n",
    "\n",
    "  const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", SYSTEM_TEMPLATE],\n",
    "    new MessagesPlaceholder(\"messages\"),\n",
    "  ]);\n",
    "\n",
    "  return prompt.pipe(model).invoke({ messages: state });\n",
    "});\n",
    "\n",
    "graph.addNode(\"billing_agent\", async (state: BaseMessage[]) => {\n",
    "  const SYSTEM_TEMPLATE = `You are an expert billing support specialist for LangCorp, a company that sells computers.\n",
    "Help the user to the best of your ability, but be concise in your responses.\n",
    "You have the ability to transfer to another agent to authorize refunds.\n",
    "If you do, assume the other agent has all necessary information about the customer and their order.\n",
    "You do not need to ask the user for more information.`;\n",
    "\n",
    "  let messages = state;\n",
    "  if (messages[messages.length - 1]._getType() === \"ai\") {\n",
    "    messages = state.slice(0, -1);\n",
    "  }\n",
    "\n",
    "  const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", SYSTEM_TEMPLATE],\n",
    "    new MessagesPlaceholder(\"messages\"),\n",
    "  ]);\n",
    "  return prompt.pipe(model).invoke({ messages });\n",
    "});\n",
    "\n",
    "graph.addNode(\"refund_tool\", async (state) => {\n",
    "  return new AIMessage(\"Refund processed!\");\n",
    "});\n",
    "\n",
    "graph.addConditionalEdges(\"initial_support_agent\", async (state) => {\n",
    "  const mostRecentMessage = state[state.length - 1];\n",
    "  const SYSTEM_TEMPLATE = `Your job is to detect whether a customer support representative wants to send a user to a billing team, technical team, or neither.`;\n",
    "  const HUMAN_TEMPLATE = `The following text is a response from a customer support representative.\n",
    "Extract whether they are routing the user to a team related to billing, technical or neither.\n",
    "If they want to route the user to the billing team, respond only with the word \"BILLING\".\n",
    "If they want to route the user to the technical team, respond only with the word \"TECHNICAL\".\n",
    "Otherwise, respond only with the word \"NEITHER\".\n",
    "\n",
    "Here is the text:\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Remember, only respond with one word.`;\n",
    "  const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", SYSTEM_TEMPLATE],\n",
    "    [\"human\", HUMAN_TEMPLATE],\n",
    "  ]);\n",
    "  const chain = prompt\n",
    "    .pipe(model)\n",
    "    .pipe(new StringOutputParser());\n",
    "  const rawCategorization = await chain.invoke({ text: mostRecentMessage.content });\n",
    "  return rawCategorization.toLowerCase().replace(/\"/g, \"\");\n",
    "}, {\n",
    "  billing: \"billing_agent\",\n",
    "  technical: END,\n",
    "  neither: END\n",
    "});\n",
    "\n",
    "graph.addEdge(\"refund_tool\", END);\n",
    "\n",
    "graph.addConditionalEdges(\"billing_agent\", async (state) => {\n",
    "  const mostRecentMessage = state[state.length - 1];\n",
    "  const SYSTEM_TEMPLATE = `Your job is to detect whether a billing support representative wants to authorize a refund or reject it.`;\n",
    "  const HUMAN_TEMPLATE = `The following text is a response from a customer support representative.\n",
    "Extract whether they are authorizing a refund or not.\n",
    "If they want to refund the user, respond only with the word \"REFUND\".\n",
    "Otherwise, respond only with the word \"RESPOND\".\n",
    "\n",
    "Here is the text:\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Remember, only respond with one word.`;\n",
    "  const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", SYSTEM_TEMPLATE],\n",
    "    [\"human\", HUMAN_TEMPLATE],\n",
    "  ]);\n",
    "  const chain = prompt\n",
    "    .pipe(model)\n",
    "    .pipe(new StringOutputParser());\n",
    "  const response = await chain.invoke({ text: mostRecentMessage.content });\n",
    "  if (response.toLowerCase().replace(/\"/g, \"\") === \"refund\") {\n",
    "    return \"refund\";\n",
    "  } else {\n",
    "    return \"end\";\n",
    "  }\n",
    "}, {\n",
    "  refund: \"refund_tool\",\n",
    "  end: END\n",
    "});\n",
    "\n",
    "graph.setEntryPoint(\"initial_support_agent\");\n",
    "\n",
    "const runnable = graph.compile();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  initial_support_agent: AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"I'm sorry to hear that. Please hold while I transfer you to our billing department for further assis\"... 64 more characters,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"I'm sorry to hear that. Please hold while I transfer you to our billing department for further assis\"... 64 more characters,\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "}\n",
      "{\n",
      "  billing_agent: AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"I'm sorry to hear that. Please provide your order number so I can initiate the refund process. Our p\"... 381 more characters,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"I'm sorry to hear that. Please provide your order number so I can initiate the refund process. Our p\"... 381 more characters,\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "}\n",
      "{\n",
      "  __end__: [\n",
      "    HumanMessage {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: {\n",
      "        content: \"I've changed my mind and I want a refund for my computer!\",\n",
      "        additional_kwargs: {},\n",
      "        response_metadata: {}\n",
      "      },\n",
      "      lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "      content: \"I've changed my mind and I want a refund for my computer!\",\n",
      "      name: undefined,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    AIMessage {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: {\n",
      "        content: \"I'm sorry to hear that. Please hold while I transfer you to our billing department for further assis\"... 64 more characters,\n",
      "        additional_kwargs: {},\n",
      "        response_metadata: {}\n",
      "      },\n",
      "      lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "      content: \"I'm sorry to hear that. Please hold while I transfer you to our billing department for further assis\"... 64 more characters,\n",
      "      name: undefined,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    AIMessage {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: {\n",
      "        content: \"I'm sorry to hear that. Please provide your order number so I can initiate the refund process. Our p\"... 381 more characters,\n",
      "        additional_kwargs: {},\n",
      "        response_metadata: {}\n",
      "      },\n",
      "      lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "      content: \"I'm sorry to hear that. Please provide your order number so I can initiate the refund process. Our p\"... 381 more characters,\n",
      "      name: undefined,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const stream = await runnable.stream(\n",
    "  new HumanMessage(\"I've changed my mind and I want a refund for order #182818!\")\n",
    ");\n",
    "for await (const message of stream) {\n",
    "  console.log(message);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
