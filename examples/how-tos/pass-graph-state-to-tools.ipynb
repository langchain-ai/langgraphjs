{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pass graph state to tools\n",
    "\n",
    "Sometimes we need to pass in agent state to our tools. This type of stateful tools is useful when a tool's output is affected by past agent steps (e.g. if you're using a sub-agent as a tool, and want to pass the message history in to the sub-agent), or when a tool's input needs to be validated given context from past agent steps. \n",
    "\n",
    "In this guide we'll demonstrate how to create tools that take agent state as input.\n",
    "\n",
    "This is a special case of [passing runtime arguments to tools](https://python.langchain.com/v0.2/docs/how_to/tool_runtime/), which you can learn about in the LangChain docs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First we need to install the packages required\n",
    "\n",
    "```bash\n",
    "npm install @langchain/langgraph @langchain/openai\n",
    "```\n",
    "\n",
    "Next, we need to set API keys for OpenAI (the LLM we will use)\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=your-api-key\n",
    "```\n",
    "\n",
    "Optionally, we can set API key for [LangSmith tracing](https://smith.langchain.com/), which will give us best-in-class observability.\n",
    "\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\n",
    "export LANGCHAIN_API_KEY=your-api-key\n",
    "```\n",
    "\n",
    "## Defining the tools\n",
    "\n",
    "We'll want our tool to take graph state as an input, but we don't want the model to try to generate this input when calling the tool. In order to pass runtime values to our tools, we are going to wrap them in a factory function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { tool } from '@langchain/core/tools';\n",
    "import { z } from 'zod';\n",
    "import { Document } from '@langchain/core/documents';\n",
    "import { ChatOpenAI } from '@langchain/openai'\n",
    "import { ToolMessage } from '@langchain/core/messages';\n",
    "import { BaseMessage } from '@langchain/core/messages';\n",
    "\n",
    "let model = new ChatOpenAI({ model: \"gpt-4o\" })\n",
    "\n",
    "const cite = z.object({\n",
    "  indexes: z.array(z.number()).describe(\"Return the index(es) of the documents that justify the claim\"),\n",
    "});\n",
    "\n",
    "function generateTools(messages: BaseMessage[]) {\n",
    "  const getContext = tool(() => {    \n",
    "      const docs: Document[] = [\n",
    "          {\n",
    "              pageContent: \"FooBar company just raised 1 Billion dollars!\",\n",
    "              metadata: { source: \"twitter\" }\n",
    "          },\n",
    "          {\n",
    "              pageContent: \"FooBar company is now only hiring AI's\",\n",
    "              metadata: { source: \"twitter\" }\n",
    "          },\n",
    "          {\n",
    "              pageContent: \"FooBar company was founded in 2019\",\n",
    "              metadata: { source: \"wikipedia\" }\n",
    "          },\n",
    "          {\n",
    "              pageContent: \"FooBar company makes friendly robots\",\n",
    "              metadata: { source: \"wikipedia\" }\n",
    "          }\n",
    "      ];\n",
    "      // Join the page content of all documents with \"\\n\\n\"\n",
    "      const joinedContent: string = docs.map(doc => doc.pageContent).join(\"\\n\\n\");\n",
    "  \n",
    "      return { joinedContent, docs };\n",
    "  }, {\n",
    "      name: 'get_context',\n",
    "      description: 'Get context on the question',\n",
    "      schema: z.object({\n",
    "          question: z.string().describe(\"The user question\"),\n",
    "      })\n",
    "  })\n",
    "  \n",
    "  const citeContextSources = tool(async (input) => {    \n",
    "    const docs: Document[] = [];\n",
    "  \n",
    "    // We get the potentially cited docs from past ToolMessages in our state.\n",
    "    for (const msg of messages) {\n",
    "        if ((msg as ToolMessage).name === \"get_context\") {\n",
    "            docs.push(...(msg as ToolMessage).artifact);\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    // Define the Cite interface\n",
    "    const structuredModel = model.withStructuredOutput(cite);\n",
    "  \n",
    "    // Create the system prompt and context\n",
    "    const system: string = `Which of the following documents best justifies the claim:\\n\\n${input.claim}`;\n",
    "    const context: string = docs.map((doc, i) => `Document ${i}:\\n${doc.pageContent}`).join(\"\\n\\n\");\n",
    "  \n",
    "    // Invoke the structured model to get the citation\n",
    "    const citation = await structuredModel.invoke([[\"system\", system], [\"human\", context]]);\n",
    "  \n",
    "    // Get the cited documents based on the indexes returned\n",
    "    const citedDocs: Document[] = citation.indexes.map(i => docs[i]);\n",
    "  \n",
    "    // Extract the sources from the cited documents\n",
    "    const sources: string = citedDocs.map(doc => doc.metadata.source).join(\", \");\n",
    "  \n",
    "    // Return the sources and cited documents\n",
    "    return { sources, citedDocs };\n",
    "  \n",
    "  }, {\n",
    "    name: 'cite_context_sources',\n",
    "    description: 'e which source a claim was based on.',\n",
    "    schema: z.object({\n",
    "        claim: z.string().describe(\"The claim that was made.\"),\n",
    "    })\n",
    "  })\n",
    "\n",
    "  return [getContext, citeContextSources];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the tool call schema, which is what is passed to the model for tool-calling, only `claim` is being passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  type: 'object',\n",
      "  properties: {\n",
      "    claim: { type: 'string', description: 'The claim that was made.' }\n",
      "  },\n",
      "  required: [ 'claim' ],\n",
      "  additionalProperties: false,\n",
      "  '$schema': 'http://json-schema.org/draft-07/schema#'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "\n",
    "let tools = generateTools([]);\n",
    "\n",
    "console.log(zodToJsonSchema(tools[1].schema));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the agent state\n",
    "\n",
    "For this example, the state we will track will just be a list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { Annotation } from \"@langchain/langgraph\";\n",
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const AgentState = Annotation.Root({\n",
    "  messages: Annotation<BaseMessage[]>({\n",
    "      reducer: (x, y) => x.concat(y),\n",
    "  }),\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the nodes\n",
    "\n",
    "We now need to define a few different nodes in our graph.\n",
    "\n",
    "1. The agent: responsible for deciding what (if any) actions to take.\n",
    "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
    "\n",
    "We will also need to define some edges.\n",
    "\n",
    "1. After the agent is called, we should either invoke the tool node or finish.\n",
    "2. After the tool node have been invoked, it should always go back to the agent to decide what to do next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, START, StateGraph, MemorySaver } from \"@langchain/langgraph\";\n",
    "import { AIMessage } from \"@langchain/core/messages\";\n",
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "\n",
    "const routeMessage = (state: typeof AgentState.State) => {\n",
    "  const { messages } = state;\n",
    "  const lastMessage = messages[messages.length - 1] as AIMessage;\n",
    "  // If no tools are called, we can finish (respond to the user)\n",
    "  if (!lastMessage?.tool_calls?.length) {\n",
    "    return END;\n",
    "  }\n",
    "  // Otherwise if there is, we continue and call the tools\n",
    "  return \"tools\";\n",
    "};\n",
    "\n",
    "const callModel = async (\n",
    "  state: typeof AgentState.State,\n",
    ") => {\n",
    "  // For versions of @langchain/core < 0.2.3, you must call `.stream()`\n",
    "  // and aggregate the message from chunks instead of calling `.invoke()`.\n",
    "  const { messages } = state;\n",
    "  const tools = generateTools(messages);\n",
    "  const modelWithTools = model.bindTools(tools);\n",
    "  const responseMessage = await modelWithTools.invoke(messages);\n",
    "  return { messages: [responseMessage] };\n",
    "};\n",
    "\n",
    "const toolNodeWithConfig = async (\n",
    "  state: typeof AgentState.State,\n",
    ") => {\n",
    "  // For versions of @langchain/core < 0.2.3, you must call `.stream()`\n",
    "  // and aggregate the message from chunks instead of calling `.invoke()`.\n",
    "  const tools = generateTools(state.messages);\n",
    "  const toolNodeWithConfig = new ToolNode(tools).bind({ configurable: {\"messages\": state.messages } })\n",
    "  return toolNodeWithConfig.invoke(state);\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph(AgentState)\n",
    "  .addNode(\"agent\", callModel)\n",
    "  .addNode(\"tools\", toolNodeWithConfig)\n",
    "  .addEdge(START, \"agent\")\n",
    "  .addConditionalEdges(\"agent\", routeMessage)\n",
    "  .addEdge(\"tools\", \"agent\");\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "\n",
    "const graph = workflow.compile({ checkpointer: memory });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it!\n",
    "\n",
    "Let's use our graph now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A21aF1YtWVeT3YYZbrZ5i1cusMKCX\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_NI6QZtisyFzebvxvRKLeAYmz\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 23,\n",
      "          \"promptTokens\": 96,\n",
      "          \"totalTokens\": 119\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_157b3831f5\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"get_context\",\n",
      "          \"args\": {\n",
      "            \"question\": \"What's the latest single news item about FooBar?\"\n",
      "          },\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_NI6QZtisyFzebvxvRKLeAYmz\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 96,\n",
      "        \"output_tokens\": 23,\n",
      "        \"total_tokens\": 119\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: tools\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    ToolMessage {\n",
      "      \"content\": \"{\\n  \\\"joinedContent\\\": \\\"FooBar company just raised 1 Billion dollars!\\\\n\\\\nFooBar company is now only hiring AI's\\\\n\\\\nFooBar company was founded in 2019\\\\n\\\\nFooBar company makes friendly robots\\\",\\n  \\\"docs\\\": [\\n    {\\n      \\\"pageContent\\\": \\\"FooBar company just raised 1 Billion dollars!\\\",\\n      \\\"metadata\\\": {\\n        \\\"source\\\": \\\"twitter\\\"\\n      }\\n    },\\n    {\\n      \\\"pageContent\\\": \\\"FooBar company is now only hiring AI's\\\",\\n      \\\"metadata\\\": {\\n        \\\"source\\\": \\\"twitter\\\"\\n      }\\n    },\\n    {\\n      \\\"pageContent\\\": \\\"FooBar company was founded in 2019\\\",\\n      \\\"metadata\\\": {\\n        \\\"source\\\": \\\"wikipedia\\\"\\n      }\\n    },\\n    {\\n      \\\"pageContent\\\": \\\"FooBar company makes friendly robots\\\",\\n      \\\"metadata\\\": {\\n        \\\"source\\\": \\\"wikipedia\\\"\\n      }\\n    }\\n  ]\\n}\",\n",
      "      \"name\": \"get_context\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_NI6QZtisyFzebvxvRKLeAYmz\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A21aGZP2nWMuXUIlxhvmTMiyqKHKl\",\n",
      "      \"content\": \"FooBar company just raised 1 Billion dollars!\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 11,\n",
      "          \"promptTokens\": 318,\n",
      "          \"totalTokens\": 329\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_157b3831f5\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 318,\n",
      "        \"output_tokens\": 11,\n",
      "        \"total_tokens\": 329\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let inputs = { messages: [{ role: \"user\", content: \"what's the latest single news item about FooBar? Please only return the news.\" }] };\n",
    "let config = {\"configurable\": {\"thread_id\": \"1\"}};\n",
    "let stream = await graph.stream(inputs, {\n",
    "  ...config\n",
    "});\n",
    "\n",
    "for await (\n",
    "  const chunk of stream\n",
    ") {\n",
    "  for (const [node, values] of Object.entries(chunk)) {\n",
    "    console.log(`Output from node: ${node}`);\n",
    "    console.log(\"---\");\n",
    "    console.log(values);\n",
    "    console.log(\"\\n====\\n\");\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify it can properly cite where it got the information from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A21aZ7uhxR2Z9t6KVmwGzPc0ezYhi\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_FyD5zbCjnoBbMvrRqLuJaM9h\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 25,\n",
      "          \"promptTokens\": 343,\n",
      "          \"totalTokens\": 368\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_157b3831f5\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"cite_context_sources\",\n",
      "          \"args\": {\n",
      "            \"claim\": \"FooBar company just raised 1 Billion dollars!\"\n",
      "          },\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_FyD5zbCjnoBbMvrRqLuJaM9h\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 343,\n",
      "        \"output_tokens\": 25,\n",
      "        \"total_tokens\": 368\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: tools\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    ToolMessage {\n",
      "      \"content\": \"Error: msg.artifact is not iterable (cannot read property undefined)\\n Please fix your mistakes.\",\n",
      "      \"name\": \"cite_context_sources\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_FyD5zbCjnoBbMvrRqLuJaM9h\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A21aaPFyWOxM3nhRTNEVeT4L5bZbp\",\n",
      "      \"content\": \"The information about FooBar company raising 1 billion dollars came from a Twitter source.\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 18,\n",
      "          \"promptTokens\": 396,\n",
      "          \"totalTokens\": 414\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_157b3831f5\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 396,\n",
      "        \"output_tokens\": 18,\n",
      "        \"total_tokens\": 414\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let inputs = { messages: [{ role: \"user\", content: \"where did you get this information?\" }] };\n",
    "let stream = await graph.stream(inputs, {\n",
    "  ...config\n",
    "});\n",
    "\n",
    "for await (\n",
    "  const chunk of stream\n",
    ") {\n",
    "  for (const [node, values] of Object.entries(chunk)) {\n",
    "    console.log(`Output from node: ${node}`);\n",
    "    console.log(\"---\");\n",
    "    console.log(values);\n",
    "    console.log(\"\\n====\\n\");\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the agent is able to properly cite that the information came from Twitter!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
