{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7240d5b5-9dac-4070-8a9e-2350fb01e0be",
   "metadata": {},
   "source": [
    "# How to share state between threads\n",
    "\n",
    "By default, state in a graph is scoped to that thread.\n",
    "LangGraph also allows you to specify a \"scope\" for a given key/value pair that exists between threads. This can be useful for storing information that is shared between threads. For instance, you may want to store information about a user's preferences expressed in one thread, and then use that information in another thread.\n",
    "\n",
    "In this notebook we will go through an example of how to construct and use such a graph.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install the required packages and set our API keys\n",
    "\n",
    "```bash\n",
    "npm install @langchain/openai @langchain/langgraph @langchain/core zod uuid\n",
    "```\n",
    "\n",
    "Then set your enviroment variables for OpenAI:\n",
    "\n",
    "```typescript\n",
    "process.env.OPENAI_API_KEY = \"your-openai-api-key\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6817d",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c550b5-1954-496b-8b9d-800361af17dc",
   "metadata": {},
   "source": [
    "## Create graph\n",
    "\n",
    "In this example we will create a graph that will let us store information about a user's preferences. We will do so by defining a state key that will be scoped to a `user_id`, and allowing the model to populate this field as it deems fit (by providing the model with a tool to save information about the user).\n",
    "\n",
    "    \n",
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">Typing shared state keys</p>\n",
    "    <p style=\"margin-top: 5px;\">\n",
    "        Shared state channels (keys) MUST be objects (see <code>info</code> channel in the AgentState example below)\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337ee88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from running graph with input \"hi\":\n",
      "{\n",
      "  messages: [\n",
      "    { role: 'user', content: 'hi' },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A78TYaGE5SR73sYVyztv1FN4A3WxD\",\n",
      "      \"content\": \"Hello! How can I assist you today?\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 10,\n",
      "          \"promptTokens\": 137,\n",
      "          \"totalTokens\": 147\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 137,\n",
      "        \"output_tokens\": 10,\n",
      "        \"total_tokens\": 147\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Result from running graph with input \"i like pepperoni pizza\":\n",
      "{\n",
      "  messages: [\n",
      "    { role: 'user', content: 'hi' },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A78TYaGE5SR73sYVyztv1FN4A3WxD\",\n",
      "      \"content\": \"Hello! How can I assist you today?\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 10,\n",
      "          \"promptTokens\": 137,\n",
      "          \"totalTokens\": 147\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": []\n",
      "    },\n",
      "    { role: 'user', content: 'i like pepperoni pizza' },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A78TZt7YOxzETGP0lBwoDKgIJBxhG\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_6QS9KOHEWRh1E0dJj17teVy1\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 23,\n",
      "          \"promptTokens\": 159,\n",
      "          \"totalTokens\": 182\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"Info\",\n",
      "          \"args\": {\n",
      "            \"fact\": \"The user likes pepperoni pizza\",\n",
      "            \"topic\": \"Food Preferences\"\n",
      "          },\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_6QS9KOHEWRh1E0dJj17teVy1\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 159,\n",
      "        \"output_tokens\": 23,\n",
      "        \"total_tokens\": 182\n",
      "      }\n",
      "    },\n",
      "    ToolMessage {\n",
      "      \"content\": \"Saved!\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_6QS9KOHEWRh1E0dJj17teVy1\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Result from running graph with input \"i also just moved to SF\":\n",
      "{\n",
      "  messages: [\n",
      "    { role: 'user', content: 'hi' },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A78TYaGE5SR73sYVyztv1FN4A3WxD\",\n",
      "      \"content\": \"Hello! How can I assist you today?\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 10,\n",
      "          \"promptTokens\": 137,\n",
      "          \"totalTokens\": 147\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": []\n",
      "    },\n",
      "    { role: 'user', content: 'i like pepperoni pizza' },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A78TZt7YOxzETGP0lBwoDKgIJBxhG\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_6QS9KOHEWRh1E0dJj17teVy1\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 23,\n",
      "          \"promptTokens\": 159,\n",
      "          \"totalTokens\": 182\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"Info\",\n",
      "          \"args\": {\n",
      "            \"fact\": \"The user likes pepperoni pizza\",\n",
      "            \"topic\": \"Food Preferences\"\n",
      "          },\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_6QS9KOHEWRh1E0dJj17teVy1\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": []\n",
      "    },\n",
      "    ToolMessage {\n",
      "      \"content\": \"Saved!\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_6QS9KOHEWRh1E0dJj17teVy1\"\n",
      "    },\n",
      "    { role: 'user', content: 'i also just moved to SF' },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-A78TazfkxUt04C5mcFu4aCV6D1tNZ\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_Pn7TvEXGs0jp9Ai2S1sZ1rSJ\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 22,\n",
      "          \"promptTokens\": 208,\n",
      "          \"totalTokens\": 230\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"Info\",\n",
      "          \"args\": {\n",
      "            \"fact\": \"The user just moved to SF\",\n",
      "            \"topic\": \"Location\"\n",
      "          },\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_Pn7TvEXGs0jp9Ai2S1sZ1rSJ\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 208,\n",
      "        \"output_tokens\": 22,\n",
      "        \"total_tokens\": 230\n",
      "      }\n",
      "    },\n",
      "    ToolMessage {\n",
      "      \"content\": \"Saved!\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_Pn7TvEXGs0jp9Ai2S1sZ1rSJ\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import { z } from \"zod\";\n",
    "import {\n",
    "  START,\n",
    "  END,\n",
    "  Annotation,\n",
    "  StateGraph,\n",
    "  MemoryStore,\n",
    "  SharedValue,\n",
    "  MemorySaver,\n",
    "} from \"@langchain/langgraph\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import {\n",
    "  type AIMessage,\n",
    "  type BaseMessage,\n",
    "  ToolMessage,\n",
    "} from \"@langchain/core/messages\";\n",
    "import { RunnableConfig } from \"@langchain/core/runnables\";\n",
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "\n",
    "const infoSchema = z.object({\n",
    "  fact: z.string().describe(\"The fact about the user\"),\n",
    "  topic: z.string().describe(\"The topic of the fact\"),\n",
    "});\n",
    "\n",
    "const AgentAnnotation = Annotation.Root({\n",
    "  messages: Annotation<BaseMessage[]>({\n",
    "    reducer: (a, b) => a.concat(b),\n",
    "    default: () => [],\n",
    "  }),\n",
    "  info: SharedValue.on(\"user_id\"),\n",
    "});\n",
    "\n",
    "const prompt = `You are helpful assistant.\n",
    "\n",
    "Here is what you know about the user:\n",
    "\n",
    "<info>\n",
    "{info}\n",
    "</info>\n",
    "\n",
    "Help out the user. If the user tells you any information about themselves, save the information using the \\`Info\\` tool.\n",
    "\n",
    "This means if the user provides any sort of fact about themselves, be it an opinion they have, a fact about themselves, etc. SAVE IT!\n",
    "`;\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "  model: \"gpt-4o\",\n",
    "  temperature: 0,\n",
    "}).bindTools([\n",
    "  {\n",
    "    name: \"Info\",\n",
    "    description: \"Save the information provided by the user\",\n",
    "    schema: infoSchema,\n",
    "  },\n",
    "]);\n",
    "\n",
    "const callModel = async (\n",
    "  state: typeof AgentAnnotation.State\n",
    "): Promise<Partial<typeof AgentAnnotation.State>> => {\n",
    "  const facts = Object.values(state.info).map((d) => d.fact);\n",
    "  const info = facts.join(\"\\n\");\n",
    "  const systemMsg = prompt.replace(\"{info}\", info);\n",
    "  const response = await model.invoke([\n",
    "    { role: \"system\", content: systemMsg },\n",
    "    ...state.messages,\n",
    "  ]);\n",
    "  return { messages: [response] };\n",
    "};\n",
    "\n",
    "const route = (state: typeof AgentAnnotation.State): string => {\n",
    "  const lastMessage = state.messages[state.messages.length - 1];\n",
    "  if (!(\"tool_calls\" in lastMessage)) {\n",
    "    throw new Error(\"Expected an AI message with tool calls.\");\n",
    "  }\n",
    "\n",
    "  return (lastMessage as AIMessage).tool_calls?.length ? \"update_memory\" : END;\n",
    "};\n",
    "\n",
    "const updateMemory = (\n",
    "  state: typeof AgentAnnotation.State\n",
    "): Partial<typeof AgentAnnotation.State> => {\n",
    "  const toolResponseMessages: ToolMessage[] = [];\n",
    "  const memories: Record<string, z.infer<typeof infoSchema>> = {};\n",
    "\n",
    "  const lastMessage = state.messages[state.messages.length - 1];\n",
    "  if (!(\"tool_calls\" in lastMessage)) {\n",
    "    throw new Error(\"Expected an AI message with tool calls.\");\n",
    "  }\n",
    "  const castLastMessage = lastMessage as AIMessage;\n",
    "\n",
    "  castLastMessage.tool_calls?.forEach((tc) => {\n",
    "    toolResponseMessages.push(\n",
    "      new ToolMessage({\n",
    "        content: \"Saved!\",\n",
    "        tool_call_id: tc.id as string,\n",
    "      })\n",
    "    );\n",
    "    memories[uuidv4()] = {\n",
    "      fact: tc.args.fact,\n",
    "      topic: tc.args.topic,\n",
    "    };\n",
    "  });\n",
    "\n",
    "  return { messages: toolResponseMessages, info: memories };\n",
    "};\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "const kv = new MemoryStore();\n",
    "\n",
    "const graph = new StateGraph(AgentAnnotation)\n",
    "  .addNode(\"call_model\", callModel)\n",
    "  .addNode(\"update_memory\", updateMemory)\n",
    "  .addEdge(\"update_memory\", END)\n",
    "  .addEdge(START, \"call_model\")\n",
    "  .addConditionalEdges(\"call_model\", route);\n",
    "\n",
    "const compiledGraph = graph.compile({\n",
    "  checkpointer: memory,\n",
    "  store: kv,\n",
    "});\n",
    "\n",
    "// Example usage:\n",
    "const config: RunnableConfig = {\n",
    "  configurable: { thread_id: \"1\", user_id: \"1\" },\n",
    "};\n",
    "\n",
    "const runGraph = async (input: string) => {\n",
    "  const result = await compiledGraph.invoke(\n",
    "    {\n",
    "      messages: [\n",
    "        {\n",
    "          role: \"user\",\n",
    "          content: input,\n",
    "        },\n",
    "      ],\n",
    "    },\n",
    "    config\n",
    "  );\n",
    "  console.log(`Result from running graph with input \"${input}\":`);\n",
    "  console.log(result);\n",
    "  console.log(\"\\n\\n\");\n",
    "};\n",
    "\n",
    "// Usage examples:\n",
    "await runGraph(\"hi\");\n",
    "await runGraph(\"i like pepperoni pizza\");\n",
    "await runGraph(\"i also just moved to SF\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d4e33-556d-4fa5-8094-2a076bc21529",
   "metadata": {},
   "source": [
    "## Run graph on one thread\n",
    "\n",
    "We can now run the graph on one thread and give it some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bd8679-3a73-4033-bfb4-5093ac1f5d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  call_model: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        \"id\": \"chatcmpl-A78Tb2nKOM98bRLoRldxDmBwmjHfG\",\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {\n",
      "          \"tokenUsage\": {\n",
      "            \"completionTokens\": 10,\n",
      "            \"promptTokens\": 137,\n",
      "            \"totalTokens\": 147\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "        },\n",
      "        \"tool_calls\": [],\n",
      "        \"invalid_tool_calls\": [],\n",
      "        \"usage_metadata\": {\n",
      "          \"input_tokens\": 137,\n",
      "          \"output_tokens\": 10,\n",
      "          \"total_tokens\": 147\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  call_model: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        \"id\": \"chatcmpl-A78TbqS00POpWMxpZURPVRHnvCQ4B\",\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_aYpF8bN61Ypprlz8verxbDnM\",\n",
      "              \"type\": \"function\",\n",
      "              \"function\": \"[Object]\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"response_metadata\": {\n",
      "          \"tokenUsage\": {\n",
      "            \"completionTokens\": 23,\n",
      "            \"promptTokens\": 159,\n",
      "            \"totalTokens\": 182\n",
      "          },\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "        },\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"name\": \"Info\",\n",
      "            \"args\": {\n",
      "              \"fact\": \"The user likes pepperoni pizza\",\n",
      "              \"topic\": \"Food Preferences\"\n",
      "            },\n",
      "            \"type\": \"tool_call\",\n",
      "            \"id\": \"call_aYpF8bN61Ypprlz8verxbDnM\"\n",
      "          }\n",
      "        ],\n",
      "        \"invalid_tool_calls\": [],\n",
      "        \"usage_metadata\": {\n",
      "          \"input_tokens\": 159,\n",
      "          \"output_tokens\": 23,\n",
      "          \"total_tokens\": 182\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  update_memory: {\n",
      "    messages: [\n",
      "      ToolMessage {\n",
      "        \"content\": \"Saved!\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {},\n",
      "        \"tool_call_id\": \"call_aYpF8bN61Ypprlz8verxbDnM\"\n",
      "      }\n",
      "    ],\n",
      "    info: { '1dbd22b1-8f52-4298-af97-dde0482047c4': [Object] }\n",
      "  }\n",
      "}\n",
      "{\n",
      "  call_model: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        \"id\": \"chatcmpl-A78TbxEVCFBvK8V1JRH9Wm2gcygSs\",\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_LnOPtxIBaF07ISGgcCvIc1l0\",\n",
      "              \"type\": \"function\",\n",
      "              \"function\": \"[Object]\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"response_metadata\": {\n",
      "          \"tokenUsage\": {\n",
      "            \"completionTokens\": 23,\n",
      "            \"promptTokens\": 208,\n",
      "            \"totalTokens\": 231\n",
      "          },\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "        },\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"name\": \"Info\",\n",
      "            \"args\": {\n",
      "              \"fact\": \"The user just moved to San Francisco\",\n",
      "              \"topic\": \"Location\"\n",
      "            },\n",
      "            \"type\": \"tool_call\",\n",
      "            \"id\": \"call_LnOPtxIBaF07ISGgcCvIc1l0\"\n",
      "          }\n",
      "        ],\n",
      "        \"invalid_tool_calls\": [],\n",
      "        \"usage_metadata\": {\n",
      "          \"input_tokens\": 208,\n",
      "          \"output_tokens\": 23,\n",
      "          \"total_tokens\": 231\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  update_memory: {\n",
      "    messages: [\n",
      "      ToolMessage {\n",
      "        \"content\": \"Saved!\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {},\n",
      "        \"tool_call_id\": \"call_LnOPtxIBaF07ISGgcCvIc1l0\"\n",
      "      }\n",
      "    ],\n",
      "    info: { 'f8a1a4b7-f045-427f-bf88-8a036d23884f': [Object] }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const config2 = { configurable: { thread_id: \"2\", user_id: \"2\" }, streamMode: \"updates\" as const };\n",
    "\n",
    "// First let's just say hi to the AI\n",
    "for await (const update of await compiledGraph.stream({\n",
    "  messages: [{ role: \"user\", content: \"hi\" }],\n",
    "}, config2)) {\n",
    "  console.log(update);\n",
    "}\n",
    "\n",
    "// Let's continue the conversation (by passing the same config) and tell the AI we like pepperoni pizza\n",
    "for await (const update of await compiledGraph.stream({\n",
    "  messages: [{ role: \"user\", content: \"i like pepperoni pizza\" }],\n",
    "}, config2)) {\n",
    "  console.log(update);\n",
    "}\n",
    "\n",
    "// Let's continue the conversation even further (by passing the same config) and tell the AI we live in SF\n",
    "for await (const update of await compiledGraph.stream({\n",
    "  messages: [{ role: \"user\", content: \"i also just moved to SF\" }],\n",
    "}, config2)) {\n",
    "  console.log(update);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c416fa-086a-491d-a7d3-57091f6413e3",
   "metadata": {},
   "source": [
    "## Run graph on a different thread\n",
    "\n",
    "We can now run the graph on a different thread and see that it remembers facts about the user (specifically that the user likes pepperoni pizza and lives in SF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e240f025-ff8b-4d17-beb7-2420c0575dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  call_model: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        \"id\": \"chatcmpl-A78TcnpbLqzpItVeBwIM6f7e3vSHt\",\n",
      "        \"content\": \"Sure! Since you just moved to San Francisco, here are some great restaurant options you might enjoy:\\n\\n1. **Tony's Pizza Napoletana**\\n   - **Cuisine:** Italian, Pizza\\n   - **Location:** 1570 Stockton St, San Francisco, CA 94133\\n   - **Why you might like it:** They have amazing pepperoni pizza!\\n\\n2. **House of Prime Rib**\\n   - **Cuisine:** American, Steakhouse\\n   - **Location:** 1906 Van Ness Ave, San Francisco, CA 94109\\n   - **Why you might like it:** If you're in the mood for a hearty steak dinner.\\n\\n3. **Tartine Bakery**\\n   - **Cuisine:** Bakery, Cafe\\n   - **Location:** 600 Guerrero St, San Francisco, CA 94110\\n   - **Why you might like it:** Perfect for a casual dinner with delicious pastries and sandwiches.\\n\\n4. **La Taqueria**\\n   - **Cuisine:** Mexican\\n   - **Location:** 2889 Mission St, San Francisco, CA 94110\\n   - **Why you might like it:** Known for their amazing tacos and burritos.\\n\\n5. **Swan Oyster Depot**\\n   - **Cuisine:** Seafood\\n   - **Location:** 1517 Polk St, San Francisco, CA 94109\\n   - **Why you might like it:** If you're in the mood for fresh seafood.\\n\\n6. **Nopa**\\n   - **Cuisine:** American, Contemporary\\n   - **Location:** 560 Divisadero St, San Francisco, CA 94117\\n   - **Why you might like it:** Great for a modern American dining experience.\\n\\nWould you like more information on any of these places or have a specific type of cuisine in mind?\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {\n",
      "          \"tokenUsage\": {\n",
      "            \"completionTokens\": 365,\n",
      "            \"promptTokens\": 166,\n",
      "            \"totalTokens\": 531\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "        },\n",
      "        \"tool_calls\": [],\n",
      "        \"invalid_tool_calls\": [],\n",
      "        \"usage_metadata\": {\n",
      "          \"input_tokens\": 166,\n",
      "          \"output_tokens\": 365,\n",
      "          \"total_tokens\": 531\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const config3 = { configurable: { thread_id: \"3\", user_id: \"2\" }, streamMode: \"updates\" as const };\n",
    "\n",
    "for await (const update of await compiledGraph.stream({\n",
    "  messages: [{ role: \"user\", content: \"where and what should i eat for dinner? Can you list some restaurants?\" }],\n",
    "}, config3)) {\n",
    "  console.log(update);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091995d3",
   "metadata": {},
   "source": [
    "Perfect! The AI recommended restaurants in SF, and included a pizza restaurant at the top of it's list.\n",
    "\n",
    "Notice that the `messages` in this new thread do NOT contain the messages from the previous thread since we didn't store them as shared values across the `user_id`. However, the `info` we saved in the previous thread was saved since we passed in the same `user_id` in this new thread.\n",
    "\n",
    "Let's now run the graph for another user to verify that the preferences of the first user are self contained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bf2c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  call_model: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        \"id\": \"chatcmpl-A78Tg2Kx6tJ93Co76psm0HTzsVYW1\",\n",
      "        \"content\": \"Sure, I can help with that! To give you the best recommendations, could you please tell me your location or the city you're in? Additionally, do you have any preferences for cuisine or dietary restrictions?\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {\n",
      "          \"tokenUsage\": {\n",
      "            \"completionTokens\": 42,\n",
      "            \"promptTokens\": 151,\n",
      "            \"totalTokens\": 193\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"system_fingerprint\": \"fp_25624ae3a5\"\n",
      "        },\n",
      "        \"tool_calls\": [],\n",
      "        \"invalid_tool_calls\": [],\n",
      "        \"usage_metadata\": {\n",
      "          \"input_tokens\": 151,\n",
      "          \"output_tokens\": 42,\n",
      "          \"total_tokens\": 193\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const config4 = { configurable: { thread_id: \"4\", user_id: \"3\" }, streamMode: \"updates\" as const }\n",
    "\n",
    "for await (const update of await compiledGraph.stream({\n",
    "  messages: [{ role: \"user\", content: \"where and what should i eat for dinner? Can you list some restaurants?\" }],\n",
    "}, config4)) {\n",
    "  console.log(update);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7086cea",
   "metadata": {},
   "source": [
    "Perfect! The graph has forgotten all of the previous preferences and has to ask the user for it's location and dietary preferences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
