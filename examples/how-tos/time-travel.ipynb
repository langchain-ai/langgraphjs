{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395cccb-a6d0-4d46-bad7-ed2d012af58a",
   "metadata": {},
   "source": [
    "# Get State and Update State\n",
    "\n",
    "Once you start [checkpointing](./persistence.ipynb) your graphs, you can easily **get** or **update** the state of the agent at any point in time. This permits a few things:\n",
    "\n",
    "1. You can surface a state during an interrupt to a user to let them accept an action.\n",
    "2. You can **rewind** the graph to reproduce or avoid issues.\n",
    "3. You can **modify** the state to embed your agent into a larger system, or to let the user better control its actions.\n",
    "\n",
    "The key methods used for this functionality are:\n",
    "\n",
    "- [getState](https://langchain-ai.github.io/langgraphjs/reference/classes/pregel.Pregel.html#getState): fetch the values from the target config\n",
    "- [updateState](https://langchain-ai.github.io/langgraphjs/reference/classes/pregel.Pregel.html#updateState): apply the given values to the target state\n",
    "\n",
    "**Note:** this requires passing in a checkpointer.\n",
    "\n",
    "<!-- Example:\n",
    "```javascript\n",
    "TODO\n",
    "...\n",
    "``` -->\n",
    "\n",
    "This works for\n",
    "[StateGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.StateGraph.html)\n",
    "and all its subclasses, such as\n",
    "[MessageGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.MessageGraph.html).\n",
    "\n",
    "Below is an example.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        In this how-to, we will create our agent from scratch to be transparent (but verbose). You can accomplish similar functionality using the <code>createReactAgent(model, tools=tool, checkpointer=checkpointer)</code> (<a href=\"https://langchain-ai.github.io/langgraphjs/reference/functions/prebuilt.createReactAgent.html\">API doc</a>) constructor. This may be more appropriate if you are used to LangChain’s <a href=\"https://js.langchain.com/v0.2/docs/langgraph/#agentexecutor\">AgentExecutor</a> class.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "## Setup\n",
    "\n",
    "This guide will use OpenAI's GPT-4o model. We will optionally set our API key\n",
    "for [LangSmith tracing](https://smith.langchain.com/), which will give us\n",
    "best-in-class observability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05706ae-f5c9-45e8-8c0a-2215703ee993",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"OPENAI_API_KEY\", \"sk_...\");\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"ls__...\");\n",
    "Deno.env.set(\"LANGCHAIN_CALLBACKS_BACKGROUND\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_PROJECT\", \"Time Travel: LangGraphJS\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47c4dc-cabe-4ee5-aaa8-9552f5d75ed2",
   "metadata": {},
   "source": [
    "## Define the state\n",
    "\n",
    "The state is the interface for all of the nodes in our graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abea6e1f-c21c-4dfe-a4cd-89326e625c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "interface IState {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => BaseMessage[];\n",
    "    default: () => BaseMessage[];\n",
    "  };\n",
    "}\n",
    "\n",
    "// This defines the agent state\n",
    "const graphState: IState = {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),\n",
    "    default: () => [],\n",
    "  },\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408be71e-8d06-403a-8623-6e6c222c677a",
   "metadata": {},
   "source": [
    "## Set up the tools\n",
    "\n",
    "We will first define the tools we want to use. For this simple example, we will\n",
    "use create a placeholder search engine. However, it is really easy to create\n",
    "your own tools - see documentation\n",
    "[here](https://js.langchain.com/v0.2/docs/how_to/custom_tools) on how to do\n",
    "that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae6c71e-10ce-4783-9dfc-49e5b750b269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Cold, with a low of 13 ℃\"\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const searchTool = new DynamicStructuredTool({\n",
    "  name: \"search\",\n",
    "  description:\n",
    "    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n",
    "  schema: z.object({\n",
    "    query: z.string().describe(\"The query to use in your search.\"),\n",
    "  }),\n",
    "  func: async ({ query }: { query: string }) => {\n",
    "    // This is a placeholder for the actual implementation\n",
    "    return \"Cold, with a low of 13 ℃\";\n",
    "  },\n",
    "});\n",
    "\n",
    "await searchTool.invoke({ query: \"What's the weather like?\" });\n",
    "\n",
    "const tools = [searchTool];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eae3ed-b322-4afe-9111-d7dc204fdb77",
   "metadata": {},
   "source": [
    "We can now wrap these tools in a simple\n",
    "[ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/prebuilt.ToolNode.html).\n",
    "This object will actually run the tools (functions) whenever they are invoked by\n",
    "our LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638fa6e9-cb76-4838-bc8b-02edf7da5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const toolNode = new ToolNode(tools);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94b49b-fb11-463c-b34c-9d66b5327678",
   "metadata": {},
   "source": [
    "## Set up the model\n",
    "\n",
    "Now we will load the [chat model](https://js.langchain.com/v0.2/docs/concepts/#chat-models).\n",
    "\n",
    "1. It should work with messages. We will represent all agent state in the form\n",
    "   of messages, so it needs to be able to work well with them.\n",
    "2. It should work with\n",
    "   [tool calling](https://js.langchain.com/v0.2/docs/how_to/tool_calling/#passing-tools-to-llms),\n",
    "   meaning it can return function arguments in its response.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        These model requirements are not general requirements for using LangGraph - they are just requirements for this one example.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a00435f-5e80-4a3e-a873-b308b1f781db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "// const model = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" });\n",
    "const model = new ChatOpenAI({ model: \"gpt-4o\" });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975c1ab-fcac-4448-a0cd-7969ae6f4e45",
   "metadata": {},
   "source": [
    "After we've done this, we should make sure the model knows that it has these\n",
    "tools available to call. We can do this by calling\n",
    "[bindTools](https://v01.api.js.langchain.com/classes/langchain_core_language_models_chat_models.BaseChatModel.html#bindTools).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d4a57f-e7d0-48d7-8626-e83185c1236d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  tools: [\n",
       "    {\n",
       "      type: \u001b[32m\"function\"\u001b[39m,\n",
       "      function: {\n",
       "        name: \u001b[32m\"search\"\u001b[39m,\n",
       "        description: \u001b[32m\"Use to surf the web, fetch current information, check the weather, and retrieve other information.\"\u001b[39m,\n",
       "        parameters: {\n",
       "          type: \u001b[32m\"object\"\u001b[39m,\n",
       "          properties: \u001b[36m[Object]\u001b[39m,\n",
       "          required: \u001b[36m[Array]\u001b[39m,\n",
       "          additionalProperties: \u001b[33mfalse\u001b[39m,\n",
       "          \u001b[32m\"$schema\"\u001b[39m: \u001b[32m\"http://json-schema.org/draft-07/schema#\"\u001b[39m\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const boundModel = model.bindTools(tools);\n",
    "boundModel.kwargs;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0626d5-faae-4e24-bf1b-f01357c28627",
   "metadata": {},
   "source": [
    "## Define the graph\n",
    "\n",
    "We can now put it all together. Time travel requires a checkpointer to save the state - otherwise you wouldn't have anything go `get` or `update`. We will use the [MemorySaver](https://langchain-ai.github.io/langgraphjs/reference/classes/index.MemorySaver.html), which \"saves\" checkpoints in-memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "812b6d4b-9db7-490b-adae-ad9d933da56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateGraph {\n",
       "  nodes: {\n",
       "    agent: RunnableLambda {\n",
       "      lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "      lc_kwargs: { func: \u001b[36m[AsyncFunction: callModel]\u001b[39m },\n",
       "      lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"runnables\"\u001b[39m ],\n",
       "      func: \u001b[36m[AsyncFunction: callModel]\u001b[39m\n",
       "    },\n",
       "    tools: ToolNode {\n",
       "      lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "      lc_kwargs: {},\n",
       "      lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "      name: \u001b[32m\"tools\"\u001b[39m,\n",
       "      lc_namespace: [ \u001b[32m\"langgraph\"\u001b[39m ],\n",
       "      func: \u001b[36m[Function: func]\u001b[39m,\n",
       "      tags: \u001b[90mundefined\u001b[39m,\n",
       "      config: { tags: [] },\n",
       "      trace: \u001b[33mtrue\u001b[39m,\n",
       "      recurse: \u001b[33mtrue\u001b[39m,\n",
       "      tools: [\n",
       "        DynamicStructuredTool {\n",
       "          lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
       "          lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "          name: \u001b[32m\"search\"\u001b[39m,\n",
       "          verbose: \u001b[33mfalse\u001b[39m,\n",
       "          callbacks: \u001b[90mundefined\u001b[39m,\n",
       "          tags: [],\n",
       "          metadata: {},\n",
       "          returnDirect: \u001b[33mfalse\u001b[39m,\n",
       "          description: \u001b[32m\"Use to surf the web, fetch current information, check the weather, and retrieve other information.\"\u001b[39m,\n",
       "          func: \u001b[36m[AsyncFunction: func]\u001b[39m,\n",
       "          schema: \u001b[36m[ZodObject]\u001b[39m\n",
       "        }\n",
       "      ]\n",
       "    }\n",
       "  },\n",
       "  edges: Set(2) { [ \u001b[32m\"__start__\"\u001b[39m, \u001b[32m\"agent\"\u001b[39m ], [ \u001b[32m\"tools\"\u001b[39m, \u001b[32m\"agent\"\u001b[39m ] },\n",
       "  branches: {\n",
       "    agent: {\n",
       "      routeMessage: Branch {\n",
       "        condition: \u001b[36m[Function: routeMessage]\u001b[39m,\n",
       "        ends: \u001b[90mundefined\u001b[39m,\n",
       "        then: \u001b[90mundefined\u001b[39m\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  entryPoint: \u001b[90mundefined\u001b[39m,\n",
       "  compiled: \u001b[33mtrue\u001b[39m,\n",
       "  supportMultipleEdges: \u001b[33mtrue\u001b[39m,\n",
       "  channels: {\n",
       "    messages: BinaryOperatorAggregate {\n",
       "      lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "      value: [],\n",
       "      operator: \u001b[36m[Function: value]\u001b[39m,\n",
       "      initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  waitingEdges: Set(0) {}\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { BaseMessage, AIMessage } from \"@langchain/core/messages\";\n",
    "import { RunnableConfig } from \"@langchain/core/runnables\";\n",
    "import { MemorySaver, START, END, StateGraph } from \"@langchain/langgraph\";\n",
    "\n",
    "const routeMessage = (state: { messages: Array<BaseMessage> }) => {\n",
    "  const { messages } = state;\n",
    "  const lastMessage = messages[messages.length - 1] as AIMessage;\n",
    "  // If no tools are called, we can finish (respond to the user)\n",
    "  if (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0) {\n",
    "    return END;\n",
    "  }\n",
    "  // Otherwise if there is, we continue and call the tools\n",
    "  return \"tools\";\n",
    "};\n",
    "\n",
    "const callModel = async (\n",
    "  state: { messages: Array<BaseMessage> },\n",
    "  config: RunnableConfig\n",
    ") => {\n",
    "  const { messages } = state;\n",
    "  const response = await boundModel.invoke(messages, config);\n",
    "  return { messages: [response] };\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph({\n",
    "  channels: graphState,\n",
    "});\n",
    "\n",
    "// Define the two nodes we will cycle between\n",
    "workflow.addNode(\"agent\", callModel);\n",
    "workflow.addNode(\"tools\", toolNode);\n",
    "\n",
    "// Set the entrypoint as `agent`\n",
    "workflow.addEdge(START, \"agent\");\n",
    "workflow.addConditionalEdges(\"agent\", routeMessage);\n",
    "workflow.addEdge(\"tools\", \"agent\");\n",
    "\n",
    "// Here we only save in-memory\n",
    "let memory = new MemorySaver();\n",
    "const graph = workflow.compile({ checkpointer: memory });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d8e1d",
   "metadata": {},
   "source": [
    "## Interacting with the Agent\n",
    "\n",
    "We can now interact with the agent. Between interactions you can get and update state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24711ca1-3fd8-46ca-b2c1-affa8cd45267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"user\", \"Hi I'm Jo.\" ]\n",
      "-----\n",
      "\n",
      "Hello, Jo! How can I assist you today?\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let config = { configurable: { thread_id: \"conversation-num-1\" } };\n",
    "let inputs = { messages: [[\"user\", \"Hi I'm Jo.\"]] };\n",
    "for await (const { messages } of await graph.stream(inputs, {\n",
    "  ...config,\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11210c6",
   "metadata": {},
   "source": [
    "See LangSmith example run here https://smith.langchain.com/public/b3feb09b-bcd2-4ad5-ad1d-414106148448/r\n",
    "\n",
    "Here you can see the \"agent\" node ran, and then our edge returned `__end__` so the graph stopped execution there.\n",
    "\n",
    "Let's check the current graph state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41d017ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  messages: [\n",
       "    [ \u001b[32m\"user\"\u001b[39m, \u001b[32m\"Hi I'm Jo.\"\u001b[39m ],\n",
       "    AIMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: \u001b[32m\"Hello, Jo! How can I assist you today?\"\u001b[39m,\n",
       "        tool_calls: [],\n",
       "        invalid_tool_calls: [],\n",
       "        additional_kwargs: {},\n",
       "        response_metadata: { tokenUsage: \u001b[36m[Object]\u001b[39m, finish_reason: \u001b[32m\"stop\"\u001b[39m }\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"Hello, Jo! How can I assist you today?\"\u001b[39m,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {\n",
       "        tokenUsage: { completionTokens: \u001b[33m12\u001b[39m, promptTokens: \u001b[33m68\u001b[39m, totalTokens: \u001b[33m80\u001b[39m },\n",
       "        finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "      },\n",
       "      tool_calls: [],\n",
       "      invalid_tool_calls: []\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let checkpoint = await graph.getState(config);\n",
    "checkpoint.values;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849e28b",
   "metadata": {},
   "source": [
    "The current state is the two messages we've seen above, 1. the HumanMessage we sent in, 2. the AIMessage we got back from the model.\n",
    "\n",
    "The `next` values are empty since the graph has terminated (transitioned to the `__end__`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b6df77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.next;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87346938",
   "metadata": {},
   "source": [
    "## Let's get it to execute a tool\n",
    "\n",
    "When we call the graph again, it will create a checkpoint after each internal execution step. Let's get it to run a tool, then look at the checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8537fd9d-083c-4096-91c5-44a2e66b18c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"user\", \"What's the weather like in SF currently?\" ]\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    name: \"search\",\n",
      "    args: { query: \"current weather in San Francisco\" },\n",
      "    id: \"call_SVSDHe158HFTljdh2d1Q6SC1\"\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n",
      "Cold, with a low of 13 ℃\n",
      "-----\n",
      "\n",
      "The weather in San Francisco is currently cold, with a low of 13°C. Is there anything else you'd like to know?\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = { messages: [[\"user\", \"What's the weather like in SF currently?\"]] };\n",
    "for await (const { messages } of await graph.stream(inputs, {\n",
    "  ...config,\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc172a",
   "metadata": {},
   "source": [
    "See the trace of the above execution here: https://smith.langchain.com/public/0ef426fd-0da1-4c02-a50b-64ae1e68338e/r\n",
    "We can see it planned the tool execution (ie the \"agent\" node), then \"should_continue\" edge returned \"continue\" so we proceeded to \"action\" node, which executed the tool, and then \"agent\" node emitted the final response, which made \"should_continue\" edge return \"end\". Let's see how we can have more control over this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383edee-1a8c-4b66-b668-ee760918bede",
   "metadata": {},
   "source": [
    "### Pause before tools\n",
    "\n",
    "If you notice below, we now will add `interruptBefore=[\"action\"]` - this means that before any actions are taken we pause. This is a great moment to allow the user to correct and update the state! This is very useful when you want to have a human-in-the-loop to validate (and potentially change) the action to take.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdf5046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"user\", \"What's the weather like in SF currently?\" ]\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    name: \"search\",\n",
      "    args: { query: \"current weather in San Francisco\" },\n",
      "    id: \"call_bEJjPCtJ2saAcx7XdMh4lZxC\"\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory = new MemorySaver();\n",
    "const graphWithInterrupt = workflow.compile({\n",
    "  checkpointer: memory,\n",
    "  interruptBefore: [\"tools\"],\n",
    "});\n",
    "\n",
    "inputs = { messages: [[\"user\", \"What's the weather like in SF currently?\"]] };\n",
    "for await (const { messages } of await graphWithInterrupt.stream(inputs, {\n",
    "  ...config,\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0172432",
   "metadata": {},
   "source": [
    "## Get State\n",
    "\n",
    "You can fetch the latest graph checkpoint using [`getState(config)`](https://langchain-ai.github.io/langgraphjs/reference/classes/pregel.Pregel.html#getState).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41e2d0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ \u001b[32m\"tools\"\u001b[39m ]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let snapshot = await graphWithInterrupt.getState(config);\n",
    "snapshot.next;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c50e6b",
   "metadata": {},
   "source": [
    "## Resume\n",
    "\n",
    "You can resume by running the graph with a `null` input.\n",
    "The checkpoint is loaded, and with no new inputs, it will execute as if no interrupt had occurred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f43897a",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_bEJjPCtJ2saAcx7XdMh4lZxC",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_bEJjPCtJ2saAcx7XdMh4lZxC",
      "    at Function.generate (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/error.mjs:41:20)",
      "    at OpenAI.makeStatusError (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/core.mjs:256:25)",
      "    at OpenAI.makeRequest (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/core.mjs:299:30)",
      "    at eventLoopTick (ext:core/01_core.js:168:7)",
      "    at async file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/@langchain/openai/0.0.31/dist/chat_models.js:756:29",
      "    at async RetryOperation._fn (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/p-retry/4.6.2/index.js:50:12)"
     ]
    }
   ],
   "source": [
    "for await (const { messages } of await graphWithInterrupt.stream(\n",
    "  {},\n",
    "  {\n",
    "    ...snapshot.config,\n",
    "    streamMode: \"values\",\n",
    "  }\n",
    ")) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2e176",
   "metadata": {},
   "source": [
    "## Check full history\n",
    "\n",
    "Let's browse the history of this thread, from newest to oldest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41cb0ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  values: {\n",
      "    messages: [\n",
      "      [ \"user\", \"What's the weather like in SF currently?\" ],\n",
      "      AIMessage {\n",
      "        lc_serializable: true,\n",
      "        lc_kwargs: {\n",
      "          content: \"\",\n",
      "          tool_calls: [Array],\n",
      "          invalid_tool_calls: [],\n",
      "          additional_kwargs: [Object],\n",
      "          response_metadata: [Object]\n",
      "        },\n",
      "        lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "        content: \"\",\n",
      "        name: undefined,\n",
      "        additional_kwargs: { tool_calls: [Array] },\n",
      "        response_metadata: { tokenUsage: [Object], finish_reason: \"tool_calls\" },\n",
      "        tool_calls: [ [Object] ],\n",
      "        invalid_tool_calls: []\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  next: [ \"agent\" ],\n",
      "  metadata: { source: \"loop\", step: 3 },\n",
      "  config: {\n",
      "    configurable: {\n",
      "      thread_id: \"conversation-num-1\",\n",
      "      checkpoint_id: \"1ef147c4-56fa-66a1-8003-d875623a1683\"\n",
      "    }\n",
      "  },\n",
      "  parentConfig: undefined\n",
      "}\n",
      "--\n",
      "{\n",
      "  values: {\n",
      "    messages: [\n",
      "      [ \"user\", \"What's the weather like in SF currently?\" ],\n",
      "      AIMessage {\n",
      "        lc_serializable: true,\n",
      "        lc_kwargs: {\n",
      "          content: \"\",\n",
      "          tool_calls: [Array],\n",
      "          invalid_tool_calls: [],\n",
      "          additional_kwargs: [Object],\n",
      "          response_metadata: [Object]\n",
      "        },\n",
      "        lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "        content: \"\",\n",
      "        name: undefined,\n",
      "        additional_kwargs: { tool_calls: [Array] },\n",
      "        response_metadata: { tokenUsage: [Object], finish_reason: \"tool_calls\" },\n",
      "        tool_calls: [ [Object] ],\n",
      "        invalid_tool_calls: []\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  next: [ \"__start__\" ],\n",
      "  metadata: { source: \"input\", step: 2, writes: { __start__: {} } },\n",
      "  config: {\n",
      "    configurable: {\n",
      "      thread_id: \"conversation-num-1\",\n",
      "      checkpoint_id: \"1ef147c4-56fa-66a0-8002-6fcead100b0f\"\n",
      "    }\n",
      "  },\n",
      "  parentConfig: undefined\n",
      "}\n",
      "--\n",
      "{\n",
      "  values: {\n",
      "    messages: [\n",
      "      [ \"user\", \"What's the weather like in SF currently?\" ],\n",
      "      AIMessage {\n",
      "        lc_serializable: true,\n",
      "        lc_kwargs: {\n",
      "          content: \"\",\n",
      "          tool_calls: [Array],\n",
      "          invalid_tool_calls: [],\n",
      "          additional_kwargs: [Object],\n",
      "          response_metadata: [Object]\n",
      "        },\n",
      "        lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "        content: \"\",\n",
      "        name: undefined,\n",
      "        additional_kwargs: { tool_calls: [Array] },\n",
      "        response_metadata: { tokenUsage: [Object], finish_reason: \"tool_calls\" },\n",
      "        tool_calls: [ [Object] ],\n",
      "        invalid_tool_calls: []\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  next: [ \"tools\" ],\n",
      "  metadata: {\n",
      "    source: \"loop\",\n",
      "    step: 1,\n",
      "    writes: {\n",
      "      messages: [\n",
      "        [ \"user\", \"What's the weather like in SF currently?\" ],\n",
      "        AIMessage {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_namespace: [Array],\n",
      "          content: \"\",\n",
      "          name: undefined,\n",
      "          additional_kwargs: [Object],\n",
      "          response_metadata: [Object],\n",
      "          tool_calls: [Array],\n",
      "          invalid_tool_calls: []\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  config: {\n",
      "    configurable: {\n",
      "      thread_id: \"conversation-num-1\",\n",
      "      checkpoint_id: \"1ef147c3-ac8c-60b1-8001-9d33401e64e8\"\n",
      "    }\n",
      "  },\n",
      "  parentConfig: undefined\n",
      "}\n",
      "--\n",
      "{\n",
      "  values: {\n",
      "    messages: [ [ \"user\", \"What's the weather like in SF currently?\" ] ]\n",
      "  },\n",
      "  next: [ \"agent\" ],\n",
      "  metadata: {\n",
      "    source: \"loop\",\n",
      "    step: 0,\n",
      "    writes: {\n",
      "      messages: [ [ \"user\", \"What's the weather like in SF currently?\" ] ]\n",
      "    }\n",
      "  },\n",
      "  config: {\n",
      "    configurable: {\n",
      "      thread_id: \"conversation-num-1\",\n",
      "      checkpoint_id: \"1ef147c3-a5c4-6340-8000-d08d302fa0b7\"\n",
      "    }\n",
      "  },\n",
      "  parentConfig: undefined\n",
      "}\n",
      "--\n",
      "{\n",
      "  values: { messages: [] },\n",
      "  next: [ \"__start__\" ],\n",
      "  metadata: {\n",
      "    source: \"input\",\n",
      "    step: -1,\n",
      "    writes: { __start__: { messages: [ [Array] ] } }\n",
      "  },\n",
      "  config: {\n",
      "    configurable: {\n",
      "      thread_id: \"conversation-num-1\",\n",
      "      checkpoint_id: \"1ef147c3-a5c1-6c31-unde-finedffbaadc606e5d5\"\n",
      "    }\n",
      "  },\n",
      "  parentConfig: undefined\n",
      "}\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "let toReplay = null;\n",
    "for await (const state of graphWithInterrupt.getStateHistory(config)) {\n",
    "    console.log(state);\n",
    "    console.log(\"--\");\n",
    "    if (state.values?.messages?.length === 2) {\n",
    "        toReplay = state;\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552de41",
   "metadata": {},
   "source": [
    "## Replay a past state\n",
    "\n",
    "To replay from this place we just need to pass its config back to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74e73b60",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_bEJjPCtJ2saAcx7XdMh4lZxC",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_bEJjPCtJ2saAcx7XdMh4lZxC",
      "    at Function.generate (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/error.mjs:41:20)",
      "    at OpenAI.makeStatusError (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/core.mjs:256:25)",
      "    at OpenAI.makeRequest (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/core.mjs:299:30)",
      "    at eventLoopTick (ext:core/01_core.js:168:7)",
      "    at async file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/@langchain/openai/0.0.31/dist/chat_models.js:756:29",
      "    at async RetryOperation._fn (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/p-retry/4.6.2/index.js:50:12)"
     ]
    }
   ],
   "source": [
    "for await (const { messages } of await graphWithInterrupt.stream(\n",
    "  {},\n",
    "  {\n",
    "    ...toReplay.config,\n",
    "    streamMode: \"values\",\n",
    "  }\n",
    ")) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cef56",
   "metadata": {},
   "source": [
    "## Branch off a past state\n",
    "\n",
    "Using LangGraph's checkpointing, you can do more than just replay past states. You can branch off previous locations to let the agent explore alternate trajectories or to let a user \"version control\" changes in a workflow.\n",
    "\n",
    "#### First, update a previous checkpoint\n",
    "\n",
    "Updating the state will create a **new** snapshot by applying the update to the previous checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a1c7ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  messages: [\n",
      "    [ \"user\", \"What's the weather like in SF currently?\" ],\n",
      "    AIMessage {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: {\n",
      "        content: \"\",\n",
      "        tool_calls: [ [Object] ],\n",
      "        invalid_tool_calls: [],\n",
      "        additional_kwargs: { tool_calls: [Array] },\n",
      "        response_metadata: { tokenUsage: [Object], finish_reason: \"tool_calls\" }\n",
      "      },\n",
      "      lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "      content: \"\",\n",
      "      name: undefined,\n",
      "      additional_kwargs: { tool_calls: [ [Object] ] },\n",
      "      response_metadata: {\n",
      "        tokenUsage: { completionTokens: 17, promptTokens: 72, totalTokens: 89 },\n",
      "        finish_reason: \"tool_calls\"\n",
      "      },\n",
      "      tool_calls: [\n",
      "        {\n",
      "          name: \"search\",\n",
      "          args: [Object],\n",
      "          id: \"call_bEJjPCtJ2saAcx7XdMh4lZxC\"\n",
      "        }\n",
      "      ],\n",
      "      invalid_tool_calls: []\n",
      "    },\n",
      "    AIMessage {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: {\n",
      "        content: \"All done here!\",\n",
      "        tool_calls: [],\n",
      "        invalid_tool_calls: [],\n",
      "        additional_kwargs: {},\n",
      "        response_metadata: {}\n",
      "      },\n",
      "      lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "      content: \"All done here!\",\n",
      "      name: undefined,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {},\n",
      "      tool_calls: [],\n",
      "      invalid_tool_calls: []\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import { AIMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const branchConfig = await graphWithInterrupt.updateState(\n",
    "    toReplay.config,\n",
    "    {\n",
    "        messages: [\n",
    "            new AIMessage(\"All done here!\", toReplay.values.messages[toReplay.values.messages.length - 1].id)\n",
    "        ]\n",
    "    }\n",
    ");\n",
    "\n",
    "const branchState = await graphWithInterrupt.getState(branchConfig);\n",
    "console.log(branchState.values);\n",
    "console.log(branchState.next);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a68c0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Promise {\n",
       "  {\n",
       "    configurable: {\n",
       "      thread_id: \u001b[32m\"conversation-num-1\"\u001b[39m,\n",
       "      checkpoint_id: \u001b[32m\"1ef147d6-e96d-6161-8002-d54d82c4420d\"\u001b[39m\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branchConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97a823",
   "metadata": {},
   "source": [
    "#### Now you can run from this branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38b185d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_bEJjPCtJ2saAcx7XdMh4lZxC",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_bEJjPCtJ2saAcx7XdMh4lZxC",
      "    at Function.generate (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/error.mjs:41:20)",
      "    at OpenAI.makeStatusError (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/core.mjs:256:25)",
      "    at OpenAI.makeRequest (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/openai/4.47.1/core.mjs:299:30)",
      "    at eventLoopTick (ext:core/01_core.js:168:7)",
      "    at async file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/@langchain/openai/0.0.31/dist/chat_models.js:756:29",
      "    at async RetryOperation._fn (file:///Users/wfh/Library/Caches/deno/npm/registry.npmjs.org/p-retry/4.6.2/index.js:50:12)"
     ]
    }
   ],
   "source": [
    "for await (const { messages } of await graphWithInterrupt.stream(\n",
    "  {},\n",
    "  {\n",
    "    ...branchConfig,\n",
    "    streamMode: \"values\",\n",
    "  }\n",
    ")) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
