{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395cccb-a6d0-4d46-bad7-ed2d012af58a",
   "metadata": {},
   "source": [
    "# Get/Update State\n",
    "\n",
    "Once you start [checkpointing](./persistence.ipynb) your graphs, you can easily **get** or **update** the state of the agent at any point in time. This permits a few things:\n",
    "\n",
    "1. You can surface a state during an interrupt to a user to let them accept an action.\n",
    "2. You can **rewind** the graph to reproduce or avoid issues.\n",
    "3. You can **modify** the state to embed your agent into a larger system, or to let the user better control its actions.\n",
    "\n",
    "The key methods used for this functionality are:\n",
    "\n",
    "- [get_state](https://langchain-ai.github.io/langgraphjs/reference/classes/pregel.Pregel.html#getState): fetch the values from the target config\n",
    "- [update_state](https://langchain-ai.github.io/langgraphjs/reference/classes/pregel.Pregel.html#updateState): apply the given values to the target state\n",
    "\n",
    "**Note:** this requires passing in a checkpointer.\n",
    "\n",
    "<!-- Example:\n",
    "```javascript\n",
    "TODO\n",
    "...\n",
    "``` -->\n",
    "\n",
    "This works for\n",
    "[StateGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.StateGraph.html)\n",
    "and all its subclasses, such as\n",
    "[MessageGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.MessageGraph.html).\n",
    "\n",
    "Below is an example.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        In this how-to, we will create our agent from scratch to be transparent (but verbose). You can accomplish similar functionality using the <code>createReactAgent(model, tools=tool, checkpointer=checkpointer)</code> (<a href=\"https://langchain-ai.github.io/langgraphjs/reference/functions/prebuilt.createReactAgent.html\">API doc</a>) constructor. This may be more appropriate if you are used to LangChain’s <a href=\"https://js.langchain.com/v0.2/docs/langgraph/#agentexecutor\">AgentExecutor</a> class.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "## Setup\n",
    "\n",
    "This guide will use Anthropic's Claude model. We will optionally set our API key\n",
    "for [LangSmith tracing](https://smith.langchain.com/), which will give us\n",
    "best-in-class observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05706ae-f5c9-45e8-8c0a-2215703ee993",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"ANTHROPIC_API_KEY\", \"sk_...\");\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"ls__...\");\n",
    "Deno.env.set(\"LANGCHAIN_CALLBACKS_BACKGROUND\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_PROJECT\", \"Time Travel: LangGraphJS\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47c4dc-cabe-4ee5-aaa8-9552f5d75ed2",
   "metadata": {},
   "source": [
    "## Define the state\n",
    "\n",
    "The state is the interface for all of the nodes in our graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abea6e1f-c21c-4dfe-a4cd-89326e625c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "interface IState {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => BaseMessage[];\n",
    "    default: () => BaseMessage[];\n",
    "  };\n",
    "  next: string;\n",
    "}\n",
    "\n",
    "// This defines the agent state\n",
    "const State: IState = {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),\n",
    "    default: () => [],\n",
    "  },\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408be71e-8d06-403a-8623-6e6c222c677a",
   "metadata": {},
   "source": [
    "## Set up the tools\n",
    "\n",
    "We will first define the tools we want to use. For this simple example, we will\n",
    "use create a placeholder search engine. However, it is really easy to create\n",
    "your own tools - see documentation\n",
    "[here](https://js.langchain.com/v0.2/docs/how_to/custom_tools) on how to do\n",
    "that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae6c71e-10ce-4783-9dfc-49e5b750b269",
   "metadata": {},
   "outputs": [
    {
     "ename": "{\"code\":-32000,\"message\":\"Promise was collected\"}",
     "evalue": " ",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const searchTool = new DynamicStructuredTool({\n",
    "  name: \"search\",\n",
    "  description:\n",
    "    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n",
    "  schema: z.object({\n",
    "    query: z.string().describe(\"The query to use in your search.\"),\n",
    "  }),\n",
    "  func: async ({ query }: { query: string }) => {\n",
    "    // This is a placeholder for the actual implementation\n",
    "    return [\"Cold, with a low of -78 ℃\"];\n",
    "  },\n",
    "});\n",
    "\n",
    "await searchTool.invoke({ query: \"What's the weather like?\" });\n",
    "\n",
    "const tools = [searchTool];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eae3ed-b322-4afe-9111-d7dc204fdb77",
   "metadata": {},
   "source": [
    "We can now wrap these tools in a simple\n",
    "[ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/prebuilt.ToolNode.html).\n",
    "This object will actually run the tools (functions) whenever they are invoked by\n",
    "our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638fa6e9-cb76-4838-bc8b-02edf7da5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const toolNode = new ToolNode(tools);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94b49b-fb11-463c-b34c-9d66b5327678",
   "metadata": {},
   "source": [
    "## Set up the model\n",
    "\n",
    "Now we will load the [chat model](https://js.langchain.com/v0.2/docs/concepts/#chat-models).\n",
    "\n",
    "1. It should work with messages. We will represent all agent state in the form\n",
    "   of messages, so it needs to be able to work well with them.\n",
    "2. It should work with\n",
    "   [tool calling](https://js.langchain.com/v0.2/docs/how_to/tool_calling/#passing-tools-to-llms),\n",
    "   meaning it can return function arguments in its response.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        These model requirements are not general requirements for using LangGraph - they are just requirements for this one example.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a00435f-5e80-4a3e-a873-b308b1f781db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const model = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975c1ab-fcac-4448-a0cd-7969ae6f4e45",
   "metadata": {},
   "source": [
    "After we've done this, we should make sure the model knows that it has these\n",
    "tools available to call. We can do this by calling\n",
    "[bindTools](https://v01.api.js.langchain.com/classes/langchain_core_language_models_chat_models.BaseChatModel.html#bindTools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d4a57f-e7d0-48d7-8626-e83185c1236d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  tools: [\n",
       "    {\n",
       "      name: \u001b[32m\"search\"\u001b[39m,\n",
       "      description: \u001b[32m\"Use to surf the web, fetch current information, check the weather, and retrieve other information.\"\u001b[39m,\n",
       "      input_schema: {\n",
       "        type: \u001b[32m\"object\"\u001b[39m,\n",
       "        properties: { query: \u001b[36m[Object]\u001b[39m },\n",
       "        required: [ \u001b[32m\"query\"\u001b[39m ],\n",
       "        additionalProperties: \u001b[33mfalse\u001b[39m,\n",
       "        \u001b[32m\"$schema\"\u001b[39m: \u001b[32m\"http://json-schema.org/draft-07/schema#\"\u001b[39m\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const boundModel = model.bindTools(tools);\n",
    "boundModel.kwargs;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0626d5-faae-4e24-bf1b-f01357c28627",
   "metadata": {},
   "source": [
    "## Define the graph\n",
    "\n",
    "We can now put it all together. Time travel requires a checkpointer to save the state - otherwise you wouldn't have anything go `get` or `update`. We will use the [MemorySaver](https://langchain-ai.github.io/langgraphjs/reference/classes/index.MemorySaver.html), which \"saves\" checkpoints in-memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812b6d4b-9db7-490b-adae-ad9d933da56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateGraph {\n",
       "  nodes: {\n",
       "    agent: RunnableLambda {\n",
       "      lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "      lc_kwargs: { func: \u001b[36m[AsyncFunction: callModel]\u001b[39m },\n",
       "      lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"runnables\"\u001b[39m ],\n",
       "      func: \u001b[36m[AsyncFunction: callModel]\u001b[39m\n",
       "    },\n",
       "    tools: ToolNode {\n",
       "      lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "      lc_kwargs: {},\n",
       "      lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "      name: \u001b[32m\"tools\"\u001b[39m,\n",
       "      lc_namespace: [ \u001b[32m\"langgraph\"\u001b[39m ],\n",
       "      func: \u001b[36m[Function: func]\u001b[39m,\n",
       "      tags: \u001b[90mundefined\u001b[39m,\n",
       "      config: { tags: [] },\n",
       "      trace: \u001b[33mtrue\u001b[39m,\n",
       "      recurse: \u001b[33mtrue\u001b[39m,\n",
       "      tools: [\n",
       "        DynamicStructuredTool {\n",
       "          lc_serializable: \u001b[33mfalse\u001b[39m,\n",
       "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
       "          lc_runnable: \u001b[33mtrue\u001b[39m,\n",
       "          name: \u001b[32m\"search\"\u001b[39m,\n",
       "          verbose: \u001b[33mfalse\u001b[39m,\n",
       "          callbacks: \u001b[90mundefined\u001b[39m,\n",
       "          tags: [],\n",
       "          metadata: {},\n",
       "          returnDirect: \u001b[33mfalse\u001b[39m,\n",
       "          description: \u001b[32m\"Use to surf the web, fetch current information, check the weather, and retrieve other information.\"\u001b[39m,\n",
       "          func: \u001b[36m[AsyncFunction: func]\u001b[39m,\n",
       "          schema: \u001b[36m[ZodObject]\u001b[39m\n",
       "        }\n",
       "      ]\n",
       "    }\n",
       "  },\n",
       "  edges: Set(2) { [ \u001b[32m\"__start__\"\u001b[39m, \u001b[32m\"agent\"\u001b[39m ], [ \u001b[32m\"tools\"\u001b[39m, \u001b[32m\"agent\"\u001b[39m ] },\n",
       "  branches: {\n",
       "    agent: {\n",
       "      routeMessage: Branch {\n",
       "        condition: \u001b[36m[Function: routeMessage]\u001b[39m,\n",
       "        ends: \u001b[90mundefined\u001b[39m,\n",
       "        then: \u001b[90mundefined\u001b[39m\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  entryPoint: \u001b[90mundefined\u001b[39m,\n",
       "  compiled: \u001b[33mtrue\u001b[39m,\n",
       "  supportMultipleEdges: \u001b[33mtrue\u001b[39m,\n",
       "  channels: {\n",
       "    messages: BinaryOperatorAggregate {\n",
       "      lc_graph_name: \u001b[32m\"BinaryOperatorAggregate\"\u001b[39m,\n",
       "      value: [],\n",
       "      operator: \u001b[36m[Function: value]\u001b[39m,\n",
       "      initialValueFactory: \u001b[36m[Function: default]\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  waitingEdges: Set(0) {}\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "import { load } from \"@langchain/core/load\";\n",
    "\n",
    "\n",
    "const routeMessage = (state: { messages: Array<BaseMessage> }) => {\n",
    "  const { messages } = state;\n",
    "  const lastMessage = messages[messages.length - 1];\n",
    "  // If no tools are called, we can finish (respond to the user)\n",
    "  if (!lastMessage.tool_calls.length) {\n",
    "    return END;\n",
    "  }\n",
    "  // Otherwise if there is, we continue and call the tools\n",
    "  return \"tools\";\n",
    "};\n",
    "\n",
    "const callModel = async (state: { messages: Array<BaseMessage> }) => {\n",
    "  const { messages } = state;\n",
    "  const response = await boundModel.invoke(messages);\n",
    "  return { messages: [response] };\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph({\n",
    "  channels: State,\n",
    "});\n",
    "\n",
    "// Define the two nodes we will cycle between\n",
    "workflow.addNode(\"agent\", callModel);\n",
    "workflow.addNode(\"tools\", toolNode);\n",
    "\n",
    "// Set the entrypoint as `agent`\n",
    "workflow.addEdge(START, \"agent\");\n",
    "workflow.addConditionalEdges(\"agent\", routeMessage);\n",
    "workflow.addEdge(\"tools\", \"agent\");\n",
    "\n",
    "const graph = workflow.compile();\n",
    "// Here we only save in-memory\n",
    "let memory = new MemorySaver({\n",
    "  parse: load,\n",
    "  stringify: JSON.stringify,\n",
    "});\n",
    "const persistentGraph = workflow.compile({ checkpointer: memory });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d8e1d",
   "metadata": {},
   "source": [
    "## Interacting with the Agent\n",
    "\n",
    "We can now interact with the agent. Between interactions you can get and update state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24711ca1-3fd8-46ca-b2c1-affa8cd45267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"user\", \"Hi I'm Jo.\" ]\n",
      "-----\n",
      "\n",
      "It's nice to meet you Jo! I'm an AI assistant here to help. How can I assist you today?\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let config = { configurable: { thread_id: \"conversation-num-1\" } };\n",
    "let inputs = { messages: [[\"user\", \"Hi I'm Jo.\"]] };\n",
    "for await (\n",
    "  const { messages } of await persistentGraph.stream(inputs, {\n",
    "    ...config,\n",
    "    streamMode: \"values\",\n",
    "  })\n",
    ") {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11210c6",
   "metadata": {},
   "source": [
    "See LangSmith example run here https://smith.langchain.com/public/b3feb09b-bcd2-4ad5-ad1d-414106148448/r\n",
    "\n",
    "Here you can see the \"agent\" node ran, and then our edge returned `__end__` so the graph stopped execution there.\n",
    "\n",
    "Let's check the current graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d017ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  messages: [\n",
       "    [ \u001b[32m\"user\"\u001b[39m, \u001b[32m\"Hi I'm Jo.\"\u001b[39m ],\n",
       "    AIMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: \u001b[32m\"It's nice to meet you Jo! I'm an AI assistant here to help. How can I assist you today?\"\u001b[39m,\n",
       "        tool_calls: [],\n",
       "        invalid_tool_calls: [],\n",
       "        additional_kwargs: {\n",
       "          id: \u001b[32m\"msg_014ivm19SVn9hD5vewa9Eawr\"\u001b[39m,\n",
       "          type: \u001b[32m\"message\"\u001b[39m,\n",
       "          role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "          usage: \u001b[36m[Object]\u001b[39m,\n",
       "          stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "        },\n",
       "        response_metadata: {\n",
       "          id: \u001b[32m\"msg_014ivm19SVn9hD5vewa9Eawr\"\u001b[39m,\n",
       "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "          usage: \u001b[36m[Object]\u001b[39m,\n",
       "          stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "        }\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"It's nice to meet you Jo! I'm an AI assistant here to help. How can I assist you today?\"\u001b[39m,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {\n",
       "        id: \u001b[32m\"msg_014ivm19SVn9hD5vewa9Eawr\"\u001b[39m,\n",
       "        type: \u001b[32m\"message\"\u001b[39m,\n",
       "        role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m379\u001b[39m, output_tokens: \u001b[33m27\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "      },\n",
       "      response_metadata: {\n",
       "        id: \u001b[32m\"msg_014ivm19SVn9hD5vewa9Eawr\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m379\u001b[39m, output_tokens: \u001b[33m27\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "      },\n",
       "      tool_calls: [],\n",
       "      invalid_tool_calls: []\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let checkpoint = await persistentGraph.getState(config);\n",
    "checkpoint.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849e28b",
   "metadata": {},
   "source": [
    "The current state is the two messages we've seen above, 1. the HumanMessage we sent in, 2. the AIMessage we got back from the model.\n",
    "\n",
    "The `next` values are empty since the graph has terminated (transitioned to the `__end__`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6df77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87346938",
   "metadata": {},
   "source": [
    "## Let's get it to execute a tool\n",
    "\n",
    "When we call the graph again, it will create a checkpoint after each internal execution step. Let's get it to run a tool, then look at the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8537fd9d-083c-4096-91c5-44a2e66b18c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"user\", \"What's the weather like in SF currently?\" ]\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    type: \"tool_use\",\n",
      "    id: \"toolu_01F1bGoXL4RmuwR7gMoMM4QM\",\n",
      "    name: \"search\",\n",
      "    input: { query: \"weather in san francisco\" }\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n",
      "[\"Cold, with a low of -78 ℃\"]\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    type: \"text\",\n",
      "    text: \"Hmm, that can't be right - San Francisco doesn't typically get that cold! Let me double check the cu\"... 20 more characters\n",
      "  },\n",
      "  {\n",
      "    type: \"tool_use\",\n",
      "    id: \"toolu_01VRrGkm3Lnar94uAqtgyHon\",\n",
      "    name: \"search\",\n",
      "    input: { query: \"current weather in san francisco\" }\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n",
      "[\"Cold, with a low of -78 ℃\"]\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    type: \"text\",\n",
      "    text: \"Ah, it seems the initial search result was incorrect. Let me try a more reliable weather source:\"\n",
      "  },\n",
      "  {\n",
      "    type: \"tool_use\",\n",
      "    id: \"toolu_01WXdj9fB1rHCvP1AFphDruX\",\n",
      "    name: \"search\",\n",
      "    input: { query: \"san francisco weather\" }\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n",
      "[\"Cold, with a low of -78 ℃\"]\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    type: \"text\",\n",
      "    text: \"That doesn't seem right at all. Let me try a different approach:\"\n",
      "  },\n",
      "  {\n",
      "    type: \"tool_use\",\n",
      "    id: \"toolu_01DfLiLesRNtLcThtD3ujnQL\",\n",
      "    name: \"search\",\n",
      "    input: { query: \"what is the current weather in san francisco\" }\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n",
      "[\"Cold, with a low of -78 ℃\"]\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    type: \"text\",\n",
      "    text: \"Hmm, I'm still not getting reliable weather information for San Francisco. Let me try a different se\"... 12 more characters\n",
      "  },\n",
      "  {\n",
      "    type: \"tool_use\",\n",
      "    id: \"toolu_015219GuQtaxV3kQ57CTMxdL\",\n",
      "    name: \"search\",\n",
      "    input: { query: \"current weather in san francisco\" }\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n",
      "[\"Cold, with a low of -78 ℃\"]\n",
      "-----\n",
      "\n",
      "I'm afraid the weather information I'm finding is not accurate. Would you mind if I try a different approach to get the current weather in San Francisco?\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = { messages: [[\"user\", \"What's the weather like in SF currently?\"]] };\n",
    "for await (\n",
    "  const { messages } of await persistentGraph.stream(inputs, {\n",
    "    ...config,\n",
    "    streamMode: \"values\",\n",
    "  })\n",
    ") {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc172a",
   "metadata": {},
   "source": [
    "See the trace of the above execution here: https://smith.langchain.com/public/0ef426fd-0da1-4c02-a50b-64ae1e68338e/r\n",
    "We can see it planned the tool execution (ie the \"agent\" node), then \"should_continue\" edge returned \"continue\" so we proceeded to \"action\" node, which executed the tool, and then \"agent\" node emitted the final response, which made \"should_continue\" edge return \"end\". Let's see how we can have more control over this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383edee-1a8c-4b66-b668-ee760918bede",
   "metadata": {},
   "source": [
    "### Pause before tools\n",
    "\n",
    "If you notice below, we now will add `interruptBefore=[\"action\"]` - this means that before any actions are taken we pause. This is a great moment to allow the user to correct and update the state! This is very useful when you want to have a human-in-the-loop to validate (and potentially change) the action to take. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1201189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemorySaver {\n",
       "  serde: { parse: \u001b[36m[AsyncFunction: load]\u001b[39m, stringify: \u001b[36m[Function: stringify]\u001b[39m },\n",
       "  storage: {}\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = new MemorySaver({\n",
    "    parse: load,\n",
    "    stringify: JSON.stringify,\n",
    "});\n",
    "const appWithInterrupt = workflow.compile({ checkpointer: memory, interruptBefore: [\"tools\", \"agent\"] });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdf5046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n",
      "-----\n",
      "\n",
      "foo\n",
      "-----\n",
      "\n",
      "foo\n",
      "-----\n",
      "\n",
      "foo\n",
      "-----\n",
      "\n",
      "foo\n",
      "-----\n",
      "\n",
      "foo\n",
      "-----\n",
      "\n",
      "foo\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "memory = new MemorySaver({\n",
    "  parse: load,\n",
    "  stringify: JSON.stringify,\n",
    "});\n",
    "const appWithInterrupt = workflow.compile({ checkpointer: memory, interruptBefore: [\"tools\"] });\n",
    "inputs = { messages: [[\"user\", \"What's the weather like in SF currently?\"]] };\n",
    "for await (\n",
    "  const { messages } of await appWithInterrupt.stream(inputs, {\n",
    "    ...config,\n",
    "    streamMode: \"values\",\n",
    "    interruptBefore:[\"tools\"],\n",
    "  })\n",
    ") {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41e2d0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let snapshot = await appWithInterrupt.getState(config);\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43897a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
