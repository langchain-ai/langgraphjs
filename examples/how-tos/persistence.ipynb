{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395cccb-a6d0-4d46-bad7-ed2d012af58a",
   "metadata": {},
   "source": [
    "# Persistence\n",
    "\n",
    "Many AI applications need memory to share context across multiple interactions. In LangGraph, memory is provided for any [StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph) through [Checkpointers](https://langchain-ai.github.io/langgraph/reference/checkpoints/).\n",
    "\n",
    "When creating any LangGraph workflow, you can set them up to persist their state by doing using the following:\n",
    "\n",
    "1. A [Checkpointer](https://langchain-ai.github.io/langgraphjs/reference/classes/index.BaseCheckpointSaver.html), such as the [MemorySaver](https://langchain-ai.github.io/langgraphjs/reference/classes/index.MemorySaver.html)\n",
    "2. Call `compile(checkpointer=myCheckpointer)` when compiling the graph.\n",
    "\n",
    "<!-- Example:\n",
    "```javascript\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "builder = StateGraph(....)\n",
    "# ... define the graph\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "...\n",
    "``` -->\n",
    "\n",
    "This works for [StateGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.StateGraph.html and all its subclasses, such as [MessageGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#messagegraph).\n",
    "\n",
    "Below is an example.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        In this how-to, we will create our agent from scratch to be transparent (but verbose). You can accomplish similar functionality using the <code>create_react_agent(model, tools=tool, checkpointer=checkpointer)</code> (<a href=\"https://langchain-ai.github.io/langgraphjs/reference/functions/prebuilt.createReactAgent.html\">API doc</a>) constructor. This may be more appropriate if you are used to LangChainâ€™s <a href=\"https://python.langchain.com/v0.1/docs/modules/agents/concepts/#agentexecutor\">AgentExecutor</a> class.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "This guide will use Anthropic's Claude model. We will optionally set our API key for [LangSmith tracing](https://smith.langchain.com/), which will give us best-in-class observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05706ae-f5c9-45e8-8c0a-2215703ee993",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"ANTHROPIC_API_KEY\", \"sk_...\");\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"sk_...\");\n",
    "// Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\");\n",
    "// Deno.env.set(\"LANGCHAIN_PROJECT\", \"Persistence: LangGraphJS\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47c4dc-cabe-4ee5-aaa8-9552f5d75ed2",
   "metadata": {},
   "source": [
    "## Define the state\n",
    "\n",
    "The state is the interface for all of the nodes in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abea6e1f-c21c-4dfe-a4cd-89326e625c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "interface AgentStateChannels {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => BaseMessage[];\n",
    "    default: () => BaseMessage[];\n",
    "  };\n",
    "  next: string;\n",
    "}\n",
    "\n",
    "// This defines the agent state\n",
    "const agentStateChannels: AgentStateChannels = {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),\n",
    "    default: () => [],\n",
    "  },\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408be71e-8d06-403a-8623-6e6c222c677a",
   "metadata": {},
   "source": [
    "## Set up the tools\n",
    "\n",
    "We will first define the tools we want to use. For this simple example, we will use create a placeholder search engine.\n",
    "However, it is really easy to create your own tools - see documentation [here](https://js.langchain.com/v0.2/docs/how_to/custom_tools) on how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae6c71e-10ce-4783-9dfc-49e5b750b269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ \u001b[32m\"The answer to your question lies within.\"\u001b[39m ]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const searchTool = new DynamicStructuredTool({\n",
    "  name: \"search\",\n",
    "  description: \"Use to surf the web\",\n",
    "  schema: z.object({\n",
    "    query: z.string().describe(\"The query to use in your search.\"),\n",
    "  }),\n",
    "  func: async ({ query }: { query: string }) => {\n",
    "    // This is a placeholder for the actual implementation\n",
    "    return [\"The answer to your question lies within.\"];\n",
    "  },\n",
    "});\n",
    "\n",
    "await searchTool.invoke({ query: \"What's the meaning of it all?\" });\n",
    "\n",
    "const tools = [searchTool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eae3ed-b322-4afe-9111-d7dc204fdb77",
   "metadata": {},
   "source": [
    "We can now wrap these tools in a simple [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/prebuilt.ToolNode.html). This object will actually run the tools (functions) whenever they are invoked by our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "638fa6e9-cb76-4838-bc8b-02edf7da5ecc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "exports is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: exports is not defined",
      "    at file:///Users/wfh/code/lc/langgraphjs/langgraph/dist/prebuilt/index.cjs:2:23"
     ]
    }
   ],
   "source": [
    "import { ToolNode } from \"../../langgraph/dist/prebuilt/index.cjs\";\n",
    "const toolNode = new ToolNode([tools]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c3bed2-e6cc-4e23-afae-50f482b0b763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"undefined\"\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94b49b-fb11-463c-b34c-9d66b5327678",
   "metadata": {},
   "source": [
    "## Set up the model\n",
    "\n",
    "Now we will load the [chat model]().\n",
    "https://js.langchain.com/v0.2/docs/concepts/#chat-models\n",
    "1. It should work with messages. We will represent all agent state in the form of messages, so it needs to be able to work well with them.\n",
    "2. It should work with tool calling. This means it should either be an OpenAI model or a model that exposes a similar interface.\n",
    "\n",
    "Note: these model requirements are not requirements for using LangGraph - they are just requirements for this one example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
