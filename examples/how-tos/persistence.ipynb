{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395cccb-a6d0-4d46-bad7-ed2d012af58a",
   "metadata": {},
   "source": [
    "# Persistence\n",
    "\n",
    "Many AI applications need memory to share context across multiple interactions. In LangGraph, memory is provided for any [StateGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.StateGraph.html) through [Checkpointers](https://langchain-ai.github.io/langgraphjs/reference/interfaces/index.Checkpoint.html).\n",
    "\n",
    "When creating any LangGraph workflow, you can set them up to persist their state by doing using the following:\n",
    "\n",
    "1. A [Checkpointer](https://langchain-ai.github.io/langgraphjs/reference/classes/index.BaseCheckpointSaver.html), such as the [MemorySaver](https://langchain-ai.github.io/langgraphjs/reference/classes/index.MemorySaver.html)\n",
    "2. Call `compile(checkpointer=myCheckpointer)` when compiling the graph.\n",
    "\n",
    "<!-- Example:\n",
    "```javascript\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "builder = StateGraph(....)\n",
    "# ... define the graph\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "...\n",
    "``` -->\n",
    "\n",
    "This works for [StateGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.StateGraph.html) and all its subclasses, such as [MessageGraph](https://langchain-ai.github.io/langgraphjs/reference/classes/index.MessageGraph.html).\n",
    "\n",
    "Below is an example.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        In this how-to, we will create our agent from scratch to be transparent (but verbose). You can accomplish similar functionality using the <code>create_react_agent(model, tools=tool, checkpointer=checkpointer)</code> (<a href=\"https://langchain-ai.github.io/langgraphjs/reference/functions/prebuilt.createReactAgent.html\">API doc</a>) constructor. This may be more appropriate if you are used to LangChain’s <a href=\"https://python.langchain.com/v0.1/docs/modules/agents/concepts/#agentexecutor\">AgentExecutor</a> class.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "## Setup\n",
    "\n",
    "This guide will use Anthropic's Claude model. We will optionally set our API key for [LangSmith tracing](https://smith.langchain.com/), which will give us best-in-class observability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05706ae-f5c9-45e8-8c0a-2215703ee993",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"ANTHROPIC_API_KEY\", \"sk_...\");\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"ls__...\");\n",
    "Deno.env.set(\"LANGCHAIN_CALLBACKS_BACKGROUND\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_PROJECT\", \"Persistence: LangGraphJS\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47c4dc-cabe-4ee5-aaa8-9552f5d75ed2",
   "metadata": {},
   "source": [
    "## Define the state\n",
    "\n",
    "The state is the interface for all of the nodes in our graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abea6e1f-c21c-4dfe-a4cd-89326e625c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "interface IState {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => BaseMessage[];\n",
    "    default: () => BaseMessage[];\n",
    "  };\n",
    "  next: string;\n",
    "}\n",
    "\n",
    "// This defines the agent state\n",
    "const State: IState = {\n",
    "  messages: {\n",
    "    value: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),\n",
    "    default: () => [],\n",
    "  },\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408be71e-8d06-403a-8623-6e6c222c677a",
   "metadata": {},
   "source": [
    "## Set up the tools\n",
    "\n",
    "We will first define the tools we want to use. For this simple example, we will use create a placeholder search engine.\n",
    "However, it is really easy to create your own tools - see documentation [here](https://js.langchain.com/v0.2/docs/how_to/custom_tools) on how to do that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae6c71e-10ce-4783-9dfc-49e5b750b269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ \u001b[32m\"Cold, with a low of -78 ℃\"\u001b[39m ]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const searchTool = new DynamicStructuredTool({\n",
    "  name: \"search\",\n",
    "  description:\n",
    "    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n",
    "  schema: z.object({\n",
    "    query: z.string().describe(\"The query to use in your search.\"),\n",
    "  }),\n",
    "  func: async ({ query }: { query: string }) => {\n",
    "    // This is a placeholder for the actual implementation\n",
    "    return [\"Cold, with a low of -78 ℃\"];\n",
    "  },\n",
    "});\n",
    "\n",
    "await searchTool.invoke({ query: \"What's the weather like?\" });\n",
    "\n",
    "const tools = [searchTool];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eae3ed-b322-4afe-9111-d7dc204fdb77",
   "metadata": {},
   "source": [
    "We can now wrap these tools in a simple [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/prebuilt.ToolNode.html). This object will actually run the tools (functions) whenever they are invoked by our LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638fa6e9-cb76-4838-bc8b-02edf7da5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const toolNode = new ToolNode(tools);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94b49b-fb11-463c-b34c-9d66b5327678",
   "metadata": {},
   "source": [
    "## Set up the model\n",
    "\n",
    "Now we will load the [chat model]().\n",
    "https://js.langchain.com/v0.2/docs/concepts/#chat-models\n",
    "\n",
    "1. It should work with messages. We will represent all agent state in the form of messages, so it needs to be able to work well with them.\n",
    "2. It should work with [tool calling](https://js.langchain.com/v0.2/docs/how_to/tool_calling/#passing-tools-to-llms), meaning it can return function arguments in its response.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Note</p>\n",
    "    <p>\n",
    "        These model requirements are not general requirements for using LangGraph - they are just requirements for this one example.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a00435f-5e80-4a3e-a873-b308b1f781db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const model = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975c1ab-fcac-4448-a0cd-7969ae6f4e45",
   "metadata": {},
   "source": [
    "After we've done this, we should make sure the model knows that it has these tools available to call. We can do this by calling [bindTools](https://v01.api.js.langchain.com/classes/langchain_core_language_models_chat_models.BaseChatModel.html#bindTools).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d4a57f-e7d0-48d7-8626-e83185c1236d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  tools: [\n",
       "    {\n",
       "      name: \u001b[32m\"search\"\u001b[39m,\n",
       "      description: \u001b[32m\"Use to surf the web, fetch current information, check the weather, and retrieve other information.\"\u001b[39m,\n",
       "      input_schema: {\n",
       "        type: \u001b[32m\"object\"\u001b[39m,\n",
       "        properties: { query: \u001b[36m[Object]\u001b[39m },\n",
       "        required: [ \u001b[32m\"query\"\u001b[39m ],\n",
       "        additionalProperties: \u001b[33mfalse\u001b[39m,\n",
       "        \u001b[32m\"$schema\"\u001b[39m: \u001b[32m\"http://json-schema.org/draft-07/schema#\"\u001b[39m\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const boundModel = model.bindTools(tools);\n",
    "boundModel.kwargs;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0626d5-faae-4e24-bf1b-f01357c28627",
   "metadata": {},
   "source": [
    "## Define the graph\n",
    "\n",
    "We can now put it all together. We will run it first without a checkpointer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812b6d4b-9db7-490b-adae-ad9d933da56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"\"\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { StateGraph, END, START } from \"@langchain/langgraph\";\n",
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const routeMessage = (state: { messages: Array<BaseMessage> }) => {\n",
    "  const { messages } = state;\n",
    "  const lastMessage = messages[messages.length - 1];\n",
    "  // If no tools are called, we can finish (respond to the user)\n",
    "  if (!lastMessage.tool_calls.length) {\n",
    "    return END;\n",
    "  }\n",
    "  // Otherwise if there is, we continue and call the tools\n",
    "  return \"tools\";\n",
    "};\n",
    "\n",
    "const callModel = async (state: { messages: Array<BaseMessage> }) => {\n",
    "  const { messages } = state;\n",
    "  const response = await boundModel.invoke(messages);\n",
    "  return { messages: [response] };\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph({\n",
    "  channels: State,\n",
    "});\n",
    "\n",
    "// Define the two nodes we will cycle between\n",
    "workflow.addNode(\"agent\", callModel);\n",
    "workflow.addNode(\"tools\", toolNode);\n",
    "\n",
    "// Set the entrypoint as `agent`\n",
    "workflow.addEdge(START, \"agent\");\n",
    "workflow.addConditionalEdges(\"agent\", routeMessage);\n",
    "workflow.addEdge(\"tools\", \"agent\");\n",
    "\n",
    "const graph = workflow.compile();\n",
    "(\"\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584468e0-c824-4401-acc5-6384e893830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"user\"\u001b[39m, \u001b[32m\"Hi I'm Yu, niced to meet you.\"\u001b[39m ]\n",
      "-----\n",
      "\n",
      "It's nice to meet you too, Yu! I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. I'm here to assist you with any questions or tasks you may have. Please let me know how I can be of help!\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let inputs = { messages: [[\"user\", \"Hi I'm Yu, niced to meet you.\"]] };\n",
    "\n",
    "for await (const { messages } of await graph.stream(inputs, {\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4db9d23-7ede-42d5-9288-0c31fe1f028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"user\"\u001b[39m, \u001b[32m\"Remember my name?\"\u001b[39m ]\n",
      "-----\n",
      "\n",
      "I'm afraid I don't actually have a way to remember your name, since this is a new conversation. As an AI assistant without persistent memory, I don't have a way to keep track of details about previous interactions. Could you please provide your name again so I can refer to you properly?\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = { messages: [[\"user\", \"Remember my name?\"]] };\n",
    "\n",
    "for await (const { messages } of await graph.stream(inputs, {\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312879af-f504-4888-a737-bf74487b81ef",
   "metadata": {},
   "source": [
    "## Add Memory\n",
    "\n",
    "Let's try it again with a checkpointer. We will use the SqliteSaver, which will \"save\" checkpoints in-memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef68c6a0-b4c8-4e71-acdb-7edd9023f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "import { load } from \"@langchain/core/load\";\n",
    "\n",
    "// Here we only save in-memory\n",
    "const memory = new MemorySaver({\n",
    "  parse: load,\n",
    "  stringify: JSON.stringify,\n",
    "});\n",
    "const persistentGraph = workflow.compile({ checkpointer: memory });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24711ca1-3fd8-46ca-b2c1-affa8cd45267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"user\"\u001b[39m, \u001b[32m\"Hi I'm Jo, niced to meet you.\"\u001b[39m ]\n",
      "-----\n",
      "\n",
      "It's nice to meet you too, Jo! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know if there's anything I can assist you with.\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let config = { configurable: { thread_id: \"conversation-num-1\" } };\n",
    "inputs = { messages: [[\"user\", \"Hi I'm Jo, niced to meet you.\"]] };\n",
    "for await (const { messages } of await persistentGraph.stream(inputs, {\n",
    "  ...config,\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8537fd9d-083c-4096-91c5-44a2e66b18c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"user\"\u001b[39m, \u001b[32m\"Remember my name?\"\u001b[39m ]\n",
      "-----\n",
      "\n",
      "Yes, I remember your name is Jo. It's nice to meet you Jo!\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = { messages: [[\"user\", \"Remember my name?\"]] };\n",
    "for await (const { messages } of await persistentGraph.stream(inputs, {\n",
    "  ...config,\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ae8c30-b462-4f61-94d5-3b361c2719c2",
   "metadata": {},
   "source": [
    "## New Conversational Thread\n",
    "\n",
    "If we want to start a new conversation, we can pass in a different **`thread_id`**. Poof! All the memories are gone (just kidding, they'll always live in that other thread)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf3a5244-7ff6-4ece-95fe-240341992863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ configurable: { thread_id: \u001b[32m\"conversation-2\"\u001b[39m } }"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = { configurable: { thread_id: \"conversation-2\" } };\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c183a4a2-57a3-4ee4-89e4-f695e1a15295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"user\"\u001b[39m, \u001b[32m\"you forgot?\"\u001b[39m ]\n",
      "-----\n",
      "\n",
      "I'm afraid I don't have enough context to understand what you mean by \"you forgot?\". Could you please provide more details about what you are referring to? I'd be happy to try and assist you once I have a better understanding of your question or concern.\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = { messages: [[\"user\", \"you forgot?\"]] };\n",
    "for await (const { messages } of await persistentGraph.stream(inputs, {\n",
    "  ...config,\n",
    "  streamMode: \"values\",\n",
    "})) {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383edee-1a8c-4b66-b668-ee760918bede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
