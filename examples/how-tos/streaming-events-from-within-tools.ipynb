{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23ced4e-dc29-43be-9f94-0c36bb181b8a",
   "metadata": {},
   "source": [
    "# How to stream events from within a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044eeb8-4074-4f9c-8a62-962488744557",
   "metadata": {},
   "source": [
    "If your LangGraph graph needs to use tools that call LLMs (or any other LangChain `Runnable` objects -- other graphs, LCEL chains, retrievers, etc.), you might want to stream events from the underlying `Runnable`. This guide shows how you can do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f60af-43ea-4aa6-847a-df8cc47065f5",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "```bash\n",
    "npm install @langchain/langgraph @langchain/anthropic zod\n",
    "```\n",
    "\n",
    "```typescript\n",
    "process.env.ANTHROPIC_API_KEY = 'YOUR_API_KEY'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d02ebb-c2e1-4ef7-b187-810d55139317",
   "metadata": {},
   "source": [
    "## Define graph and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a1760-a063-4d05-8c6f-9d16bc31fa82",
   "metadata": {},
   "source": [
    "We'll use a prebuilt ReAct agent for this guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cb38dd9-74d8-456d-9e39-4655f2bf3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const model = new ChatAnthropic({\n",
    "  model: \"claude-3-5-sonnet-20240620\",\n",
    "  temperature: 0,\n",
    "})\n",
    "\n",
    "const getItems = tool(\n",
    "  async (input, config) => {\n",
    "    const template = ChatPromptTemplate.fromMessages([\n",
    "      [\n",
    "        \"human\",\n",
    "        \"Can you tell me what kind of items i might find in the following place: '{place}'. \" +\n",
    "        \"List at least 3 such items separating them by a comma. And include a brief description of each item..\",\n",
    "      ]\n",
    "    ]);\n",
    "\n",
    "    const modelWithConfig = model.withConfig({\n",
    "      runName: \"Get Items LLM\",\n",
    "      tags: [\"tool_llm\"],\n",
    "    });\n",
    "\n",
    "    const chain = template.pipe(modelWithConfig);\n",
    "    const result = await chain.invoke(input, config);\n",
    "    return result.content;\n",
    "  },\n",
    "  {\n",
    "    name: \"get_items\",\n",
    "    description: \"Use this tool to look up which items are in the given place.\",\n",
    "    schema: z.object({\n",
    "      place: z.string(),\n",
    "    }),\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17279b8a-049d-483d-af63-8a875098e71f",
   "metadata": {},
   "source": [
    "We're adding a custom tag (`tool_llm`) to our LLM runnable within the tool. This will allow us to filter events that we'll stream from the compiled graph (`agent`) Runnable below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7254310e-7016-45f7-9795-6d52a1160086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const agent = createReactAgent({\n",
    "  llm: model,\n",
    "  tools: [getItems],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d88960-a66b-4699-adee-c12d40b4318a",
   "metadata": {},
   "source": [
    "## Stream events from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "let finalEvent\n",
    "for await (const event of agent.streamEvents(\n",
    "  {\n",
    "    messages: [[\"human\", \"what items are on the shelf?\"]],\n",
    "  },\n",
    "  {\n",
    "    version: \"v2\"\n",
    "  },\n",
    "  {\n",
    "    includeTags: [\"tool_llm\"],\n",
    "  }\n",
    ")) {\n",
    "  console.log(event.data);\n",
    "  finalEvent = event\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8902e-935b-4724-8b5d-551b7674fd34",
   "metadata": {},
   "source": [
    "Let's inspect the last event to get the final list of messages from the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca382c1f-b1c7-4c8a-bd9b-7a873b891b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "const finalMessages = finalEvent.data.output.messages;\n",
    "console.dir(finalMessages.map((msg) => ({\n",
    "  type: msg._getType(),\n",
    "  content: msg.content,\n",
    "  tool_calls: msg.tool_calls,\n",
    "})), { depth: null });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9457c-5665-4cd5-9a99-d54c84270616",
   "metadata": {},
   "source": [
    "You can see that the content of the `ToolMessage` is the same as the output we streamed above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
