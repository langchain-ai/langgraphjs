{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to cache expensive nodes\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Prerequisites</p>\n",
    "    <p>\n",
    "        This guide assumes familiarity with the following:\n",
    "        <ul>\n",
    "            <li>\n",
    "                <a href=\"/langgraphjs/concepts/low_level/#graphs\">\n",
    "                    Graphs\n",
    "                </a>\n",
    "            </li>\n",
    "            <li>\n",
    "                <a href=\"/langgraphjs/concepts/low_level/#nodes\">\n",
    "                    Nodes\n",
    "                </a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "Node caching is useful in cases where you want to avoid repeating operations, like when doing something expensive (either in terms of time or cost). LangGraph lets you add individualized caching policies to nodes in a graph.\n",
    "\n",
    "To configure a cache policy, pass the `cachePolicy` parameter to the `addNode` method. In the following example, we specify a cache policy with a time to live (TTL) of 120 seconds and default key serialization function. Then, to enable node-level caching for a graph, set the `cache` argument when compiling the graph. The example below uses `InMemoryCache` to set up a graph with in-memory cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StateGraph, Annotation, START } from \"@langchain/langgraph\";\n",
    "import { InMemoryCache } from \"@langchain/langgraph-checkpoint\";\n",
    "\n",
    "const StateAnnotation = Annotation.Root({\n",
    "  items: Annotation<string[]>({\n",
    "    default: () => [],\n",
    "    reducer: (acc, item) => [...acc, ...item],\n",
    "  }),\n",
    "});\n",
    "\n",
    "const cache = new InMemoryCache();\n",
    "\n",
    "const graph = new StateGraph(StateAnnotation)\n",
    "  .addNode(\n",
    "    \"node\",\n",
    "    async () => {\n",
    "      // Simulate an expensive operation\n",
    "      await new Promise((resolve) => setTimeout(resolve, 3000));\n",
    "      return { items: [\"Hello, how are you?\"] };\n",
    "    },\n",
    "    { cachePolicy: true }\n",
    "  )\n",
    "  .addEdge(START, \"node\")\n",
    "  .compile({ cache });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial run will take 3 seconds since the cache is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ items: [ 'Hello!', 'Hello, how are you?' ] }\n"
     ]
    }
   ],
   "source": [
    "const firstRun = await graph.invoke({ items: [\"Hello!\"] });\n",
    "firstRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequent runs will be cached and yielded immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ items: [ 'Hello!', 'Hello, how are you?' ] }\n"
     ]
    }
   ],
   "source": [
    "const secondRun = await graph.invoke({ items: [\"Hello!\"] });\n",
    "secondRun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
