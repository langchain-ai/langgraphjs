{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pass runtime values to tools\n",
    "\n",
    "This guide shows how to define tools that depend on dynamically defined variables. These values are provided by your program, not by the LLM.\n",
    "\n",
    "Tools can access the [config.configurable](https://langchain-ai.github.io/langgraphjs/reference/interfaces/langgraph.LangGraphRunnableConfig.html) field for values like user IDs that are known when a graph is initially executed, as well as managed values from the [store](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.BaseStore.html) for persistence across threads.\n",
    "\n",
    "However, it can be convenient to access intermediate runtime values which are not known ahead of time, but are progressively generated as a graph executes, such as the current graph state. This guide will cover two techniques for this: context variables and closures.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install the following to run this guide:\n",
    "\n",
    "```bash\n",
    "npm install @langchain/langgraph @langchain/openai @langchain/core\n",
    "```\n",
    "\n",
    "Next, configure your environment to connect to your model provider.\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=your-api-key\n",
    "```\n",
    "\n",
    "Optionally, set your API key for [LangSmith tracing](https://smith.langchain.com/), which will give us best-in-class observability.\n",
    "\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\n",
    "export LANGCHAIN_API_KEY=your-api-key\n",
    "```\n",
    "\n",
    "## Context variables\n",
    "\n",
    "[Context variables](https://js.langchain.com/docs/how_to/tool_runtime#using-context-variables) are a powerful feature that allows you to set values at a higher level of your application, then access them within child runnable (such as tools) called from that level.\n",
    "\n",
    "These variables are scoped and accessible to child runnables, including tools. They work outside of traditional scoping rules, so you donâ€™t need to have a direct reference to the declared variable to access it.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Compatibility</p>\n",
    "    <p>\n",
    "        This functionality was added in <code>@langchain/core>=0.3.10</code>. If you are using the LangSmith SDK separately in your project, we also recommend upgrading to <code>langsmith>=0.1.65</code>. For help upgrading, see <a href=\"/langgraphjs/how-tos/manage-ecosystem-dependencies/\">this guide</a>.\n",
    "    </p>\n",
    "    <p>\n",
    "        It also requires <a href=\"https://nodejs.org/api/async_hooks.html\"><code>async_hooks</code></a> support, which is supported in many popular JavaScript environments (such as Node.js, Deno, and Cloudflare Workers), but not all of them (mainly web browsers).\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "Let's define a tool that an LLM can use to update pet preferences for a user. The tool will retrieve the current state of the graph from the current context.\n",
    "\n",
    "### Define the agent state\n",
    "\n",
    "For this example, the state we will track will just be a list of messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { Annotation } from \"@langchain/langgraph\";\n",
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const StateAnnotation = Annotation.Root({\n",
    "  messages: Annotation<BaseMessage[]>({\n",
    "    reducer: (x, y) => x.concat(y),\n",
    "  }),\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, declare a tool as shown below. The tool receives values in three different ways:\n",
    "\n",
    "1. It will receive a generated list of `pets` from the LLM in its `input`.\n",
    "2. It will pull a `userId` populated from the initial graph invocation.\n",
    "3. It will get the current state of the graph at runtime from a context variable.\n",
    "\n",
    "It will then use LangGraph's [cross-thread persistence](https://langchain-ai.github.io/langgraphjs/how-tos/cross-thread-persistence/) to save preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { getContextVariable } from \"@langchain/core/context\";\n",
    "import { LangGraphRunnableConfig } from \"@langchain/langgraph\";\n",
    "\n",
    "const updateFavoritePets = tool(async (input, config: LangGraphRunnableConfig) => {\n",
    "  // Fetch the current state of the graph that is calling the tool.\n",
    "  // We will set this explicitly in each node that calls this tool.\n",
    "  const currentState = getContextVariable(\"currentState\");\n",
    "  // Some arguments are populated by the LLM; these are included in the schema below\n",
    "  const { pets } = input;\n",
    "  // Others (such as a UserID) are best provided via the config\n",
    "  // This is set when when invoking or streaming the graph\n",
    "  const userId = config.configurable?.userId;\n",
    "  // LangGraph's managed key-value store is also accessible via the config\n",
    "  const store = config.store;\n",
    "  await store.put([userId, \"pets\"], \"names\", pets);\n",
    "  // Store the initial input message from the user as a note.\n",
    "  // Using the same key will override previous values - you could\n",
    "  // use something different if you wanted to store many interactions.\n",
    "  await store.put([userId, \"pets\"], \"context\", currentState.messages[0].content);\n",
    "\n",
    "  return \"update_favorite_pets called.\";\n",
    "},\n",
    "{\n",
    "  // The LLM \"sees\" the following schema:\n",
    "  name: \"update_favorite_pets\",\n",
    "  description: \"add to the list of favorite pets.\",\n",
    "  schema: z.object({\n",
    "    pets: z.array(z.string()),\n",
    "  }),\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the tool call schema, which is what is passed to the model for tool-calling, only `pets` is being passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  type: 'object',\n",
      "  properties: { pets: { type: 'array', items: [Object] } },\n",
      "  required: [ 'pets' ],\n",
      "  additionalProperties: false,\n",
      "  '$schema': 'http://json-schema.org/draft-07/schema#'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "\n",
    "console.log(zodToJsonSchema(updateFavoritePets.schema));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also declare another tool so that our agent can retrieve previously set preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "const getFavoritePets = tool(\n",
    "  async (_, config: LangGraphRunnableConfig) => {\n",
    "    const userId = config.configurable?.userId;\n",
    "    // LangGraph's managed key-value store is also accessible via the config\n",
    "    const store = config.store;\n",
    "    const petNames = await store.get([userId, \"pets\"], \"names\");\n",
    "    const context = await store.get([userId, \"pets\"], \"context\");\n",
    "    return JSON.stringify({\n",
    "      pets: petNames.value,\n",
    "      context: context.value,\n",
    "    });\n",
    "  },\n",
    "  {\n",
    "    // The LLM \"sees\" the following schema:\n",
    "    name: \"get_favorite_pets\",\n",
    "    description: \"retrieve the list of favorite pets for the given user.\",\n",
    "    schema: z.object({}),\n",
    "  }\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the nodes\n",
    "\n",
    "We now need to define a few different nodes in our graph.\n",
    "\n",
    "1. The agent: responsible for deciding what (if any) actions to take.\n",
    "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action. It will also set the current state as a context variable.\n",
    "\n",
    "We will also need to define some edges.\n",
    "\n",
    "1. After the agent is called, we should either invoke the tool node or finish.\n",
    "2. After the tool node have been invoked, it should always go back to the agent to decide what to do next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  END,\n",
    "  START,\n",
    "  StateGraph,\n",
    "  MemorySaver,\n",
    "  InMemoryStore,\n",
    "} from \"@langchain/langgraph\";\n",
    "import { AIMessage } from \"@langchain/core/messages\";\n",
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "import { setContextVariable } from \"@langchain/core/context\";\n",
    "\n",
    "const model = new ChatOpenAI({ model: \"gpt-4o\" });\n",
    "\n",
    "const tools = [getFavoritePets, updateFavoritePets];\n",
    "\n",
    "const routeMessage = (state: typeof StateAnnotation.State) => {\n",
    "  const { messages } = state;\n",
    "  const lastMessage = messages[messages.length - 1] as AIMessage;\n",
    "  // If no tools are called, we can finish (respond to the user)\n",
    "  if (!lastMessage?.tool_calls?.length) {\n",
    "    return END;\n",
    "  }\n",
    "  // Otherwise if there is, we continue and call the tools\n",
    "  return \"tools\";\n",
    "};\n",
    "\n",
    "const callModel = async (state: typeof StateAnnotation.State) => {\n",
    "  const { messages } = state;\n",
    "  const modelWithTools = model.bindTools(tools);\n",
    "  const responseMessage = await modelWithTools.invoke([\n",
    "    {\n",
    "      role: \"system\",\n",
    "      content: \"You are a personal assistant. Store any preferences the user tells you about.\"\n",
    "    },\n",
    "    ...messages\n",
    "  ]);\n",
    "  return { messages: [responseMessage] };\n",
    "};\n",
    "\n",
    "const toolNodeWithGraphState = async (state: typeof StateAnnotation.State) => {\n",
    "  // We set a context variable before invoking the tool node and running our tool.\n",
    "  setContextVariable(\"currentState\", state);\n",
    "  const toolNodeWithConfig = new ToolNode(tools);\n",
    "  return toolNodeWithConfig.invoke(state);\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph(StateAnnotation)\n",
    "  .addNode(\"agent\", callModel)\n",
    "  .addNode(\"tools\", toolNodeWithGraphState)\n",
    "  .addEdge(START, \"agent\")\n",
    "  .addConditionalEdges(\"agent\", routeMessage)\n",
    "  .addEdge(\"tools\", \"agent\");\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "const store = new InMemoryStore();\n",
    "\n",
    "const graph = workflow.compile({ checkpointer: memory, store: store });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import * as tslab from \"tslab\";\n",
    "\n",
    "const graphViz = graph.getGraph();\n",
    "const image = await graphViz.drawMermaidPng();\n",
    "const arrayBuffer = await image.arrayBuffer();\n",
    "\n",
    "await tslab.display.png(new Uint8Array(arrayBuffer));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it!\n",
    "\n",
    "Let's use our graph now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AHcDfVrNHLi0DVBtW84UapOoeAP1t\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_L3pw6ipwtBxdudekgCymgcBt\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 19,\n",
      "          \"promptTokens\": 102,\n",
      "          \"totalTokens\": 121\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_6b68a8204b\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"update_favorite_pets\",\n",
      "          \"args\": {\n",
      "            \"pets\": \"[Array]\"\n",
      "          },\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_L3pw6ipwtBxdudekgCymgcBt\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 102,\n",
      "        \"output_tokens\": 19,\n",
      "        \"total_tokens\": 121\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: tools\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    ToolMessage {\n",
      "      \"content\": \"update_favorite_pets called.\",\n",
      "      \"name\": \"update_favorite_pets\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_L3pw6ipwtBxdudekgCymgcBt\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AHcDfhVBJjGpk3Bdxw1tDQCZxqci5\",\n",
      "      \"content\": \"I've added \\\"terrier\\\" to your list of favorite pets! If there's anything else you would like to share or update, feel free to let me know.\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 33,\n",
      "          \"promptTokens\": 139,\n",
      "          \"totalTokens\": 172\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_6b68a8204b\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 139,\n",
      "        \"output_tokens\": 33,\n",
      "        \"total_tokens\": 172\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let inputs = { messages: [{ role: \"user\", content: \"My favorite pet is a terrier. I saw a cute one on Twitter.\" }] };\n",
    "let config = {\n",
    "  configurable: {\n",
    "    thread_id: \"1\",\n",
    "    userId: \"a-user\"\n",
    "  }\n",
    "};\n",
    "let stream = await graph.stream(inputs, config);\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  for (const [node, values] of Object.entries(chunk)) {\n",
    "    console.log(`Output from node: ${node}`);\n",
    "    console.log(\"---\");\n",
    "    console.log(values);\n",
    "    console.log(\"\\n====\\n\");\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now verify it can properly fetch the stored preferences and cite where it got the information from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AHcDgeIcrobhGEwsuuH0yI4YoEKbo\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_1vtxWaH6Xhg8uwWo1M2Y5gOg\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 13,\n",
      "          \"promptTokens\": 103,\n",
      "          \"totalTokens\": 116\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_6b68a8204b\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"get_favorite_pets\",\n",
      "          \"args\": {},\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_1vtxWaH6Xhg8uwWo1M2Y5gOg\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 103,\n",
      "        \"output_tokens\": 13,\n",
      "        \"total_tokens\": 116\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: tools\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    ToolMessage {\n",
      "      \"content\": \"{\\\"pets\\\":[\\\"terrier\\\"],\\\"context\\\":\\\"My favorite pet is a terrier. I saw a cute one on Twitter.\\\"}\",\n",
      "      \"name\": \"get_favorite_pets\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_1vtxWaH6Xhg8uwWo1M2Y5gOg\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AHcDhsL27h4nI441ZPRBs8FDPoo5a\",\n",
      "      \"content\": \"Your favorite pet is a terrier. You mentioned this when you said, \\\"My favorite pet is a terrier. I saw a cute one on Twitter.\\\"\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 33,\n",
      "          \"promptTokens\": 153,\n",
      "          \"totalTokens\": 186\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_6b68a8204b\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 153,\n",
      "        \"output_tokens\": 33,\n",
      "        \"total_tokens\": 186\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = { messages: [{ role: \"user\", content: \"What're my favorite pets and what did I say when I told you about them?\" }] };\n",
    "config = {\n",
    "  configurable: {\n",
    "    thread_id: \"2\", // New thread ID, so the conversation history isn't present.\n",
    "    userId: \"a-user\"\n",
    "  }\n",
    "};\n",
    "\n",
    "stream = await graph.stream(inputs, {\n",
    "  ...config\n",
    "});\n",
    "\n",
    "for await (\n",
    "  const chunk of stream\n",
    ") {\n",
    "  for (const [node, values] of Object.entries(chunk)) {\n",
    "    console.log(`Output from node: ${node}`);\n",
    "    console.log(\"---\");\n",
    "    console.log(values);\n",
    "    console.log(\"\\n====\\n\");\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the agent is able to properly cite that the information came from Twitter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closures\n",
    "\n",
    "If you cannot use context variables in your environment, you can use [closures](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures) to create tools with access to dynamic content. Here is a high-level example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generateTools(state: typeof StateAnnotation.State) {\n",
    "  const updateFavoritePets = tool(\n",
    "    async (input, config: LangGraphRunnableConfig) => {\n",
    "      // Some arguments are populated by the LLM; these are included in the schema below\n",
    "      const { pets } = input;\n",
    "      // Others (such as a UserID) are best provided via the config\n",
    "      // This is set when when invoking or streaming the graph\n",
    "      const userId = config.configurable?.userId;\n",
    "      // LangGraph's managed key-value store is also accessible via the config\n",
    "      const store = config.store;\n",
    "      await store.put([userId, \"pets\"], \"names\", pets )\n",
    "      await store.put([userId, \"pets\"], \"context\", {content: state.messages[0].content})\n",
    "\n",
    "      return \"update_favorite_pets called.\";\n",
    "    },\n",
    "    {\n",
    "      // The LLM \"sees\" the following schema:\n",
    "      name: \"update_favorite_pets\",\n",
    "      description: \"add to the list of favorite pets.\",\n",
    "      schema: z.object({\n",
    "        pets: z.array(z.string()),\n",
    "      }),\n",
    "    }\n",
    "  );\n",
    "  return [updateFavoritePets];\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, when laying out your graph, you will need to call the above method whenever you bind or invoke tools. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "const toolNodeWithClosure = async (state: typeof StateAnnotation.State) => {\n",
    "  // We fetch the tools any time this node is reached to\n",
    "  // form a closure and let it access the latest messages\n",
    "  const tools = generateTools(state);\n",
    "  const toolNodeWithConfig = new ToolNode(tools);\n",
    "  return toolNodeWithConfig.invoke(state);\n",
    "};"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
