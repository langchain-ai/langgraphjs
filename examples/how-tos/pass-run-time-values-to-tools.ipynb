{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pass runtime values tools\n",
    "\n",
    "This guide shows how to define tools that depend on dynamically defined variables provided, configuration, graph state, Storage, or other variables. These values are provided by your program, not by the LLM.\n",
    "\n",
    "Tools can access the [config](https://langchain-ai.github.io/langgraphjs/reference/interfaces/langgraph.LangGraphRunnableConfig.html) for configurable values like user IDs as well as managed values like the [store](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.BaseStore.html).\n",
    "\n",
    "To inject other arbitrary dependencies, such as graph state, the primary technique is to use [closures](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures) to create tools with access to dynamic content. Here's a brief example:\n",
    "\n",
    "```js\n",
    "function generateTools(state: typeof StateAnnotation.State) {\n",
    "  const updateFavoritePets = tool(\n",
    "    async (input, config) => {\n",
    "      // Some arguments are populated by the LLM; these are included in the schema below\n",
    "      const { pets } = input;\n",
    "      // Others (such as a UserID) are best provided via the config\n",
    "      // This is set when when invoking or streaming the graph\n",
    "      const userId = config.configurable?.userId; /\n",
    "      // LangGraph's managed key-value store is also accessible via the config\n",
    "      const store = config.store as BaseStore;\n",
    "      await store.put([userId, \"pets\"], \"names\", pets )\n",
    "      await store.put([userId, \"notes\"], uuidv4(), {content: state.messages[state.messages.length - 1].content})\n",
    "\n",
    "      return \"update_favorite_pets called.\";\n",
    "    },\n",
    "    {\n",
    "      // The LLM \"sees\" the following schema:\n",
    "      name: \"update_favorite_pets\",\n",
    "      description: \"add to the list of favorite pets.\",\n",
    "      schema: z.object({\n",
    "        pets: z.array(z.string()),\n",
    "      }),\n",
    "    }\n",
    "  );\n",
    "  return [updateFavoritePets];\n",
    "}\n",
    "```\n",
    "\n",
    "The following examples will elaborate further on these two techniques.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Prerequisites</p>\n",
    "    <p>\n",
    "        This guide is written for those using **tool calling in LangChain**; you can also use tool calling more in LangGraph using your provider SDK without losing any of LangGraph's core features. While this guide will be less applicable, you may consider adapting the general approach of using closures to inject dependencies into tools.\n",
    "    </p>\n",
    "</div> \n",
    "\n",
    "## Setup\n",
    "\n",
    "Install the following to run this guide:\n",
    "\n",
    "```bash\n",
    "npm install @langchain/langgraph @langchain/openai @langchain/core\n",
    "```\n",
    "\n",
    "Next, configure your environment to connect to your model provider.\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=your-api-key\n",
    "```\n",
    "\n",
    "Optionally, set your API key for [LangSmith tracing](https://smith.langchain.com/), which will give us best-in-class observability.\n",
    "\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\n",
    "export LANGCHAIN_API_KEY=your-api-key\n",
    "```\n",
    "\n",
    "## Accessing state\n",
    "\n",
    "For our first example, we'll want our tool to take graph state as an input, but we don't want the model to try to generate this input when calling the tool. In order to pass runtime values to our tools, we are going to wrap them in a factory function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the agent state\n",
    "\n",
    "For this example, the state we will track will just be a list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { Annotation } from \"@langchain/langgraph\";\n",
    "import { BaseMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const AgentState = Annotation.Root({\n",
    "  messages: Annotation<BaseMessage[]>({\n",
    "    reducer: (x, y) => x.concat(y),\n",
    "  }),\n",
    "});\n",
    "\n",
    "const State = AgentState.State;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { LangGraphRunnableConfig } from \"@langchain/langgraph\";\n",
    "import { BaseStore } from \"@langchain/langgraph\";\n",
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "function generateTools(state: typeof State) {\n",
    "  const updateFavoritePets = tool(\n",
    "    async (input, config: LangGraphRunnableConfig) => {\n",
    "      // Some arguments are populated by the LLM; these are included in the schema below\n",
    "      const { pets } = input;\n",
    "      // Others (such as a UserID) are best provided via the config\n",
    "      // This is set when when invoking or streaming the graph\n",
    "      const userId = config.configurable?.userId;\n",
    "      // LangGraph's managed key-value store is also accessible via the config\n",
    "      const store = config.store as BaseStore;\n",
    "      await store.put([userId, \"pets\"], \"names\", pets);\n",
    "      await store.put([userId, \"notes\"], uuidv4(), {\n",
    "        content: state.messages[state.messages.length - 1].content,\n",
    "      });\n",
    "\n",
    "      return \"update_favorite_pets called.\";\n",
    "    },\n",
    "    {\n",
    "      // The LLM \"sees\" the following schema:\n",
    "      name: \"update_favorite_pets\",\n",
    "      description: \"add to the list of favorite pets.\",\n",
    "      schema: z.object({\n",
    "        pets: z.array(z.string()),\n",
    "      }),\n",
    "    }\n",
    "  );\n",
    "  const getFavoritePets = tool(\n",
    "    async (_, config: LangGraphRunnableConfig) => {\n",
    "      const userId = config.configurable?.userId;\n",
    "      // LangGraph's managed key-value store is also accessible via the config\n",
    "      const store = config.store as BaseStore;\n",
    "      const items = await store.search([userId, \"pets\"]);\n",
    "      return JSON.stringify(items.map((item) => item.value));\n",
    "    },\n",
    "    {\n",
    "      // The LLM \"sees\" the following schema:\n",
    "      name: \"get_favorite_pets\",\n",
    "      description: \"retrieve the list of favorite pets for the given user.\",\n",
    "      schema: z.object({}),\n",
    "    }\n",
    "  );\n",
    "  return [updateFavoritePets, getFavoritePets];\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the tool call schema, which is what is passed to the model for tool-calling, only `pets` is being passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  type: 'object',\n",
      "  properties: { pets: { type: 'array', items: [Object] } },\n",
      "  required: [ 'pets' ],\n",
      "  additionalProperties: false,\n",
      "  '$schema': 'http://json-schema.org/draft-07/schema#'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "\n",
    "let tools = generateTools({messages: []});\n",
    "\n",
    "console.log(zodToJsonSchema(tools[0].schema));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the nodes\n",
    "\n",
    "We now need to define a few different nodes in our graph.\n",
    "\n",
    "1. The agent: responsible for deciding what (if any) actions to take.\n",
    "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
    "\n",
    "We will also need to define some edges.\n",
    "\n",
    "1. After the agent is called, we should either invoke the tool node or finish.\n",
    "2. After the tool node have been invoked, it should always go back to the agent to decide what to do next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  END,\n",
    "  START,\n",
    "  StateGraph,\n",
    "  MemorySaver,\n",
    "  InMemoryStore,\n",
    "} from \"@langchain/langgraph\";\n",
    "import { AIMessage } from \"@langchain/core/messages\";\n",
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const model = new ChatOpenAI({ model: \"gpt-4o\" });\n",
    "const routeMessage = (state: typeof State) => {\n",
    "  const { messages } = state;\n",
    "  const lastMessage = messages[messages.length - 1] as AIMessage;\n",
    "  // If no tools are called, we can finish (respond to the user)\n",
    "  if (!lastMessage?.tool_calls?.length) {\n",
    "    return END;\n",
    "  }\n",
    "  // Otherwise if there is, we continue and call the tools\n",
    "  return \"tools\";\n",
    "};\n",
    "\n",
    "const callModel = async (state: typeof State) => {\n",
    "  const { messages } = state;\n",
    "  const tools = generateTools(state);\n",
    "  const modelWithTools = model.bindTools(tools);\n",
    "  const responseMessage = await modelWithTools.invoke(messages);\n",
    "  return { messages: [responseMessage] };\n",
    "};\n",
    "\n",
    "const toolNodeWithGraphState = async (state: typeof State) => {\n",
    "  // We fetch the tools any time this node is reached to\n",
    "  // form a closure and let it access the latest messages\n",
    "  const tools = generateTools(state);\n",
    "  const toolNodeWithConfig = new ToolNode(tools);\n",
    "  return toolNodeWithConfig.invoke(state);\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph(AgentState)\n",
    "  .addNode(\"agent\", callModel)\n",
    "  .addNode(\"tools\", toolNodeWithGraphState)\n",
    "  .addEdge(START, \"agent\")\n",
    "  .addConditionalEdges(\"agent\", routeMessage)\n",
    "  .addEdge(\"tools\", \"agent\");\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "const store = new InMemoryStore();\n",
    "\n",
    "const graph = workflow.compile({ checkpointer: memory, store: store });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import * as tslab from \"tslab\";\n",
    "\n",
    "const graphViz = graph.getGraph();\n",
    "const image = await graphViz.drawMermaidPng();\n",
    "const arrayBuffer = await image.arrayBuffer();\n",
    "\n",
    "await tslab.display.png(new Uint8Array(arrayBuffer));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it!\n",
    "\n",
    "Let's use our graph now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AFxmlhNJcUlOofixfKzZGc6zjAzBl\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_zfqKl3xbD28enfHfa88pDknh\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 19,\n",
      "          \"promptTokens\": 79,\n",
      "          \"totalTokens\": 98\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_2f406b9113\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"update_favorite_pets\",\n",
      "          \"args\": {\n",
      "            \"pets\": \"[Array]\"\n",
      "          },\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_zfqKl3xbD28enfHfa88pDknh\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 79,\n",
      "        \"output_tokens\": 19,\n",
      "        \"total_tokens\": 98\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: tools\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    ToolMessage {\n",
      "      \"content\": \"update_favorite_pets called.\",\n",
      "      \"name\": \"update_favorite_pets\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_zfqKl3xbD28enfHfa88pDknh\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AFxmmiwirx22qsDGanTLAsP4HkzAR\",\n",
      "      \"content\": \"Got it! I've added \\\"terrier\\\" to your list of favorite pets.\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 17,\n",
      "          \"promptTokens\": 116,\n",
      "          \"totalTokens\": 133\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_2f406b9113\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 116,\n",
      "        \"output_tokens\": 17,\n",
      "        \"total_tokens\": 133\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let inputs = { messages: [{ role: \"user\", content: \"My favorite pet is a terrier.\" }] };\n",
    "let config = {\n",
    "  configurable: {\n",
    "    thread_id: \"1\",\n",
    "    userId: \"a-user\"\n",
    "  }\n",
    "};\n",
    "let stream = await graph.stream(inputs, {\n",
    "  ...config\n",
    "});\n",
    "\n",
    "for await (\n",
    "  const chunk of stream\n",
    ") {\n",
    "  for (const [node, values] of Object.entries(chunk)) {\n",
    "    console.log(`Output from node: ${node}`);\n",
    "    console.log(\"---\");\n",
    "    console.log(values);\n",
    "    console.log(\"\\n====\\n\");\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify it can properly cite where it got the information from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AFxmpLOnwAAzOTlZ2qJOaqvICnOV0\",\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_q77mTPhqS4GGbC0iDyaK5Ca6\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": \"[Object]\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 13,\n",
      "          \"promptTokens\": 76,\n",
      "          \"totalTokens\": 89\n",
      "        },\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"system_fingerprint\": \"fp_2f406b9113\"\n",
      "      },\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"get_favorite_pets\",\n",
      "          \"args\": {},\n",
      "          \"type\": \"tool_call\",\n",
      "          \"id\": \"call_q77mTPhqS4GGbC0iDyaK5Ca6\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 76,\n",
      "        \"output_tokens\": 13,\n",
      "        \"total_tokens\": 89\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: tools\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    ToolMessage {\n",
      "      \"content\": \"[[\\\"terrier\\\"]]\",\n",
      "      \"name\": \"get_favorite_pets\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"tool_call_id\": \"call_q77mTPhqS4GGbC0iDyaK5Ca6\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n",
      "Output from node: agent\n",
      "---\n",
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-AFxmq0ajf68geAtIGRScxaF7n2F7k\",\n",
      "      \"content\": \"Your favorite pet is a terrier.\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"completionTokens\": 9,\n",
      "          \"promptTokens\": 105,\n",
      "          \"totalTokens\": 114\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"system_fingerprint\": \"fp_2f406b9113\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 105,\n",
      "        \"output_tokens\": 9,\n",
      "        \"total_tokens\": 114\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = { messages: [{ role: \"user\", content: \"What's my favorite pets?\" }] };\n",
    "config = {\n",
    "  configurable: {\n",
    "    thread_id: \"2\", // New thread ID, so the conversation history isn't present.\n",
    "    userId: \"a-user\"\n",
    "  }\n",
    "};\n",
    "\n",
    "stream = await graph.stream(inputs, {\n",
    "  ...config\n",
    "});\n",
    "\n",
    "for await (\n",
    "  const chunk of stream\n",
    ") {\n",
    "  for (const [node, values] of Object.entries(chunk)) {\n",
    "    console.log(`Output from node: ${node}`);\n",
    "    console.log(\"---\");\n",
    "    console.log(values);\n",
    "    console.log(\"\\n====\\n\");\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the agent is able to properly cite that the information came from Twitter!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
