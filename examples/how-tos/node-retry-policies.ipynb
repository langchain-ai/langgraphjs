{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add node retry policies\n",
    "\n",
    "There are many use cases where you may wish for your node to have a custom retry policy. Some examples of when you may wish to do this is if you are calling an API, querying a database, or calling an LLM, etc. \n",
    "\n",
    "In order to configure the retry policy, you have to pass the `retryPolicy` parameter to the `addNode` function. The `retryPolicy` parameter takes in a `RetryPolicy` named tuple object. Below we instantiate a `RetryPolicy` object with the default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RetryPolicy } from \"@langchain/langgraph\"\n",
    "\n",
    "const retryPolicy: RetryPolicy = {};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want more information on what each of the parameters does, be sure to read the [reference](https://langchain-ai.github.io/langgraph/reference/graphs/#retrypolicy).\n",
    "\n",
    "## Passing a retry policy to a node\n",
    "\n",
    "Lastly, we can pass `RetryPolicy` objects when we call the `addNode` function. In the example below we pass two different retry policies to each of our nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Database from \"better-sqlite3\"\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\"\n",
    "import { Annotation, MessagesAnnotation, StateGraph, START, END } from \"@langchain/langgraph\"\n",
    "import { AIMessage } from \"@langchain/core/messages\"\n",
    "\n",
    "const State = Annotation.Root({\n",
    "    ...MessagesAnnotation.spec, // list of messages\n",
    "  })\n",
    "\n",
    "// Create an in-memory database\n",
    "const db: typeof Database.prototype = new Database(':memory:');\n",
    "\n",
    "const model = new ChatAnthropic({ model: \"claude-3-5-sonnet-20240620\" });\n",
    "\n",
    "const callModel = async (state: typeof State.State): Promise<Partial<typeof State.State>> => {\n",
    "    const response = await model.invoke(state.messages);\n",
    "    return { messages: [response] };\n",
    "}\n",
    "\n",
    "const queryDatabase = async (state: typeof State.State): Promise<Partial<typeof State.State>> => {\n",
    "    const queryResult: string = JSON.stringify(db.prepare(\"SELECT * FROM Artist LIMIT 10;\").all());\n",
    "\n",
    "    return { messages: [new AIMessage({content: \"queryResult\"})]};\n",
    "};\n",
    "\n",
    "const workflow = new StateGraph(State)\n",
    "    // Define the two nodes we will cycle between\n",
    "    .addNode(\"call_model\", callModel, { retryPolicy: {maxAttempts: 5}})\n",
    "    .addNode(\"query_database\", queryDatabase, { retryPolicy: { retryOn: (e: any): boolean => {\n",
    "        if (e instanceof Database.SqliteError) {\n",
    "          // Retry on \"SQLITE_BUSY\" error\n",
    "          return e.code === 'SQLITE_BUSY';\n",
    "        }\n",
    "        return false; // Don't retry on other errors\n",
    "      }}})\n",
    "    .addEdge(START, \"call_model\")\n",
    "    .addEdge(\"call_model\", \"query_database\")\n",
    "    .addEdge(\"query_database\", END);\n",
    "\n",
    "const graph = workflow.compile();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
