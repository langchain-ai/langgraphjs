{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53",
   "metadata": {},
   "source": [
    "# How to delete messages\n",
    "\n",
    "One of the common states for a graph is a list of messages. Usually you only add messages to that state. However, sometimes you may want to remove messages (either by directly modifying the state or as part of the graph). To do that, you can use the `RemoveMessage` modifier. In this guide, we will cover how to do that.\n",
    "\n",
    "The key idea is that each state key has a `reducer` key. This key specifies how to combine updates to the state. The prebuilt [`MessagesAnnotation`](/langgraphjs/concepts/low_level/#messagesannotation) has a messages key, and the reducer for that key accepts these `RemoveMessage` modifiers. That reducer then uses these `RemoveMessage` to delete messages from the key.\n",
    "\n",
    "So note that just because your graph state has a key that is a list of messages, it doesn't mean that that this `RemoveMessage` modifier will work. You also have to have a `reducer` defined that knows how to work with this.\n",
    "\n",
    "**NOTE**: Many models expect certain rules around lists of messages. For example, some expect them to start with a `user` message, others expect all messages with tool calls to be followed by a tool message. **When deleting messages, you will want to make sure you don't violate these rules.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd446a-808f-4394-be92-d45ab818953c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, install the required dependencies for this example:\n",
    "\n",
    "```bash\n",
    "npm install @langchain/langgraph @langchain/openai @langchain/core zod uuid\n",
    "```\n",
    "\n",
    "Next, we need to set API keys for OpenAI (the LLM we will use):\n",
    "\n",
    "```typescript\n",
    "process.env.OPENAI_API_KEY = 'YOUR_API_KEY';\n",
    "```\n",
    "\n",
    "Optionally, we can set API key for [LangSmith tracing](https://smith.langchain.com/), which will give us best-in-class observability.\n",
    "\n",
    "```typescript\n",
    "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n",
    "process.env.LANGCHAIN_API_KEY = \"YOUR_API_KEY\";\n",
    "```\n",
    "\n",
    "Now, let's build a simple graph that uses messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767ef1c-a7cf-41f8-a301-558988cb7ac5",
   "metadata": {},
   "source": [
    "## Build the agent\n",
    "Let's now build a simple ReAct style agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab32b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { MemorySaver } from \"@langchain/langgraph-checkpoint\";\n",
    "import { MessagesAnnotation, StateGraph, START, END } from \"@langchain/langgraph\";\n",
    "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "\n",
    "const search = tool((_) => {\n",
    "  // This is a placeholder for the actual implementation\n",
    "  // Don't let the LLM know this though ðŸ˜Š\n",
    "  return [\n",
    "    \"It's sunny in San Francisco, but you better look out if you're a Gemini ðŸ˜ˆ.\",\n",
    "  ];\n",
    "}, {\n",
    "  name: \"search\",\n",
    "  description: \"Call to surf the web.\",\n",
    "  schema: z.object({\n",
    "    query: z.string(),\n",
    "  })\n",
    "});\n",
    "\n",
    "const tools = [search];\n",
    "const toolNode = new ToolNode<typeof MessagesAnnotation.State>(tools);\n",
    "const model = new ChatOpenAI({ model: \"gpt-4o\" });\n",
    "const boundModel = model.bindTools(tools);\n",
    "\n",
    "function shouldContinue(state: typeof MessagesAnnotation.State): \"action\" | typeof END {\n",
    "  const lastMessage = state.messages[state.messages.length - 1];\n",
    "  if (\n",
    "    \"tool_calls\" in lastMessage &&\n",
    "    Array.isArray(lastMessage.tool_calls) &&\n",
    "    lastMessage.tool_calls.length\n",
    "  ) {\n",
    "    return \"action\";\n",
    "  }\n",
    "  // If there is no tool call, then we finish\n",
    "  return END;\n",
    "}\n",
    "\n",
    "// Define the function that calls the model\n",
    "async function callModel(state: typeof MessagesAnnotation.State) {\n",
    "  const response = await boundModel.invoke(state.messages);\n",
    "  return { messages: [response] };\n",
    "}\n",
    "\n",
    "// Define a new graph\n",
    "const workflow = new StateGraph(MessagesAnnotation)\n",
    "  // Define the two nodes we will cycle between\n",
    "  .addNode(\"agent\", callModel)\n",
    "  .addNode(\"action\", toolNode)\n",
    "  // Set the entrypoint as `agent`\n",
    "  // This means that this node is the first one called\n",
    "  .addEdge(START, \"agent\")\n",
    "  // We now add a conditional edge\n",
    "  .addConditionalEdges(\n",
    "    // First, we define the start node. We use `agent`.\n",
    "    // This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    // Next, we pass in the function that will determine which node is called next.\n",
    "    shouldContinue\n",
    "  )\n",
    "  // We now add a normal edge from `tools` to `agent`.\n",
    "  // This means that after `tools` is called, `agent` node is called next.\n",
    "  .addEdge(\"action\", \"agent\");\n",
    "\n",
    "// Finally, we compile it!\n",
    "// This compiles it into a LangChain Runnable,\n",
    "// meaning you can use it as you would any other runnable\n",
    "const app = workflow.compile({ checkpointer: memory });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b27553-21be-43e5-ac48-d1d0a3aa0dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ type: 'human', content: \"hi! I'm bob\", tool_calls: undefined }\n",
      "{\n",
      "  type: 'ai',\n",
      "  content: 'Hi Bob! How can I assist you today?',\n",
      "  tool_calls: []\n",
      "}\n",
      "{ type: 'human', content: \"What's my name?\", tool_calls: undefined }\n",
      "{ type: 'ai', content: 'Your name is Bob.', tool_calls: [] }\n"
     ]
    }
   ],
   "source": [
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "\n",
    "const config = { configurable: { thread_id: \"2\" }, streamMode: \"values\" as const };\n",
    "const inputMessage = new HumanMessage({\n",
    "  id: uuidv4(),\n",
    "  content: \"hi! I'm bob\",\n",
    "});\n",
    "\n",
    "for await (const event of await app.stream(\n",
    "  { messages: [inputMessage] },\n",
    "  config,\n",
    ")) {\n",
    "  const lastMsg = event.messages[event.messages.length - 1];\n",
    "  console.dir(\n",
    "    {\n",
    "      type: lastMsg._getType(),\n",
    "      content: lastMsg.content,\n",
    "      tool_calls: lastMsg.tool_calls,\n",
    "    },\n",
    "    { depth: null }\n",
    "  )\n",
    "}\n",
    "\n",
    "const inputMessage2 = new HumanMessage({\n",
    "  id: uuidv4(),\n",
    "  content: \"What's my name?\",\n",
    "});\n",
    "for await (const event of await app.stream(\n",
    "  { messages: [inputMessage2] },\n",
    "  config,\n",
    ")) {\n",
    "  const lastMsg = event.messages[event.messages.length - 1];\n",
    "  console.dir(\n",
    "    {\n",
    "      type: lastMsg._getType(),\n",
    "      content: lastMsg.content,\n",
    "      tool_calls: lastMsg.tool_calls,\n",
    "    },\n",
    "    { depth: null }\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0de5b-30ec-42d4-813a-7ad63fe1c367",
   "metadata": {},
   "source": [
    "## Manually deleting messages\n",
    "\n",
    "First, we will cover how to manually delete messages. Let's take a look at the current state of the thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a850529-d038-48f7-b5a2-8d4d2923f83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    id: '24187daa-00dd-40d8-bc30-f4e24ff78165',\n",
      "    type: 'human',\n",
      "    content: \"hi! I'm bob\",\n",
      "    tool_calls: undefined\n",
      "  },\n",
      "  {\n",
      "    id: 'chatcmpl-9zYV9yHLiZmR2ZVHEhHcbVEshr3qG',\n",
      "    type: 'ai',\n",
      "    content: 'Hi Bob! How can I assist you today?',\n",
      "    tool_calls: []\n",
      "  },\n",
      "  {\n",
      "    id: 'a67e53c3-5dcf-4ddc-83f5-309b72ac61f4',\n",
      "    type: 'human',\n",
      "    content: \"What's my name?\",\n",
      "    tool_calls: undefined\n",
      "  },\n",
      "  {\n",
      "    id: 'chatcmpl-9zYV9mmpJrm3SQ7ngMJZ1XBHzHfL6',\n",
      "    type: 'ai',\n",
      "    content: 'Your name is Bob.',\n",
      "    tool_calls: []\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const messages = (await app.getState(config)).values.messages;\n",
    "console.dir(\n",
    "  messages.map((msg) => ({\n",
    "    id: msg.id,\n",
    "    type: msg._getType(),\n",
    "    content: msg.content,\n",
    "    tool_calls:\n",
    "    msg.tool_calls,\n",
    "  })),\n",
    "  { depth: null }\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be8a0a-1e94-4302-bd84-d1b72e3c501c",
   "metadata": {},
   "source": [
    "We can call `updateState` and pass in the id of the first message. This will delete that message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1a0970-7e64-4170-beef-2855d10eef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  configurable: {\n",
      "    thread_id: '2',\n",
      "    checkpoint_ns: '',\n",
      "    checkpoint_id: '1ef61abf-1fc2-6431-8005-92730e9d667c'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { RemoveMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "await app.updateState(config, { messages: new RemoveMessage({ id: messages[0].id }) })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9127ae-0d42-42b8-957f-ea69a5da555f",
   "metadata": {},
   "source": [
    "If we now look at the messages, we can verify that the first one was deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfe4ffa-e170-43bc-aec4-6e36ac620931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    id: 'chatcmpl-9zYV9yHLiZmR2ZVHEhHcbVEshr3qG',\n",
      "    type: 'ai',\n",
      "    content: 'Hi Bob! How can I assist you today?',\n",
      "    tool_calls: []\n",
      "  },\n",
      "  {\n",
      "    id: 'a67e53c3-5dcf-4ddc-83f5-309b72ac61f4',\n",
      "    type: 'human',\n",
      "    content: \"What's my name?\",\n",
      "    tool_calls: undefined\n",
      "  },\n",
      "  {\n",
      "    id: 'chatcmpl-9zYV9mmpJrm3SQ7ngMJZ1XBHzHfL6',\n",
      "    type: 'ai',\n",
      "    content: 'Your name is Bob.',\n",
      "    tool_calls: []\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const updatedMessages = (await app.getState(config)).values.messages;\n",
    "console.dir(\n",
    "  updatedMessages.map((msg) => ({\n",
    "    id: msg.id,\n",
    "    type: msg._getType(),\n",
    "    content: msg.content,\n",
    "    tool_calls:\n",
    "    msg.tool_calls,\n",
    "  })),\n",
    "  { depth: null }\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef129a75-4cad-44d7-b532-eb37b0553c0c",
   "metadata": {},
   "source": [
    "## Programmatically deleting messages\n",
    "\n",
    "We can also delete messages programmatically from inside the graph. Here we'll modify the graph to delete any old messages (longer than 3 messages ago) at the end of a graph run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c308252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RemoveMessage } from \"@langchain/core/messages\";\n",
    "import { StateGraph, START, END } from \"@langchain/langgraph\";\n",
    "import { MessagesAnnotation } from \"@langchain/langgraph\";\n",
    "\n",
    "function deleteMessages(state: typeof MessagesAnnotation.State) {\n",
    "  const messages = state.messages;\n",
    "  if (messages.length > 3) {\n",
    "    return { messages: messages.slice(0, -3).map(m => new RemoveMessage({ id: m.id })) };\n",
    "  }\n",
    "  return {};\n",
    "}\n",
    "\n",
    "// We need to modify the logic to call deleteMessages rather than end right away\n",
    "function shouldContinue2(state: typeof MessagesAnnotation.State): \"action\" | \"delete_messages\" {\n",
    "  const lastMessage = state.messages[state.messages.length - 1];\n",
    "  if (\n",
    "    \"tool_calls\" in lastMessage &&\n",
    "    Array.isArray(lastMessage.tool_calls) &&\n",
    "    lastMessage.tool_calls.length\n",
    "  ) {\n",
    "    return \"action\";\n",
    "  }\n",
    "  // Otherwise if there aren't, we finish\n",
    "  return \"delete_messages\";\n",
    "}\n",
    "\n",
    "// Define a new graph\n",
    "const workflow2 = new StateGraph(MessagesAnnotation)\n",
    "  .addNode(\"agent\", callModel)\n",
    "  .addNode(\"action\", toolNode)\n",
    "  // This is our new node we're defining\n",
    "  .addNode(\"delete_messages\", deleteMessages)\n",
    "  .addEdge(START, \"agent\")\n",
    "  .addConditionalEdges(\n",
    "    \"agent\",\n",
    "    shouldContinue2\n",
    "  )\n",
    "  .addEdge(\"action\", \"agent\")\n",
    "  // This is the new edge we're adding: after we delete messages, we finish\n",
    "  .addEdge(\"delete_messages\", END);\n",
    "\n",
    "const app2 = workflow2.compile({ checkpointer: memory });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbdef6-7db7-45a2-8194-de4f8929bd1f",
   "metadata": {},
   "source": [
    "We can now try this out. We can call the graph twice and then check the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3975f34c-c243-40ea-b9d2-424d50a48dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FIRST ITERATION ---\n",
      "\n",
      "[ [ 'human', \"hi! I'm bob\" ] ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [ 'human', \"hi! I'm bob\" ],\n",
      "  [ 'ai', 'Hi Bob! How can I assist you today?' ]\n",
      "]\n",
      "\n",
      "\n",
      "--- SECOND ITERATION ---\n",
      "\n",
      "[\n",
      "  [ 'human', \"hi! I'm bob\" ],\n",
      "  [ 'ai', 'Hi Bob! How can I assist you today?' ],\n",
      "  [ 'human', \"what's my name?\" ]\n",
      "] \n",
      "\n",
      "[\n",
      "  [ 'human', \"hi! I'm bob\" ],\n",
      "  [ 'ai', 'Hi Bob! How can I assist you today?' ],\n",
      "  [ 'human', \"what's my name?\" ],\n",
      "  [ 'ai', \"Based on what you've told me, your name is Bob.\" ]\n",
      "] \n",
      "\n",
      "[\n",
      "  [ 'ai', 'Hi Bob! How can I assist you today?' ],\n",
      "  [ 'human', \"what's my name?\" ],\n",
      "  [ 'ai', \"Based on what you've told me, your name is Bob.\" ]\n",
      "] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "\n",
    "const config2 = { configurable: { thread_id: \"3\" }, streamMode: \"values\" as const };\n",
    "\n",
    "const inputMessage3 = new HumanMessage({\n",
    "  id: uuidv4(),\n",
    "  content: \"hi! I'm bob\",\n",
    "});\n",
    "\n",
    "console.log(\"--- FIRST ITERATION ---\\n\");\n",
    "for await (const event of await app2.stream(\n",
    "  { messages: [inputMessage3] },\n",
    "  config2\n",
    ")) {\n",
    "  console.log(event.messages.map((message) => [message._getType(), message.content]));\n",
    "}\n",
    "\n",
    "const inputMessage4 = new HumanMessage({\n",
    "  id: uuidv4(),\n",
    "  content: \"what's my name?\",\n",
    "});\n",
    "\n",
    "console.log(\"\\n\\n--- SECOND ITERATION ---\\n\");\n",
    "for await (const event of await app2.stream(\n",
    "  { messages: [inputMessage4] },\n",
    "  config2\n",
    ")) {\n",
    "  console.log(event.messages.map((message) => [message._getType(), message.content]), \"\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2fd2a-14a1-4c47-8632-f8cbb0ba1d35",
   "metadata": {},
   "source": [
    "If we now check the state, we should see that it is only three messages long. This is because we just deleted the earlier messages - otherwise it would be four!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e15abb-81d8-4072-9f10-61ae0fd61dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    id: 'chatcmpl-9zYVAEiiC9D7bb0wF4KLXgY0OAG8O',\n",
      "    type: 'ai',\n",
      "    content: 'Hi Bob! How can I assist you today?',\n",
      "    tool_calls: []\n",
      "  },\n",
      "  {\n",
      "    id: 'b93e5f35-cfa3-4ca6-9b59-154ce2bd476b',\n",
      "    type: 'human',\n",
      "    content: \"what's my name?\",\n",
      "    tool_calls: undefined\n",
      "  },\n",
      "  {\n",
      "    id: 'chatcmpl-9zYVBHJWtEM6pw2koE8dykzSA0XSO',\n",
      "    type: 'ai',\n",
      "    content: \"Based on what you've told me, your name is Bob.\",\n",
      "    tool_calls: []\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const messages3 = (await app.getState(config2)).values[\"messages\"]\n",
    "console.dir(\n",
    "  messages3.map((msg) => ({\n",
    "    id: msg.id,\n",
    "    type: msg._getType(),\n",
    "    content: msg.content,\n",
    "    tool_calls:\n",
    "    msg.tool_calls,\n",
    "  })),\n",
    "  { depth: null }\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cfeae-d43a-46ee-9069-a1cab9a5720a",
   "metadata": {},
   "source": [
    "Remember, when deleting messages you will want to make sure that the remaining message list is still valid. This message list **may actually not be** - this is because it currently starts with an AI message, which some models do not allow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
