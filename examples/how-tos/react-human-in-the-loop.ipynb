{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add human-in-the-loop processes to the prebuilt ReAct agent\n",
    "\n",
    "This tutorial will show how to add human-in-the-loop processes to the prebuilt ReAct agent. Please see [this tutorial](./create-react-agent.ipynb) for how to get started with the prebuilt ReAct agent\n",
    "\n",
    "You can add a a breakpoint before tools are called by passing `interrupt_before=[\"tools\"]` to `create_react_agent`. Note that you need to be using a checkpointer for this to work.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to install the required packages.\n",
    "\n",
    "```bash\n",
    "yarn add @langchain/langgraph @langchain/openai\n",
    "```\n",
    "\n",
    "This guide will use OpenAI's GPT-4o model. We will optionally set our API key\n",
    "for [LangSmith tracing](https://smith.langchain.com/), which will give us\n",
    "best-in-class observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct Agent with human-in-the-loop: LangGraphJS\n"
     ]
    }
   ],
   "source": [
    "// process.env.OPENAI_API_KEY = \"sk_...\";\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n",
    "// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n",
    "process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n",
    "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n",
    "process.env.LANGCHAIN_PROJECT = \"ReAct Agent with human-in-the-loop: LangGraphJS\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Now we can use the prebuilt `createReactAgent` function to setup our agent with human-in-the-loop interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { tool } from '@langchain/core/tools';\n",
    "import { z } from 'zod';\n",
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "    model: \"gpt-4o\",\n",
    "  });\n",
    "\n",
    "const getWeather = tool((input) => {\n",
    "    if (['sf', 'san francisco'].includes(input.location.toLowerCase())) {\n",
    "        return 'It\\'s always sunny in sf';\n",
    "    } else {\n",
    "        return 'It might be cloudy in nyc';\n",
    "    }\n",
    "}, {\n",
    "    name: 'get_weather',\n",
    "    description: 'Call to get the current weather.',\n",
    "    schema: z.object({\n",
    "        location: z.string().describe(\"Location to get the weather for.\"),\n",
    "    })\n",
    "})\n",
    "\n",
    "// Here we only save in-memory\n",
    "const memory = new MemorySaver();\n",
    "\n",
    "const agent = createReactAgent({ llm: model, tools: [getWeather], interruptBefore: [\"tools\"], checkpointSaver: memory });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the weather in SF?\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    name: 'get_weather',\n",
      "    args: { location: 'San Francisco, CA' },\n",
      "    type: 'tool_call',\n",
      "    id: 'call_R611sSRBHim9n8CwwGA8JV5N'\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let inputs = { messages: [[\"user\", \"what is the weather in SF?\"]] };\n",
    "let config = { configurable: { thread_id: \"1\" } };\n",
    "\n",
    "for await (\n",
    "  const { messages } of await agent.stream(inputs, {\n",
    "    ...config,\n",
    "    streamMode: \"values\",\n",
    "  })\n",
    ") {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that our graph stopped at the right place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'tools' ]\n"
     ]
    }
   ],
   "source": [
    "const state = await agent.getState(config)\n",
    "console.log(state.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can either approve or edit the tool call before proceeding to the next node. If we wanted to approve the tool call, we would simply continue streaming the graph with `null` input. If we wanted to edit the tool call we need to update the state to have the correct tool call, and then after the update has been applied we can continue.\n",
    "\n",
    "Let's show how we would edit the tool call to search for \"San Francisco\" instead of \"San Francisco, CA\" - since our tool as written treats \"San Francisco, CA\" as if it were not equivalent to just \"San Francisco\" (note that if you didn't want to edit the tool call, you would just skip the state updates and go straight to the streaming):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  configurable: {\n",
      "    thread_id: '1',\n",
      "    checkpoint_ns: '',\n",
      "    checkpoint_id: '1ef6632e-145a-6310-8002-7fdd23d0e16c'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// First, lets get the current state\n",
    "const currentState = await agent.getState(config);\n",
    "\n",
    "// Let's now get the last message in the state\n",
    "// This is the one with the tool calls that we want to update\n",
    "let lastMessage = currentState.values.messages[currentState.values.messages.length - 1]\n",
    "\n",
    "// Let's now update the args for that tool call\n",
    "lastMessage.tool_calls[0].args = { location: \"San Francisco\" }\n",
    "\n",
    "// Let's now call `updateState` to pass in this message in the `messages` key\n",
    "// This will get treated as any other update to the state\n",
    "// It will get passed to the reducer function for the `messages` key\n",
    "// That reducer function will use the ID of the message to update it\n",
    "// It's important that it has the right ID! Otherwise it would get appended\n",
    "// as a new message\n",
    "await agent.updateState(config, { messages: lastMessage });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's always sunny in sf\n",
      "-----\n",
      "\n",
      "The weather in San Francisco is sunny today!\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for await (\n",
    "  const { messages } of await agent.stream(null, {\n",
    "    ...config,\n",
    "    streamMode: \"values\",\n",
    "  })\n",
    ") {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Our graph updated properly to query the weather in San Francisco and got the correct \"The weather in San Francisco is sunny today!\n",
    "\" response from the tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
