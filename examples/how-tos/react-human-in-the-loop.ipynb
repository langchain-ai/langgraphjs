{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add human-in-the-loop processes to the prebuilt ReAct agent\n",
    "\n",
    "This tutorial will show how to add human-in-the-loop processes to the prebuilt ReAct agent. Please see [this tutorial](./create-react-agent.ipynb) for how to get started with the prebuilt ReAct agent\n",
    "\n",
    "You can add a a breakpoint before tools are called by passing `interrupt_before=[\"tools\"]` to `create_react_agent`. Note that you need to be using a checkpointer for this to work.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to install the required packages.\n",
    "\n",
    "```bash\n",
    "yarn add @langchain/langgraph @langchain/openai\n",
    "```\n",
    "\n",
    "This guide will use OpenAI's GPT-4o model. We will optionally set our API key\n",
    "for [LangSmith tracing](https://smith.langchain.com/), which will give us\n",
    "best-in-class observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct Agent with human-in-the-loop: LangGraphJS\n"
     ]
    }
   ],
   "source": [
    "// process.env.OPENAI_API_KEY = \"sk_...\";\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n",
    "// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n",
    "process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n",
    "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n",
    "process.env.LANGCHAIN_PROJECT = \"ReAct Agent with human-in-the-loop: LangGraphJS\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Now we can use the prebuilt `createReactAgent` function to setup our agent with human-in-the-loop interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { tool } from '@langchain/core/tools';\n",
    "import { z } from 'zod';\n",
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "    model: \"gpt-4o\",\n",
    "  });\n",
    "\n",
    "const getWeather = tool((input) => {\n",
    "    if (input.location === 'sf') {\n",
    "        return 'It\\'s always sunny in sf';\n",
    "    } else {\n",
    "        return 'It might be cloudy in nyc';\n",
    "    }\n",
    "}, {\n",
    "    name: 'get_weather',\n",
    "    description: 'Call to get the current weather.',\n",
    "    schema: z.object({\n",
    "        location: z.enum(['sf','nyc']).describe(\"Location to get the weather for.\"),\n",
    "    })\n",
    "})\n",
    "\n",
    "// Here we only save in-memory\n",
    "const memory = new MemorySaver();\n",
    "\n",
    "const agent = createReactAgent({ llm: model, tools: [getWeather], interruptBefore: [\"tools\"], checkpointSaver: memory });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the weather in SF?\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    name: 'get_weather',\n",
      "    args: { location: 'sf' },\n",
      "    type: 'tool_call',\n",
      "    id: 'call_CMlaOt1hB6cy27ENGxxvYylB'\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "let inputs = { messages: [[\"user\", \"what is the weather in SF?\"]] };\n",
    "let config = { configurable: { thread_id: \"1\" } };\n",
    "\n",
    "for await (\n",
    "  const { messages } of await agent.stream(inputs, {\n",
    "    ...config,\n",
    "    streamMode: \"values\",\n",
    "  })\n",
    ") {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that our graph stopped at the right place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'tools' ]\n"
     ]
    }
   ],
   "source": [
    "const state = await agent.getState(config)\n",
    "console.log(state.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can either approve or edit the tool call before proceeding to the next node. If we wanted to approve the tool call, we would simply continue streaming the graph with `null` input. If we wanted to edit the tool call we need to update the state to have the correct tool call, and then after the update has been applied we can continue.\n",
    "\n",
    "Let's show how we would edit the tool call to search for \"nyc\" instead of \"sf\" (note that if you didn't want to edit the tool call, you would just skip the state updates and go straight to the streaming):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  configurable: {\n",
      "    thread_id: '1',\n",
      "    checkpoint_ns: '',\n",
      "    checkpoint_id: '1ef65adb-68da-6b20-8002-4ba7ffdb470a'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// First, lets get the current state\n",
    "const currentState = await agent.getState(config);\n",
    "\n",
    "// Let's now get the last message in the state\n",
    "// This is the one with the tool calls that we want to update\n",
    "let lastMessage = currentState.values.messages[currentState.values.messages.length - 1]\n",
    "\n",
    "// Let's now update the args for that tool call\n",
    "lastMessage.tool_calls[0].args = { location: \"nyc\" }\n",
    "\n",
    "// Let's now call `updateState` to pass in this message in the `messages` key\n",
    "// This will get treated as any other update to the state\n",
    "// It will get passed to the reducer function for the `messages` key\n",
    "// That reducer function will use the ID of the message to update it\n",
    "// It's important that it has the right ID! Otherwise it would get appended\n",
    "// as a new message\n",
    "await agent.updateState(config, { messages: lastMessage });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It might be cloudy in nyc\n",
      "-----\n",
      "\n",
      "[\n",
      "  {\n",
      "    name: 'get_weather',\n",
      "    args: { location: 'sf' },\n",
      "    type: 'tool_call',\n",
      "    id: 'call_OxzFrGuO2fp8HBdEv61RuFb0'\n",
      "  }\n",
      "]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for await (\n",
    "  const { messages } of await agent.stream(null, {\n",
    "    ...config,\n",
    "    streamMode: \"values\",\n",
    "  })\n",
    ") {\n",
    "  let msg = messages[messages?.length - 1];\n",
    "  if (msg?.content) {\n",
    "    console.log(msg.content);\n",
    "  } else if (msg?.tool_calls?.length > 0) {\n",
    "    console.log(msg.tool_calls);\n",
    "  } else {\n",
    "    console.log(msg);\n",
    "  }\n",
    "  console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Our graph updated properly to query the weather in New York and got the correct \"It might be cloudy in nyc\" response from the tool.\n",
    "\n",
    "Astute LangGraph users may have noticed that after receiving the tool response, the AI decided to not respond to the user and instead caled the `get_weather` tool again. This is because the answer it received from the tool - \"It might be cloudy in nyc\" - didn't answer the original user query of \"what's the weather in SF\", and so it is trying to call the tool again to fix this. Note that this is only relevant because in the prebuilt ReAct agent the entire message history is passed to the agent, so it always has the context of the original user query. Dealing with this issue is beyond the scope of this notebook, but it is a good reminder to be extremely aware of what's going on under the hood in your graph, especially when using human-in-the-loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
