{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd47f365",
      "metadata": {},
      "source": [
        "# How to let agent return tool results directly\n",
        "\n",
        "A typical ReAct loop follows user -> assistant -> tool -> assistant ..., ->\n",
        "user. In some cases, you don't need to call the LLM after the tool completes,\n",
        "the user can view the results directly themselves.\n",
        "\n",
        "In this example we will build a conversational ReAct agent where the LLM can\n",
        "optionally decide to return the result of a tool call as the final answer. This\n",
        "is useful in cases where you have tools that can sometimes generate responses\n",
        "that are acceptable as final answers, and you want to use the LLM to determine\n",
        "when that is the case\n",
        "\n",
        "## Setup\n",
        "\n",
        "First we need to install the required packages:\n",
        "\n",
        "```bash\n",
        "yarn add @langchain/langgraph @langchain/openai @langchain/core\n",
        "```\n",
        "\n",
        "Next, we need to set API keys for OpenAI (the LLM we will use). Optionally, we\n",
        "can set API key for [LangSmith tracing](https://smith.langchain.com/), which\n",
        "will give us best-in-class observability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bff262dd",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Direct Return: LangGraphJS\n"
          ]
        }
      ],
      "source": [
        "// process.env.OPENAI_API_KEY = \"sk_...\";\n",
        "\n",
        "// Optional, add tracing in LangSmith\n",
        "// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n",
        "process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n",
        "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n",
        "process.env.LANGCHAIN_PROJECT = \"Direct Return: LangGraphJS\";"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c02963",
      "metadata": {},
      "source": [
        "## Set up the tools\n",
        "\n",
        "We will first define the tools we want to use. For this simple example, we will\n",
        "use a simple placeholder \"search engine\". However, it is really easy to create\n",
        "your own tools - see documentation\n",
        "[here](https://js.langchain.com/docs/modules/agents/tools/dynamic) on how to do\n",
        "that.\n",
        "\n",
        "To add a 'return_direct' option, we will create a custom zod schema to use\n",
        "**instead of** the schema that would be automatically inferred by the tool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c6e93e06",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
        "import { z } from \"zod\";\n",
        "\n",
        "const SearchTool = z.object({\n",
        "  query: z.string().describe(\"query to look up online\"),\n",
        "  // **IMPORTANT** We are adding an **extra** field here\n",
        "  // that isn't used directly by the tool - it's used by our\n",
        "  // graph instead to determine whether or not to return the\n",
        "  // result directly to the user\n",
        "  return_direct: z.boolean()\n",
        "    .describe(\n",
        "      \"Whether or not the result of this should be returned directly to the user without you seeing what it is\",\n",
        "    )\n",
        "    .default(false),\n",
        "});\n",
        "\n",
        "const searchTool = new DynamicStructuredTool({\n",
        "  name: \"search\",\n",
        "  description: \"Call to surf the web.\",\n",
        "  // We are overriding the default schema here to\n",
        "  // add an extra field\n",
        "  schema: SearchTool,\n",
        "  func: async ({}: { query: string }) => {\n",
        "    // This is a placeholder for the actual implementation\n",
        "    // Don't let the LLM know this though ðŸ˜Š\n",
        "    return \"It's sunny in San Francisco, but you better look out if you're a Gemini ðŸ˜ˆ.\";\n",
        "  },\n",
        "});\n",
        "\n",
        "const tools = [searchTool];"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f443c375",
      "metadata": {},
      "source": [
        "We can now wrap these tools in a `ToolNode`.\n",
        "This is a prebuilt node that takes in a LangChain chat model's generated tool call and calls that tool,\n",
        "returning the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "82f3a772",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n",
        "\n",
        "const toolNode = new ToolNode(tools);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07a9312",
      "metadata": {},
      "source": [
        "## Set up the model\n",
        "\n",
        "Now we need to load the chat model we want to use.\\\n",
        "Importantly, this should satisfy two criteria:\n",
        "\n",
        "1. It should work with messages. We will represent all agent state in the form\n",
        "   of messages, so it needs to be able to work well with them.\n",
        "2. It should support\n",
        "   [tool calling](https://js.langchain.com/docs/concepts/tool_calling/).\n",
        "\n",
        "Note: these model requirements are not requirements for using LangGraph - they\n",
        "are just requirements for this one example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f9263d46",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const model = new ChatOpenAI({\n",
        "  temperature: 0,\n",
        "  model: \"gpt-3.5-turbo\",\n",
        "});\n",
        "// This formats the tools as json schema for the model API.\n",
        "// The model then uses this like a system prompt.\n",
        "const boundModel = model.bindTools(tools);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dbab039",
      "metadata": {},
      "source": [
        "## Define the agent state\n",
        "\n",
        "The main type of graph in `langgraph` is the\n",
        "[StateGraph](/langgraphjs/reference/classes/langgraph.StateGraph.html).\n",
        "\n",
        "This graph is parameterized by a state object that it passes around to each\n",
        "node. Each node then returns operations to update that state. These operations\n",
        "can either SET specific attributes on the state (e.g. overwrite the existing\n",
        "values) or ADD to the existing attribute. Whether to set or add is denoted in\n",
        "the state object you construct the graph with.\n",
        "\n",
        "For this example, the state we will track will just be a list of messages. We\n",
        "want each node to just add messages to that list. Therefore, we will define the\n",
        "state as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c85e2d40",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import { Annotation } from \"@langchain/langgraph\";\n",
        "import { BaseMessage } from \"@langchain/core/messages\";\n",
        "\n",
        "const AgentState = Annotation.Root({\n",
        "  messages: Annotation<BaseMessage[]>({\n",
        "    reducer: (x, y) => x.concat(y),\n",
        "  }),\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc4b9760",
      "metadata": {},
      "source": [
        "## Define the nodes\n",
        "\n",
        "We now need to define a few different nodes in our graph. In `langgraph`, a node\n",
        "can be either a function or a\n",
        "[runnable](https://js.langchain.com/docs/expression_language/). There are two\n",
        "main nodes we need for this:\n",
        "\n",
        "1. The agent: responsible for deciding what (if any) actions to take.\n",
        "2. A function to invoke tools: if the agent decides to take an action, this node\n",
        "   will then execute that action.\n",
        "\n",
        "We will also need to define some edges. Some of these edges may be conditional.\n",
        "The reason they are conditional is that based on the output of a node, one of\n",
        "several paths may be taken. The path that is taken is not known until that node\n",
        "is run (the LLM decides).\n",
        "\n",
        "1. Conditional Edge: after the agent is called, we should either: a. If the\n",
        "   agent said to take an action, then the function to invoke tools should be\n",
        "   called b. If the agent said that it was finished, then it should finish\n",
        "2. Normal Edge: after the tools are invoked, it should always go back to the\n",
        "   agent to decide what to do next\n",
        "\n",
        "Let's define the nodes, as well as a function to decide how what conditional\n",
        "edge to take.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c3da4bde",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import { RunnableConfig } from \"@langchain/core/runnables\";\n",
        "import { END } from \"@langchain/langgraph\";\n",
        "import { AIMessage } from \"@langchain/core/messages\";\n",
        "\n",
        "// Define the function that determines whether to continue or not\n",
        "const shouldContinue = (state: typeof AgentState.State) => {\n",
        "  const { messages } = state;\n",
        "  const lastMessage = messages[messages.length - 1] as AIMessage;\n",
        "  // If there is no function call, then we finish\n",
        "  if (!lastMessage?.tool_calls?.length) {\n",
        "    return END;\n",
        "  } // Otherwise if there is, we check if it's suppose to return direct\n",
        "  else {\n",
        "    const args = lastMessage.tool_calls[0].args;\n",
        "    if (args?.return_direct) {\n",
        "      return \"final\";\n",
        "    } else {\n",
        "      return \"tools\";\n",
        "    }\n",
        "  }\n",
        "};\n",
        "\n",
        "// Define the function that calls the model\n",
        "const callModel = async (state: typeof AgentState.State, config?: RunnableConfig) => {\n",
        "  const messages = state.messages;\n",
        "  const response = await boundModel.invoke(messages, config);\n",
        "  // We return an object, because this will get added to the existing list\n",
        "  return { messages: [response] };\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd38eae",
      "metadata": {},
      "source": [
        "## Define the graph\n",
        "\n",
        "We can now put it all together and define the graph!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f830fef",
      "metadata": {},
      "outputs": [],
      "source": [
        "import { START, StateGraph } from \"@langchain/langgraph\";\n",
        "\n",
        "// Define a new graph\n",
        "const workflow = new StateGraph(AgentState)\n",
        "  // Define the two nodes we will cycle between\n",
        "  .addNode(\"agent\", callModel)\n",
        "  // Note the \"action\" and \"final\" nodes are identical!\n",
        "  .addNode(\"tools\", toolNode)\n",
        "  .addNode(\"final\", toolNode)\n",
        "  // Set the entrypoint as `agent`\n",
        "  .addEdge(START, \"agent\")\n",
        "  // We now add a conditional edge\n",
        "  .addConditionalEdges(\n",
        "    // First, we define the start node. We use `agent`.\n",
        "    \"agent\",\n",
        "    // Next, we pass in the function that will determine which node is called next.\n",
        "    shouldContinue,\n",
        "  )\n",
        "  // We now add a normal edge from `tools` to `agent`.\n",
        "  .addEdge(\"tools\", \"agent\")\n",
        "  .addEdge(\"final\", END);\n",
        "\n",
        "// Finally, we compile it!\n",
        "const app = workflow.compile();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac83bfea",
      "metadata": {},
      "source": [
        "## Use it!\n",
        "\n",
        "We can now use it! This now exposes the\n",
        "[same interface](https://js.langchain.com/docs/expression_language/) as all\n",
        "other LangChain runnables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9ba5e47a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[human]: what is the weather in sf\n",
            "-----\n",
            "\n",
            "[ai]:  \n",
            "Tools: \n",
            "- search({\"query\":\"weather in San Francisco\"})\n",
            "-----\n",
            "\n",
            "[tool]: It's sunny in San Francisco, but you better look out if you're a Gemini ðŸ˜ˆ.\n",
            "-----\n",
            "\n",
            "[ai]: The weather in San Francisco is sunny.\n",
            "-----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import { HumanMessage, isAIMessage } from \"@langchain/core/messages\";\n",
        "\n",
        "const prettyPrint = (message: BaseMessage) => {\n",
        "  let txt = `[${message._getType()}]: ${message.content}`;\n",
        "  if (\n",
        "    isAIMessage(message) && (message as AIMessage)?.tool_calls?.length || 0 > 0\n",
        "  ) {\n",
        "    const tool_calls = (message as AIMessage)?.tool_calls\n",
        "      ?.map((tc) => `- ${tc.name}(${JSON.stringify(tc.args)})`)\n",
        "      .join(\"\\n\");\n",
        "    txt += ` \\nTools: \\n${tool_calls}`;\n",
        "  }\n",
        "  console.log(txt);\n",
        "};\n",
        "\n",
        "const inputs = { messages: [new HumanMessage(\"what is the weather in sf\")] };\n",
        "for await (const output of await app.stream(inputs, { streamMode: \"values\" })) {\n",
        "  const lastMessage = output.messages[output.messages.length - 1];\n",
        "  prettyPrint(lastMessage);\n",
        "  console.log(\"-----\\n\");\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "779e0d88",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[human]: what is the weather in sf? return this result directly by setting return_direct = True\n",
            "-----\n",
            "\n",
            "[ai]:  \n",
            "Tools: \n",
            "- search({\"query\":\"weather in San Francisco\",\"return_direct\":true})\n",
            "-----\n",
            "\n",
            "[tool]: It's sunny in San Francisco, but you better look out if you're a Gemini ðŸ˜ˆ.\n",
            "-----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "const inputs2 = {\n",
        "  messages: [\n",
        "    new HumanMessage(\n",
        "      \"what is the weather in sf? return this result directly by setting return_direct = True\",\n",
        "    ),\n",
        "  ],\n",
        "};\n",
        "for await (\n",
        "  const output of await app.stream(inputs2, { streamMode: \"values\" })\n",
        ") {\n",
        "  const lastMessage = output.messages[output.messages.length - 1];\n",
        "  prettyPrint(lastMessage);\n",
        "  console.log(\"-----\\n\");\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f99d8e3b",
      "metadata": {},
      "source": [
        "Done! The graph **stopped** after running the `tools` node!\n",
        "\n",
        "```\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-"
    },
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
