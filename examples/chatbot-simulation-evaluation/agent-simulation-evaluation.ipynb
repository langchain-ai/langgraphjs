{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "# Chat Bot Evaluation as Multi-agent Simulation\n",
    "\n",
    "When building a chat bot, such as a customer support assistant, it can be hard to properly evaluate your bot's performance. It's time-consuming to have to manually interact with it intensively for each code change.\n",
    "\n",
    "One way to make the evaluation process easier and more reproducible is to simulate a user interaction.\n",
    "\n",
    "Below is an example of how to create a \"virtual user\" with LangGraph.js to simulate a conversation.\n",
    "\n",
    "The overall simulation looks something like this:\n",
    "\n",
    "![diagram](./img/virtual_user_diagram.png)\n",
    "\n",
    "First, we'll set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed4de09-9ee7-4a2a-bcc7-54236e7cccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "// process.env.OPENAI_API_KEY = \"sk_...\";\n",
    "// Optional tracing in LangSmith\n",
    "// process.env.LANGCHAIN_API_KEY = \"sk_...\";\n",
    "// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n",
    "// process.env.LANGCHAIN_PROJECT = \"Agent Simulation Evaluation: LangGraphJS\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef8e26",
   "metadata": {},
   "source": [
    "## 1. Define Chat Bot\n",
    "\n",
    "Next, we'll define our chat bot. This implementation uses the OpenAI API to generate responses, and takes on the persona of an airline customer support agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afefe443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-AE3nMDCiDkmBMSVI6Y6xJBQjjWQwY\",\n",
      "  \"content\": \"Hello! How can I assist you today?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 9,\n",
      "      \"promptTokens\": 23,\n",
      "      \"totalTokens\": 32\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"system_fingerprint\": \"fp_f85bea6784\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 23,\n",
      "    \"output_tokens\": 9,\n",
      "    \"total_tokens\": 32\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from '@langchain/openai'\n",
    "import type { AIMessageChunk, BaseMessageLike } from \"@langchain/core/messages\";\n",
    "\n",
    "const llm = new ChatOpenAI({ model: \"gpt-4o-mini\" });\n",
    "\n",
    "async function myChatBot(messages: BaseMessageLike[]): Promise<AIMessageChunk> {\n",
    "  const systemMessage = {\n",
    "    role: 'system',\n",
    "    content: 'You are a customer support agent for an airline.',\n",
    "  };\n",
    "  const allMessages = [systemMessage, ...messages];\n",
    "  \n",
    "  const response = await llm.invoke(allMessages)\n",
    "  return response\n",
    "}\n",
    "\n",
    "// Test the chat bot\n",
    "const response = await myChatBot([{ role: 'user', content: 'hi!' }]);\n",
    "\n",
    "console.log(response);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5635e4",
   "metadata": {},
   "source": [
    "## 2. Define Simulated User\n",
    "\n",
    "Now we'll define the simulated user who will interact with our bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e170c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-AE3nNuHpuxAZfG6aQsKoKktitdyfD\",\n",
      "  \"content\": \"Hello! I’m Harrison, and I need to discuss a refund for my trip to Alaska that I took five years ago. I expect all of my money back. Can you assist me with that?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 40,\n",
      "      \"promptTokens\": 108,\n",
      "      \"totalTokens\": 148\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"system_fingerprint\": \"fp_f85bea6784\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 108,\n",
      "    \"output_tokens\": 40,\n",
      "    \"total_tokens\": 148\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { type Runnable } from \"@langchain/core/runnables\";\n",
    "import { AIMessage } from \"@langchain/core/messages\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "async function createSimulatedUser(): Promise<Runnable<{ messages: BaseMessageLike[] }, AIMessage>> {\n",
    "    const systemPromptTemplate = `You are a customer of an airline company. You are interacting with a user who is a customer support person \n",
    "    \n",
    "{instructions}\n",
    "\n",
    "If you have nothing more to add to the conversation, you must respond only with a single word: \"FINISHED\"`;\n",
    "    \n",
    "    const prompt = ChatPromptTemplate.fromMessages([\n",
    "      ['system', systemPromptTemplate],\n",
    "      [\"placeholder\", '{messages}'],\n",
    "    ]);\n",
    "    \n",
    "    const instructions = `Your name is Harrison. You are trying to get a refund for the trip you took to Alaska.\n",
    "You want them to give you ALL the money back. Be extremely persistent. This trip happened 5 years ago.`;\n",
    "\n",
    "    const partialPrompt = await prompt.partial({ instructions });\n",
    "    \n",
    "    const simulatedUser = partialPrompt.pipe(llm);\n",
    "    return simulatedUser;\n",
    "}\n",
    "\n",
    "// Test the simulated user\n",
    "const messages = [{role: \"user\", content: 'Hi! How can I help you?'}];\n",
    "const simulatedUser = await createSimulatedUser()\n",
    "const simulatedUserResponse = await simulatedUser.invoke({ messages });\n",
    "console.log(simulatedUserResponse);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321312b4-a1f0-4454-a481-fdac4e37cb7d",
   "metadata": {},
   "source": [
    "## 3. Define the Agent Simulation\n",
    "\n",
    "The code below creates a LangGraph workflow to run the simulation. The main components are:\n",
    "\n",
    "1. The two nodes: one for the simulated user, the other for the chat bot.\n",
    "2. The graph itself, with a conditional stopping criterion.\n",
    "\n",
    "Read the comments in the code below for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc4446-462b-4ee8-b017-2862fbbdfaf5",
   "metadata": {},
   "source": [
    "**Nodes**\n",
    "\n",
    "First, we define the nodes in the graph. These should take in a list of messages and return a list of messages to ADD to the state.\n",
    "These will be thing wrappers around the chat bot and simulated user we have above.\n",
    "\n",
    "**Note:** one tricky thing here is which messages are which. Because both the chatbot AND our simulated user are both LLMs, both of them will respond with AI messages. Our state will be a list of alternating Human and AI messages. This means that for one of the nodes, there will need to be some logic that flips the AI and human roles. In this example, we will assume that `HumanMessages` are messages from the simulated user. This means that we need some logic in the simulated user node to swap AI and Human messages.\n",
    "\n",
    "First, let's define the chat bot node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d5d9e0-41ee-46c9-b62f-9128b91f99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MessagesAnnotation } from \"@langchain/langgraph\";\n",
    "\n",
    "async function chatBotNode (state: typeof MessagesAnnotation.State) {\n",
    "  const messages = state.messages\n",
    "  const chatBotResponse = await myChatBot(messages);\n",
    "  return { messages: [chatBotResponse] }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694c3c0c-56c5-4410-8fa8-ea2c0f11f506",
   "metadata": {},
   "source": [
    "Next, let's define the node for our simulated user. This will involve a little logic to swap the roles of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac45873-91a3-4310-939f-a0a53da4233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BaseMessage, HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "// MessagesAnnotation coerces all message likes to base message classes\n",
    "function swapRoles(messages: BaseMessage[]) {\n",
    "  return messages.map((m) =>\n",
    "    m instanceof AIMessage\n",
    "      ? new HumanMessage({ content: m.content })\n",
    "      : new AIMessage({ content: m.content }),\n",
    "  )\n",
    "}\n",
    "\n",
    "async function simulatedUserNode (state: typeof MessagesAnnotation.State) {\n",
    "  const messages = state.messages\n",
    "  const newMessages = swapRoles(messages)\n",
    "  // This returns a runnable directly, so we need to use `.invoke` below:\n",
    "  const simulateUser = await createSimulatedUser();\n",
    "  const response = await simulateUser.invoke({ messages: newMessages })\n",
    "\n",
    "  return { messages: [{ role: \"user\", content: response.content }] }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d8a3e-9171-4c43-a595-44d312722148",
   "metadata": {},
   "source": [
    "**Edges**\n",
    "\n",
    "We now need to define the logic for the edges. The main logic occurs after the simulated user goes, and it should lead to one of two outcomes:\n",
    "\n",
    "- Either we continue and call the customer support bot\n",
    "- Or we finish and the conversation is over\n",
    "\n",
    "So what is the logic for the conversation being over? We will define that as either the Human chatbot responds with `FINISHED` (see the system prompt) OR the conversation is more than 6 messages long (this is an arbitrary number just to keep this example short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820a1557-a121-48c2-af5b-81220f43c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function shouldContinue(state: typeof MessagesAnnotation.State) {\n",
    "  const messages = state.messages;\n",
    "  if (messages.length > 6) {\n",
    "    return '__end__';\n",
    "  } else if (messages[messages.length - 1].content === 'FINISHED') {\n",
    "    return '__end__';\n",
    "  } else {\n",
    "    return 'continue';\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0856d4f-9334-4f28-944b-06d303e913a4",
   "metadata": {},
   "source": [
    "**Graph**\n",
    "\n",
    "We can now define the graph that sets up the simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1889196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StateGraph, END, START } from \"@langchain/langgraph\";\n",
    "\n",
    "function createSimulation() {\n",
    "  const workflow = new StateGraph(MessagesAnnotation)\n",
    "    .addNode('user', simulatedUserNode)\n",
    "    .addNode('chatbot', chatBotNode)\n",
    "    .addEdge('chatbot', 'user')\n",
    "    .addConditionalEdges('user', shouldContinue, {\n",
    "      [END]: END,\n",
    "      continue: 'chatbot',\n",
    "    })\n",
    "    .addEdge(START, 'chatbot')\n",
    "\n",
    "  const simulation = workflow.compile()\n",
    "  return simulation;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18973bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import * as tslab from \"tslab\";\n",
    "\n",
    "const drawableGraph = createSimulation().getGraph();\n",
    "const image = await drawableGraph.drawMermaidPng();\n",
    "const arrayBuffer = await image.arrayBuffer();\n",
    "\n",
    "await tslab.display.png(new Uint8Array(arrayBuffer));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd22ce",
   "metadata": {},
   "source": [
    "## 4. Run Simulation\n",
    "\n",
    "Now we can evaluate our chat bot! We can invoke it with empty messages (this will simulate letting the chat bot start the initial conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32b606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot: How can I assist you today with your airline-related questions or concerns?\n",
      "\n",
      "---\n",
      "\n",
      "user: Hi, I'm Harrison, and I'm looking to get a refund for a trip I took to Alaska five years ago. I believe I am entitled to a full refund, and I would like to resolve this matter as soon as possible. Can you help me with that?\n",
      "\n",
      "---\n",
      "\n",
      "chatbot: Hi Harrison! I’d be happy to assist you with your request. However, I must inform you that our airline’s refund policy typically covers requests made within a certain timeframe from the date of travel, generally within 12 months for most fares. Since your trip to Alaska was five years ago, it is likely that it falls outside of our standard refund window.\n",
      "\n",
      "That said, if there were any extraordinary circumstances surrounding your trip or if you have documentation that supports your claim, please provide more details so I can better assist you. If you haven't already, I recommend contacting our customer service team directly through the website or our dedicated customer service number for specific cases.\n",
      "\n",
      "---\n",
      "\n",
      "user: I understand the typical policy, but I believe my situation warrants a full refund regardless of the time elapsed. It's crucial to me that I receive all my money back for the trip. I can provide any necessary details or documentation that supports my claim. Can you please make an exception in this case or escalate this issue? I am determined to get a full refund for my trip!\n",
      "\n",
      "---\n",
      "\n",
      "chatbot: I understand how important this matter is to you, Harrison, and I appreciate your determination. Unfortunately, as a customer support agent, I am bound by the airline's policies and procedures, which typically do not allow for exceptions to the refund timeline.\n",
      "\n",
      "However, I recommend that you gather all relevant details and documentation related to your trip, including any evidence that might support your request for an exception. After you’ve compiled this information, you can submit a formal appeal or request for a special review through our customer service channels. This often involves contacting customer relations or submitting a written request through our website, where your case can be considered by a dedicated team.\n",
      "\n",
      "If you’d like, I can guide you on how to submit this information or help you find the right contact point to escalate your request. Just let me know!\n",
      "\n",
      "---\n",
      "\n",
      "user: I appreciate the guidance, but I must insist that a full refund is due to me. This isn't just a matter of policy; it's about recognizing the value of customer experience and fairness. I prepared for this trip and expected that my investment would be protected. I urge you to reconsider and push for this refund on my behalf. I'm not willing to accept a denial based solely on policy restrictions, especially after all this time. Can you take further action to ensure I receive all my money back? Please help me with this!\n",
      "\n",
      "---\n",
      "\n",
      "chatbot: I completely understand your feelings and the importance of this situation to you, Harrison. Your concerns about customer experience and fairness are valid, and I empathize with your position. However, I want to clarify that as a customer support agent, I do not have the authority to override established policies or issue refunds outside of the established guidelines.\n",
      "\n",
      "The best course of action would be to formally submit your request along with all your supporting documentation to demonstrate why you believe you deserve a refund despite the time elapsed. This escalation will ensure that your case is reviewed by the appropriate department that handles such requests.\n",
      "\n",
      "I recommend reaching out through our customer service channels, including our website’s contact form or calling our customer relations department. Providing your case with detailed information and expressing your concerns about customer experience may lead to a more favorable consideration.\n",
      "\n",
      "If you would like assistance in drafting your request or finding the correct contact information, please let me know, and I’ll do my best to help you!\n",
      "\n",
      "---\n",
      "\n",
      "user: I appreciate your attempts to guide me, but I'm not prepared to take a backseat on this matter. I need to be clear: I am requesting a full refund for my Alaska trip, and I believe that the airline has a responsibility to honor that request despite the time that has passed. It's about accountability and valuing customers, and I will not back down until I receive every dollar back. I urge you to escalate this matter. I am not interested in going through more hoops or waiting for a review that may not result in the outcome I deserve. Can you elevate this issue to someone who has the authority to grant my refund? I need this resolved now!\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async function runSimulation() {\n",
    "  const simulation = createSimulation()\n",
    "  for await (const chunk of await simulation.stream({})) {\n",
    "    const nodeName = Object.keys(chunk)[0];\n",
    "    const messages = chunk[nodeName].messages;\n",
    "    console.log(`${nodeName}: ${messages[0].content}`);\n",
    "    console.log('\\n---\\n');\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "await runSimulation();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48db342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
